{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHWEkYAeZjh8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "ab2b4a83-44f2-4bf9-bc03-33eafbc4ab01"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGfU30u7688N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "logDQNQj7cof",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing for recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOoeKpYq7h2L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('precision', 10)\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRSNQ0BW7jDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "current_phase = 2\n",
        "phases = [i for i in range(current_phase + 1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWI4Nk4Z7nkJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3552b12b-7b28-4a26-f16a-b1ab6943663d"
      },
      "source": [
        "click_list = []\n",
        "test_qtime_list = []\n",
        "\n",
        "for i in tqdm(phases):\n",
        "    #read train_click \n",
        "    df_click_train = pd.read_csv(\n",
        "        'kdd2020_data/underexpose_train/underexpose_train_click-{}.csv'.format(i),\n",
        "        header=None)\n",
        "    df_click_train.columns = ['user_id', 'item_id', 'time']\n",
        "    df_click_train['phase'] = i\n",
        "    click_list.append(df_click_train)\n",
        "\n",
        "    #read test_click \n",
        "    df_click_test = pd.read_csv(\n",
        "        'kdd2020_data/underexpose_test/underexpose_test_click-{}.csv'.format(i),\n",
        "        header=None)\n",
        "    df_click_test.columns = ['user_id', 'item_id', 'time']\n",
        "    df_click_test['phase'] = i\n",
        "\n",
        "    df_qtime_test = pd.read_csv('kdd2020_data/underexpose_test/underexpose_test_qtime-{}.csv'.format(i),\n",
        "        header=None)\n",
        "    df_qtime_test.columns = ['user_id', 'query_time']\n",
        "    df_qtime_test['item_id'] = -1\n",
        "    df_qtime_test['phase'] = i\n",
        "    \n",
        "    #combine\n",
        "    click_list.append(df_click_test)\n",
        "    test_qtime_list.append(df_qtime_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00,  7.18it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VakXzsXi9UU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#change list to df\n",
        "df_click = pd.concat(click_list)\n",
        "df_click = df_click.sort_values(['user_id', 'time']).reset_index(drop=True)\n",
        "df_test_qtime = pd.concat(test_qtime_list)\n",
        "df_test_qtime = df_test_qtime.sort_values(['user_id', 'query_time']).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLUwh6_e9wur",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9a46a05d-2c1b-4420-d98a-470e9736d25c"
      },
      "source": [
        "#know the basic of data\n",
        "print('train samples:{}'.format(len(df_click)))\n",
        "print('test samples:{}'.format(len(df_test_qtime)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train samples:795911\n",
            "test samples:5079\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyWxT8uy-jUl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63cd05d8-c2ed-4743-b3c5-8f3fe3af9a46"
      },
      "source": [
        "#del the sample in test who's time is later than qtime \n",
        "df_ = df_test_qtime.groupby(['phase'])['user_id'].apply(lambda x: sorted(list(set(x)))).reset_index()\n",
        "phase_testusers_dict = dict(zip(df_['phase'], df_['user_id']))\n",
        "\n",
        "click_list = []\n",
        "train_qtime_list = []\n",
        "\n",
        "groups = df_click.groupby(['phase', 'user_id'])\n",
        "for (phase, user_id), g in tqdm(groups):\n",
        "    if user_id in phase_testusers_dict[phase]:\n",
        "        qtime = df_test_qtime[(df_test_qtime['user_id'] == user_id) & (\n",
        "            df_test_qtime['phase'] == phase)]['query_time'].values[0]\n",
        "        test_click = g[g['time'] < qtime]\n",
        "        assert test_click.shape[0] == g.shape[0]\n",
        "        click_list.append(test_click)\n",
        "#use the last time as qtime\n",
        "    else:\n",
        "        train_qtime = g.tail(1)\n",
        "        train_qtime_list.append(train_qtime)\n",
        "\n",
        "        train_click = g.head(g.shape[0] - 1)\n",
        "        click_list.append(train_click)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 55575/55575 [01:01<00:00, 906.13it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJFnUP1fDXE8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1cbc5bcd-c23f-4ddc-ca7a-2b1002a7fd2f"
      },
      "source": [
        "df_click = pd.concat(click_list, sort=False)\n",
        "df_train_qtime = pd.concat(train_qtime_list)\n",
        "df_train_qtime.rename(columns={'time': 'query_time'}, inplace=True)\n",
        "df_train_qtime = df_train_qtime[['user_id', 'query_time', 'item_id', 'phase']]\n",
        "print('number of users in train', df_train_qtime['user_id'].nunique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of users in train 23307\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZrXhQOZEJaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#label\n",
        "df_qtime = pd.concat([df_train_qtime, df_test_qtime], sort=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfoGty64ElX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#save\n",
        "df_qtime.to_pickle('kdd2020_data/recall/qtime.pkl')\n",
        "df_click.to_pickle('kdd2020_data/recall/click.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4yJykihFK2i",
        "colab_type": "text"
      },
      "source": [
        "# Recall_1\n",
        "**item_cf:**\n",
        "* 1:\n",
        "$w_{ij}=\\frac{{N(i)}\\bigcap{N(j)}}{N(i)}$\n",
        "\n",
        "\n",
        "* 2:\n",
        "$w_{ij}=\\frac{{N(i)}\\bigcap{N(j)}}{(N(i)*N(j))^{0.5}}$\n",
        "\n",
        "\n",
        "* 3:\n",
        "$w_{ij}=\\frac{\\sum_(\\frac{1}{\\log{(1+N(x))}})}{(N(i)*N(j))^{0.5}}$\n",
        "\n",
        "N(i): how many people have interaction on item i \n",
        "\n",
        "N(j): how many people have interaction on item j\n",
        "\n",
        "N(x): how many items the people have interaction on, those people who have interaction both on item i and j \n",
        "\n",
        "* 4:\n",
        "we also can import some time and location parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbTJkSkbFDC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import warnings\n",
        "from collections import defaultdict\n",
        "import math\n",
        "import pickle\n",
        "import multitasking\n",
        "import signal\n",
        "\n",
        "multitasking.set_max_threads(10)\n",
        "multitasking.set_engine('process')\n",
        "signal.signal(signal.SIGINT, multitasking.killall)\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('precision', 10)\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzeyaS77Fr9J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "edb619e9-a682-4076-8fd3-3de738034286"
      },
      "source": [
        "df_qtime = pd.read_pickle('kdd2020_data/recall/qtime.pkl')\n",
        "df_click = pd.read_pickle('kdd2020_data/recall/click.pkl')\n",
        "phases = sorted(list(df_qtime['phase'].unique()))\n",
        "phases"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRYC6caHGE9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rec1_item_sim(df, user_col, item_col):\n",
        "\n",
        "    user_item_ = df.groupby(user_col)[item_col].agg(lambda x: list(x)).reset_index()\n",
        "    user_item_dict = dict(zip(user_item_[user_col], user_item_[item_col]))\n",
        "\n",
        "    user_time_ = df.groupby(user_col)['time'].agg(lambda x: list(x)).reset_index()  \n",
        "    user_time_dict = dict(zip(user_time_[user_col], user_time_['time']))\n",
        "\n",
        "    sim_item = {}\n",
        "    item_cnt = defaultdict(int)\n",
        "    for user, items in tqdm(user_item_dict.items()):\n",
        "        for loc1, item in enumerate(items):\n",
        "            item_cnt[item] += 1\n",
        "            sim_item.setdefault(item, {})\n",
        "            for loc2, relate_item in enumerate(items):\n",
        "                t1 = user_time_dict[user][loc1]\n",
        "                t2 = user_time_dict[user][loc2]\n",
        "                #filter the distance bigger than 5 or the time difference bigger than 0.000003\n",
        "                if abs(loc2 -loc1) > 5 or item == relate_item or abs(t2-t1) > 0.000003:\n",
        "                    continue\n",
        "                #filter itself\n",
        "                if loc2-loc1==0:\n",
        "                  continue\n",
        "                sim_item[item].setdefault(relate_item, 0)\n",
        "\n",
        "                #consider of the position relation\n",
        "                if loc1 - loc2 > 0:\n",
        "                    sim_item[item][relate_item] += 0.7 * (0.8**(loc1 - loc2 -\n",
        "                                  1)) * (1 - (t1 - t2) * 10000) / math.log(\n",
        "                                      1 + len(items))  \n",
        "                else:\n",
        "                    sim_item[item][relate_item] += 1.0 * (0.8**(loc2 - loc1 -\n",
        "                                  1)) * (1 - (t2 - t1) * 10000) / math.log(\n",
        "                                      1 + len(items))  \n",
        "\n",
        "    sim_item_corr = sim_item.copy()\n",
        "    for i, related_items in tqdm(sim_item.items()):\n",
        "        for j, cij in related_items.items():\n",
        "            sim_item_corr[i][j] = cij / math.sqrt(item_cnt[i] * item_cnt[j])\n",
        "\n",
        "    return sim_item_corr, user_item_dict, item_cnt, user_time_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7UjAdP9JLdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rec1(df_qtime, item_sim_list, user_item, item_cnt, user_time_dict):\n",
        "    data_list = []\n",
        "    for user_id, query_time, item_id, phase in tqdm(df_qtime.values):\n",
        "        rank = {}\n",
        "        interacted_items = user_item[user_id]\n",
        "        #reverse\n",
        "        interacted_items = interacted_items[::-1] \n",
        "        for loc, i in enumerate(interacted_items):\n",
        "            #import time factor\n",
        "            time_factor = 1-1000 * (query_time - user_time_dict[user_id][len(interacted_items)-loc-1]) \n",
        "            #1:500\n",
        "            for j, wij in sorted(item_sim_list[i].items(),key=lambda d: d[1],reverse=True)[0:500]:\n",
        "                if j not in interacted_items:\n",
        "                    rank.setdefault(j, 0)\n",
        "                    rank[j] += wij * (0.7**loc) * item_cnt[j] * time_factor\n",
        "        #filter top100\n",
        "        sim_items = sorted(rank.items(), key=lambda d: d[1],reverse=True)[:100]\n",
        "        item_ids = [item[0] for item in sim_items]\n",
        "        item_sim_scores = [item[1] for item in sim_items]\n",
        "\n",
        "        df_temp = pd.DataFrame()\n",
        "        df_temp['item_id'] = item_ids\n",
        "        df_temp['sim_score'] = item_sim_scores\n",
        "        df_temp['user_id'] = user_id\n",
        "        df_temp['query_time'] = query_time\n",
        "        df_temp['phase'] = phase\n",
        "\n",
        "        if item_id == -1:\n",
        "            df_temp['label'] = np.nan\n",
        "        else:\n",
        "        #if we hit the item, the label is 1,otherwise the label is 0.\n",
        "            df_temp['label'] = 0\n",
        "            df_temp.loc[df_temp['item_id'] == item_id, 'label'] = 1\n",
        "\n",
        "        df_temp.sort_values(['sim_score'], inplace=True, ascending=False)\n",
        "        df_temp = df_temp[['user_id', 'phase', 'query_time', 'item_id', 'sim_score', 'label']]\n",
        "        df_temp['user_id'] = df_temp['user_id'].astype('int')\n",
        "        df_temp['item_id'] = df_temp['item_id'].astype('int')\n",
        "\n",
        "        data_list.append(df_temp)\n",
        "\n",
        "    df_data = pd.concat(data_list, sort=False)\n",
        "\n",
        "    return df_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9PvzHa2Lbc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@multitasking.task\n",
        "#recall depend on phase\n",
        "def work(phase, force=False):\n",
        "    os.makedirs('kdd2020_data/my_model/recall_1', exist_ok=True)\n",
        "\n",
        "    if force or (\n",
        "            not os.path.exists(\n",
        "                'kdd2020_data/my_model/recall_1/sim_{}.pkl'.format(phase))\n",
        "            or not os.path.exists(\n",
        "                'kdd2020_data/my_model/recall_1/recall_{}.pkl'.format(phase))):\n",
        "        \n",
        "        df_click_phase = df_click[df_click['phase'] == phase]\n",
        "        item_sim, user_item, item_cnt, user_time_dict = rec1_item_sim(df_click_phase, 'user_id', 'item_id')\n",
        "\n",
        "        f = open('kdd2020_data/my_model/recall_1/sim_{}.pkl'.format(phase), 'wb')\n",
        "        pickle.dump(item_sim, f)\n",
        "        f.close()\n",
        "\n",
        "        df_qtime_phase = df_qtime[df_qtime['phase'] == phase]\n",
        "        df_data = rec1(df_qtime_phase, item_sim, user_item, item_cnt,user_time_dict)\n",
        "        df_data.to_pickle('kdd2020_data/my_model/recall_1/recall_{}.pkl'.format(phase))\n",
        "\n",
        "        print('phase {} finish'.format(phase))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_5X8WrhMjz3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "cfd15258-7412-4a11-ce6e-ae412308aec7"
      },
      "source": [
        "force = False\n",
        "for phase in phases:\n",
        "    work(phase, force)\n",
        "    \n",
        "multitasking.wait_for_tasks()\n",
        "print('over')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18398/18398 [00:08<00:00, 2200.18it/s]\n",
            "100%|██████████| 18505/18505 [00:08<00:00, 2256.33it/s]\n",
            "100%|██████████| 18672/18672 [00:08<00:00, 2086.19it/s]\n",
            "100%|██████████| 41024/41024 [00:01<00:00, 32510.37it/s]\n",
            "100%|██████████| 40768/40768 [00:01<00:00, 27515.55it/s]\n",
            "100%|██████████| 41400/41400 [00:01<00:00, 29163.40it/s]\n",
            "100%|██████████| 18398/18398 [08:07<00:00, 37.72it/s]\n",
            "100%|██████████| 18505/18505 [08:13<00:00, 37.48it/s]\n",
            "100%|██████████| 18672/18672 [08:19<00:00, 37.38it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "phase 2 finish\n",
            "phase 0 finish\n",
            "phase 1 finish\n",
            "over\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXC8UdCwNReU",
        "colab_type": "text"
      },
      "source": [
        "**ndcg@K**\n",
        "\n",
        "$ndcg@K=\\frac{\\sum_1^n{\\frac{Gain(r)}{log_2(r+1)}}}{n}$\n",
        "\n",
        "n:the num we have recall for every user\n",
        "\n",
        "r:the location of the recall item who's label is 1\n",
        "\n",
        "Gain(r): the gain when we hit the target, here is 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Af5WMUOOeyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(df, median_item_degree, item_degree_map, num_cases_full, num_cases_half):\n",
        "    gg = df.groupby(['user_id'])\n",
        "\n",
        "    ndcg_50_full = 0.0\n",
        "    hitrate_50_full = 0.0\n",
        "\n",
        "    ndcg_50_half = 0.0\n",
        "    hitrate_50_half = 0.0\n",
        "\n",
        "    for _, g in tqdm(gg):\n",
        "        try:\n",
        "            item_id = g[g['label'] == 1]['item_id'].values[0]\n",
        "            item_degree = item_degree_map[item_id]\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "        predictions = g['item_id'].values.tolist()\n",
        "\n",
        "        rank = 0\n",
        "        while rank < 50 and predictions[rank] != item_id:\n",
        "            rank += 1\n",
        "\n",
        "        if rank < 50:\n",
        "            ndcg_50_full += 1.0 / np.log2(rank + 2.0)\n",
        "            hitrate_50_full += 1.0\n",
        "\n",
        "        if item_degree <= median_item_degree:\n",
        "            if rank < 50:\n",
        "                ndcg_50_half += 1.0 / np.log2(rank + 2.0)\n",
        "                hitrate_50_half += 1.0\n",
        "\n",
        "    ndcg_50_full /= num_cases_full\n",
        "    hitrate_50_full /= num_cases_full\n",
        "\n",
        "    ndcg_50_half /= num_cases_half\n",
        "    hitrate_50_half /= num_cases_half\n",
        "\n",
        "    return ndcg_50_full, hitrate_50_full, ndcg_50_half, hitrate_50_half"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xetd0fPOl6j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_scores(df, phase):\n",
        "    df_qtime = pd.read_pickle('kdd2020_data/recall/qtime.pkl')\n",
        "    df_click = pd.read_pickle('kdd2020_data/recall/click.pkl')\n",
        "    \n",
        "    df_qtime = df_qtime[df_qtime['phase']==phase]\n",
        "    df_click = df_click[df_click['phase']==phase]\n",
        "    \n",
        "    #filter traindata\n",
        "    oof_answer = df_qtime[df_qtime['item_id'] != -1]\n",
        "    num_cases_full = oof_answer.shape[0]\n",
        "\n",
        "    answer_items = oof_answer['item_id'].values\n",
        "    item_degree = df_click['item_id'].value_counts().reset_index()\n",
        "    item_degree.columns = ['item_id', 'degree']\n",
        "\n",
        "    answer_item_degree = item_degree[item_degree['item_id'].isin(answer_items)]\n",
        "    list_item_degress = answer_item_degree['degree'].values.tolist()\n",
        "    median_item_degree = list_item_degress[len(list_item_degress) // 2]\n",
        "    item_degree_map = dict(zip(item_degree['item_id'], item_degree['degree']))\n",
        "    num_cases_half = answer_item_degree[answer_item_degree['degree']<= median_item_degree].shape[0]\n",
        "\n",
        "    ndcg_50_full, hitrate_50_full, ndcg_50_half, hitrate_50_half = evaluate(\n",
        "        df, median_item_degree, item_degree_map, num_cases_full, num_cases_half)\n",
        "    return ndcg_50_full, hitrate_50_full, ndcg_50_half, hitrate_50_half"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1Olg5VHPVfS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "251fae58-a827-4b8d-ede8-97c270ce4a03"
      },
      "source": [
        "item_sim_phase = {}\n",
        "df_recall = pd.DataFrame()\n",
        "val_score = np.array([0.0, 0.0, 0.0, 0.0])\n",
        "for phase in phases:\n",
        "    f = open('kdd2020_data/my_model/recall_1/sim_{}.pkl'.format(phase), 'rb')\n",
        "    item_sim = pickle.load(f)\n",
        "    f.close()\n",
        "\n",
        "    df_data = pd.read_pickle('kdd2020_data/my_model/recall_1/recall_{}.pkl'.format(phase))\n",
        "\n",
        "    item_sim_phase[phase] = item_sim\n",
        "    df_recall = df_recall.append(df_data)\n",
        "\n",
        "    score = evaluate_scores(df_data, phase)\n",
        "    val_score += score\n",
        "\n",
        "    print('phase', phase, score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18504/18504 [00:19<00:00, 961.85it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "phase 0 (0.049471085766303685, 0.11483196769979813, 0.02038499422582166, 0.06592146746918888)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18670/18670 [00:19<00:00, 956.38it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "phase 1 (0.04991123719165572, 0.11672371061017349, 0.018408447503913128, 0.0608195542774982)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18396/18396 [00:19<00:00, 953.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "phase 2 (0.05024071422638227, 0.11856595642805841, 0.018270022854726724, 0.06242603550295858)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwuCjQYKQAMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#save the similarity \n",
        "f = open('kdd2020_data/my_model/sim1.pkl', 'wb')\n",
        "pickle.dump(item_sim_phase, f)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjxNfP76PxC5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "10fd5cd9-81ec-4a69-a43c-3feb1862070b"
      },
      "source": [
        "val_score\n",
        "#save recall1\n",
        "df_recall.sort_values(['user_id', 'phase', 'query_time'], inplace=True)\n",
        "df_recall.to_pickle('kdd2020_data/my_model/recall_1.pkl')\n",
        "df_recall.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>phase</th>\n",
              "      <th>query_time</th>\n",
              "      <th>item_id</th>\n",
              "      <th>sim_score</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>87837</td>\n",
              "      <td>0.7427316859</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>92349</td>\n",
              "      <td>0.5806058044</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>91290</td>\n",
              "      <td>0.5208125481</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>38168</td>\n",
              "      <td>0.4589800761</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>13663</td>\n",
              "      <td>0.4499775748</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  phase    query_time  item_id     sim_score  label\n",
              "0        1    0.0  0.9839419315    87837  0.7427316859    0.0\n",
              "1        1    0.0  0.9839419315    92349  0.5806058044    0.0\n",
              "2        1    0.0  0.9839419315    91290  0.5208125481    0.0\n",
              "3        1    0.0  0.9839419315    38168  0.4589800761    0.0\n",
              "4        1    0.0  0.9839419315    13663  0.4499775748    0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIlsgb7YRPBS",
        "colab_type": "text"
      },
      "source": [
        "# Recall_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QP_q_IkqRb_j",
        "colab_type": "text"
      },
      "source": [
        "**item_cf**\n",
        "\n",
        "$w_{ij}=\\sum_{\\frac{1}{log(len(items)+1)*log(len(users)+1)}}$\n",
        "\n",
        "len(items):how many items the people have interaction on, those people who have interaction both on item i and j \n",
        "\n",
        "len(users):how many people have interaction on item i \n",
        "\n",
        "\n",
        "**reference:**\n",
        "\n",
        "Zhou T, Ren J, Medo M, et al. Bipartite network projection and personal recommendation[J]. Physical review E, 2007, 76(4): 046115."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNXvLzjDRFVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import warnings\n",
        "from collections import defaultdict\n",
        "import math\n",
        "import pickle\n",
        "import multitasking\n",
        "import signal\n",
        "\n",
        "multitasking.set_max_threads(10)\n",
        "multitasking.set_engine('process')\n",
        "signal.signal(signal.SIGINT, multitasking.killall)\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('precision', 10)\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U63soa7rRvzd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_qtime = pd.read_pickle('kdd2020_data/recall/qtime.pkl')\n",
        "df_click = pd.read_pickle('kdd2020_data/recall/click.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE32YngeR1Kp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f863c497-2121-4c6b-87fd-0535256a4cff"
      },
      "source": [
        "phases = sorted(list(df_qtime['phase'].unique()))\n",
        "phases"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhfR-M-iR32V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rec2_item_sim(df, user_col, item_col):\n",
        "    user_item_ = df.groupby(user_col)[item_col].agg(list).reset_index()\n",
        "    user_item_dict = dict(zip(user_item_[user_col], user_item_[item_col]))\n",
        "\n",
        "    item_user_ = df.groupby(item_col)[user_col].agg(list).reset_index()\n",
        "    item_user_dict = dict(zip(item_user_[item_col], item_user_[user_col]))\n",
        "\n",
        "    user_time_ = df.groupby(user_col)['time'].agg(lambda x: list(x)).reset_index()\n",
        "    user_time_dict = dict(zip(user_time_[user_col], user_time_['time']))\n",
        "\n",
        "    sim_item = {}\n",
        "    for item, users in tqdm(item_user_dict.items()):\n",
        "        sim_item.setdefault(item, {})\n",
        "\n",
        "        for u in users:\n",
        "            items = user_item_dict[u]\n",
        "\n",
        "            for relate_item in items:\n",
        "                if item==relate_item:\n",
        "                  continue\n",
        "                loc1 = user_item_dict[u].index(item)\n",
        "                loc2 = user_item_dict[u].index(relate_item)\n",
        "\n",
        "                t1 = user_time_dict[u][loc1]\n",
        "                t2 = user_time_dict[u][loc2]\n",
        "\n",
        "                sim_item[item].setdefault(relate_item, 0)\n",
        "                sim_item[item][relate_item] += 1 / (math.log(len(users)+1) * math.log(len(items)+1))\n",
        "\n",
        "    return sim_item, user_item_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jidY-2DATmWk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rec2(df_qtime, item_sim_list, user_item):\n",
        "    data_list = []\n",
        "    for user_id, query_time, item_id, phase in tqdm(df_qtime.values):\n",
        "        rank = {}\n",
        "        interacted_items = user_item[user_id]\n",
        "        interacted_items = interacted_items[::-1]\n",
        "        for loc, i in enumerate(interacted_items):\n",
        "            for j, wij in sorted(item_sim_list[i].items(),\n",
        "                                 key=lambda d: d[1],\n",
        "                                 reverse=True)[0:500]:\n",
        "                if j not in interacted_items:\n",
        "                    rank.setdefault(j, 0)\n",
        "                    rank[j] += wij * (0.7**loc)\n",
        "\n",
        "        sim_items = sorted(rank.items(), key=lambda d: d[1],\n",
        "                           reverse=True)[:100]\n",
        "        item_ids = [item[0] for item in sim_items]\n",
        "        item_sim_scores = [item[1] for item in sim_items]\n",
        "\n",
        "        df_temp = pd.DataFrame()\n",
        "        df_temp['item_id'] = item_ids\n",
        "        df_temp['sim_score'] = item_sim_scores\n",
        "        df_temp['user_id'] = user_id\n",
        "        df_temp['query_time'] = query_time\n",
        "        df_temp['phase'] = phase\n",
        "\n",
        "        if item_id == -1:\n",
        "            df_temp['label'] = np.nan\n",
        "        else:\n",
        "            df_temp['label'] = 0\n",
        "            df_temp.loc[df_temp['item_id'] == item_id, 'label'] = 1\n",
        "\n",
        "        df_temp.sort_values(['sim_score'], inplace=True, ascending=False)\n",
        "        df_temp = df_temp[[\n",
        "            'user_id', 'phase', 'query_time', 'item_id', 'sim_score', 'label'\n",
        "        ]]\n",
        "        df_temp['user_id'] = df_temp['user_id'].astype('int')\n",
        "        df_temp['item_id'] = df_temp['item_id'].astype('int')\n",
        "\n",
        "        data_list.append(df_temp)\n",
        "\n",
        "    df_data = pd.concat(data_list, sort=False)\n",
        "    return df_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkYYSMz7Tuek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@multitasking.task\n",
        "def work(phase, force=False):\n",
        "    os.makedirs('kdd2020_data/my_model/recall_2', exist_ok=True)\n",
        "\n",
        "    if force or (\n",
        "            not os.path.exists('kdd2020_data/my_model/recall_2/sim_{}.pkl'.format(phase))\n",
        "            or not os.path.exists('kdd2020_data/my_model/recall_2/recall_{}.pkl'.format(phase))):\n",
        "      \n",
        "        df_click_phase = df_click[df_click['phase'] == phase]\n",
        "        sim_item, user_item_dict = rec2_item_sim(df_click_phase, 'user_id','item_id')\n",
        "\n",
        "        f = open('kdd2020_data/my_model/recall_2/sim_{}.pkl'.format(phase), 'wb')\n",
        "        pickle.dump(sim_item, f)\n",
        "        f.close()\n",
        "\n",
        "        df_qtime_phase = df_qtime[df_qtime['phase'] == phase]\n",
        "        df_data = rec2(df_qtime_phase, sim_item, user_item_dict)\n",
        "        df_data.to_pickle('kdd2020_data/my_model/recall_2/recall_{}.pkl'.format(phase))\n",
        "\n",
        "        print('phase {} finish'.format(phase))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PMFI27GT9Ih",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "d526acab-f92f-4277-fe8a-75a13b3c618b"
      },
      "source": [
        "force = False\n",
        "for phase in phases:\n",
        "    work(phase, force)\n",
        "\n",
        "multitasking.wait_for_tasks()\n",
        "print('over')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40768/40768 [00:35<00:00, 1156.63it/s]\n",
            "100%|██████████| 41400/41400 [00:36<00:00, 1144.47it/s]\n",
            "100%|██████████| 41024/41024 [00:38<00:00, 1069.56it/s]\n",
            "100%|██████████| 18505/18505 [10:02<00:00, 30.71it/s]\n",
            "100%|██████████| 18672/18672 [10:11<00:00, 30.53it/s]\n",
            "100%|██████████| 18398/18398 [10:20<00:00, 29.65it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "phase 0 finish\n",
            "phase 1 finish\n",
            "phase 2 finish\n",
            "over\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIr39ZBmUPz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(df, median_item_degree, item_degree_map, num_cases_full, num_cases_half):\n",
        "    gg = df.groupby(['user_id'])\n",
        "\n",
        "    ndcg_50_full = 0.0\n",
        "    hitrate_50_full = 0.0\n",
        "\n",
        "    ndcg_50_half = 0.0\n",
        "    hitrate_50_half = 0.0\n",
        "\n",
        "    for _, g in tqdm(gg):\n",
        "        try:\n",
        "            item_id = g[g['label'] == 1]['item_id'].values[0]\n",
        "            item_degree = item_degree_map[item_id]\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "        predictions = g['item_id'].values.tolist()\n",
        "\n",
        "        rank = 0\n",
        "        while rank < 50 and predictions[rank] != item_id:\n",
        "            rank += 1\n",
        "\n",
        "        if rank < 50:\n",
        "            ndcg_50_full += 1.0 / np.log2(rank + 2.0)\n",
        "            hitrate_50_full += 1.0\n",
        "\n",
        "        if item_degree <= median_item_degree:\n",
        "            if rank < 50:\n",
        "                ndcg_50_half += 1.0 / np.log2(rank + 2.0)\n",
        "                hitrate_50_half += 1.0\n",
        "\n",
        "    ndcg_50_full /= num_cases_full\n",
        "    hitrate_50_full /= num_cases_full\n",
        "\n",
        "    ndcg_50_half /= num_cases_half\n",
        "    hitrate_50_half /= num_cases_half\n",
        "\n",
        "    return ndcg_50_full, hitrate_50_full, ndcg_50_half, hitrate_50_half"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKCSzDZEUTwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_scores(df, phase):\n",
        "    df_qtime = pd.read_pickle('kdd2020_data/recall/qtime.pkl')\n",
        "    df_click = pd.read_pickle('kdd2020_data/recall/click.pkl')\n",
        "    \n",
        "    df_qtime = df_qtime[df_qtime['phase']==phase]\n",
        "    df_click = df_click[df_click['phase']==phase]\n",
        "\n",
        "    oof_answer = df_qtime[df_qtime['item_id'] != -1]\n",
        "    num_cases_full = oof_answer.shape[0]\n",
        "\n",
        "    answer_items = oof_answer['item_id'].values\n",
        "    item_degree = df_click['item_id'].value_counts().reset_index()\n",
        "    item_degree.columns = ['item_id', 'degree']\n",
        "\n",
        "    answer_item_degree = item_degree[item_degree['item_id'].isin(answer_items)]\n",
        "    list_item_degress = answer_item_degree['degree'].values.tolist()\n",
        "    median_item_degree = list_item_degress[len(list_item_degress) // 2]\n",
        "    item_degree_map = dict(zip(item_degree['item_id'], item_degree['degree']))\n",
        "    num_cases_half = answer_item_degree[answer_item_degree['degree']<= median_item_degree].shape[0]\n",
        "\n",
        "    ndcg_50_full, hitrate_50_full, ndcg_50_half, hitrate_50_half = evaluate(\n",
        "        df, median_item_degree, item_degree_map, num_cases_full, num_cases_half)\n",
        "    return ndcg_50_full, hitrate_50_full, ndcg_50_half, hitrate_50_half"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWNtAr7aUW0E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "99c13a29-4d5e-44a9-f511-1c13ae96d635"
      },
      "source": [
        "item_sim_phase = {}\n",
        "df_recall = pd.DataFrame()\n",
        "val_score = np.array([0.0, 0.0, 0.0, 0.0])\n",
        "for phase in phases:\n",
        "    f = open('kdd2020_data/my_model/recall_2/sim_{}.pkl'.format(phase), 'rb')\n",
        "    item_sim = pickle.load(f)\n",
        "    f.close()\n",
        "\n",
        "    df_data = pd.read_pickle('kdd2020_data/my_model/recall_2/recall_{}.pkl'.format(phase))\n",
        "\n",
        "    item_sim_phase[phase] = item_sim\n",
        "    df_recall = df_recall.append(df_data)\n",
        "\n",
        "    score = evaluate_scores(df_data, phase)\n",
        "    val_score += score\n",
        "\n",
        "    print('phase', phase, score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18505/18505 [00:19<00:00, 948.77it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "phase 0 (0.049057716332143474, 0.10996318726992044, 0.0229912553375824, 0.0649183147033534)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18672/18672 [00:19<00:00, 946.03it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "phase 1 (0.05058691751623233, 0.11141272276643456, 0.023137793927580964, 0.06182602444284687)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18398/18398 [00:19<00:00, 957.64it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "phase 2 (0.05110817778025587, 0.11503471390950443, 0.022897075829062, 0.06420118343195266)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUzR-WuMVY9h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c4b77288-7cac-427f-eafb-562a560c0c27"
      },
      "source": [
        "f = open('kdd2020_data/my_model/sim2.pkl', 'wb')\n",
        "pickle.dump(item_sim_phase, f)\n",
        "f.close()\n",
        "val_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.15075281, 0.33641062, 0.06902613, 0.19094552])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAxDDa8VVjnr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b058cf9a-6d4f-4ddc-a09e-96e7cf8aa852"
      },
      "source": [
        "df_recall.sort_values(['user_id', 'phase', 'query_time'], inplace=True)\n",
        "df_recall.to_pickle('kdd2020_data/my_model/recall_2.pkl')\n",
        "df_recall.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>phase</th>\n",
              "      <th>query_time</th>\n",
              "      <th>item_id</th>\n",
              "      <th>sim_score</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>87837</td>\n",
              "      <td>0.3453144185</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>19228</td>\n",
              "      <td>0.3453144185</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>109854</td>\n",
              "      <td>0.3453144185</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>55738</td>\n",
              "      <td>0.3453144185</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>91290</td>\n",
              "      <td>0.3453144185</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  phase    query_time  item_id     sim_score  label\n",
              "0        1    0.0  0.9839419315    87837  0.3453144185    0.0\n",
              "2        1    0.0  0.9839419315    19228  0.3453144185    0.0\n",
              "3        1    0.0  0.9839419315   109854  0.3453144185    0.0\n",
              "4        1    0.0  0.9839419315    55738  0.3453144185    0.0\n",
              "1        1    0.0  0.9839419315    91290  0.3453144185    0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vf-ZVDubV6iZ",
        "colab_type": "text"
      },
      "source": [
        "# Recall_3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cojPSIwWD1J",
        "colab_type": "text"
      },
      "source": [
        "* get item txt  embedding\n",
        "* calculate distance by annoy\n",
        "\n",
        "[know more about annoy](https://github.com/spotify/annoy)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpAsK78xWC1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install annoy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADX2NbC6V5pG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from annoy import AnnoyIndex\n",
        "import os\n",
        "import warnings\n",
        "import multitasking\n",
        "import signal\n",
        "\n",
        "multitasking.set_max_threads(10)\n",
        "multitasking.set_engine('process')\n",
        "signal.signal(signal.SIGINT, multitasking.killall)\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('precision', 10)\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhzhYyaRa1SA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_qtime = pd.read_pickle('kdd2020_data/recall/qtime.pkl')\n",
        "df_click = pd.read_pickle('kdd2020_data/recall/click.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCT-vEU9bDXi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b19cc65a-a094-4c5e-fa28-16c3838226d3"
      },
      "source": [
        "phases = sorted(list(df_qtime['phase'].unique()))\n",
        "phases"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQQv0QpUbGYb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "badba74b-bef9-4965-bdac-433a2388f2a3"
      },
      "source": [
        "df_item = pd.read_csv('kdd2020_data/underexpose_train/underexpose_item_feat.csv',header=None)\n",
        "df_item.columns = ['item_id'] + ['txt_vec' + str(i) for i in range(128)] + ['img_vec' + str(i) for i in range(128)]\n",
        "df_item['txt_vec0'] = df_item['txt_vec0'].apply(lambda x: float(x[1:]))\n",
        "df_item['txt_vec127'] = df_item['txt_vec127'].apply(lambda x: float(x[:-1]))\n",
        "df_item['img_vec0'] = df_item['img_vec0'].apply(lambda x: float(x[1:]))\n",
        "df_item['img_vec127'] = df_item['img_vec127'].apply(lambda x: float(x[:-1]))\n",
        "df_item.drop_duplicates(['item_id'], inplace=True)\n",
        "df_item.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_id</th>\n",
              "      <th>txt_vec0</th>\n",
              "      <th>txt_vec1</th>\n",
              "      <th>txt_vec2</th>\n",
              "      <th>txt_vec3</th>\n",
              "      <th>txt_vec4</th>\n",
              "      <th>txt_vec5</th>\n",
              "      <th>txt_vec6</th>\n",
              "      <th>txt_vec7</th>\n",
              "      <th>txt_vec8</th>\n",
              "      <th>txt_vec9</th>\n",
              "      <th>txt_vec10</th>\n",
              "      <th>txt_vec11</th>\n",
              "      <th>txt_vec12</th>\n",
              "      <th>txt_vec13</th>\n",
              "      <th>txt_vec14</th>\n",
              "      <th>txt_vec15</th>\n",
              "      <th>txt_vec16</th>\n",
              "      <th>txt_vec17</th>\n",
              "      <th>txt_vec18</th>\n",
              "      <th>txt_vec19</th>\n",
              "      <th>txt_vec20</th>\n",
              "      <th>txt_vec21</th>\n",
              "      <th>txt_vec22</th>\n",
              "      <th>txt_vec23</th>\n",
              "      <th>txt_vec24</th>\n",
              "      <th>txt_vec25</th>\n",
              "      <th>txt_vec26</th>\n",
              "      <th>txt_vec27</th>\n",
              "      <th>txt_vec28</th>\n",
              "      <th>txt_vec29</th>\n",
              "      <th>txt_vec30</th>\n",
              "      <th>txt_vec31</th>\n",
              "      <th>txt_vec32</th>\n",
              "      <th>txt_vec33</th>\n",
              "      <th>txt_vec34</th>\n",
              "      <th>txt_vec35</th>\n",
              "      <th>txt_vec36</th>\n",
              "      <th>txt_vec37</th>\n",
              "      <th>txt_vec38</th>\n",
              "      <th>txt_vec39</th>\n",
              "      <th>txt_vec40</th>\n",
              "      <th>txt_vec41</th>\n",
              "      <th>txt_vec42</th>\n",
              "      <th>txt_vec43</th>\n",
              "      <th>txt_vec44</th>\n",
              "      <th>txt_vec45</th>\n",
              "      <th>txt_vec46</th>\n",
              "      <th>txt_vec47</th>\n",
              "      <th>txt_vec48</th>\n",
              "      <th>txt_vec49</th>\n",
              "      <th>txt_vec50</th>\n",
              "      <th>txt_vec51</th>\n",
              "      <th>txt_vec52</th>\n",
              "      <th>txt_vec53</th>\n",
              "      <th>txt_vec54</th>\n",
              "      <th>txt_vec55</th>\n",
              "      <th>txt_vec56</th>\n",
              "      <th>txt_vec57</th>\n",
              "      <th>txt_vec58</th>\n",
              "      <th>txt_vec59</th>\n",
              "      <th>txt_vec60</th>\n",
              "      <th>txt_vec61</th>\n",
              "      <th>txt_vec62</th>\n",
              "      <th>txt_vec63</th>\n",
              "      <th>txt_vec64</th>\n",
              "      <th>txt_vec65</th>\n",
              "      <th>txt_vec66</th>\n",
              "      <th>txt_vec67</th>\n",
              "      <th>txt_vec68</th>\n",
              "      <th>txt_vec69</th>\n",
              "      <th>txt_vec70</th>\n",
              "      <th>txt_vec71</th>\n",
              "      <th>txt_vec72</th>\n",
              "      <th>txt_vec73</th>\n",
              "      <th>txt_vec74</th>\n",
              "      <th>txt_vec75</th>\n",
              "      <th>txt_vec76</th>\n",
              "      <th>txt_vec77</th>\n",
              "      <th>txt_vec78</th>\n",
              "      <th>txt_vec79</th>\n",
              "      <th>txt_vec80</th>\n",
              "      <th>txt_vec81</th>\n",
              "      <th>txt_vec82</th>\n",
              "      <th>txt_vec83</th>\n",
              "      <th>txt_vec84</th>\n",
              "      <th>txt_vec85</th>\n",
              "      <th>txt_vec86</th>\n",
              "      <th>txt_vec87</th>\n",
              "      <th>txt_vec88</th>\n",
              "      <th>txt_vec89</th>\n",
              "      <th>txt_vec90</th>\n",
              "      <th>txt_vec91</th>\n",
              "      <th>txt_vec92</th>\n",
              "      <th>txt_vec93</th>\n",
              "      <th>txt_vec94</th>\n",
              "      <th>txt_vec95</th>\n",
              "      <th>txt_vec96</th>\n",
              "      <th>txt_vec97</th>\n",
              "      <th>txt_vec98</th>\n",
              "      <th>txt_vec99</th>\n",
              "      <th>txt_vec100</th>\n",
              "      <th>txt_vec101</th>\n",
              "      <th>txt_vec102</th>\n",
              "      <th>txt_vec103</th>\n",
              "      <th>txt_vec104</th>\n",
              "      <th>txt_vec105</th>\n",
              "      <th>txt_vec106</th>\n",
              "      <th>txt_vec107</th>\n",
              "      <th>txt_vec108</th>\n",
              "      <th>txt_vec109</th>\n",
              "      <th>txt_vec110</th>\n",
              "      <th>txt_vec111</th>\n",
              "      <th>txt_vec112</th>\n",
              "      <th>txt_vec113</th>\n",
              "      <th>txt_vec114</th>\n",
              "      <th>txt_vec115</th>\n",
              "      <th>txt_vec116</th>\n",
              "      <th>txt_vec117</th>\n",
              "      <th>txt_vec118</th>\n",
              "      <th>txt_vec119</th>\n",
              "      <th>txt_vec120</th>\n",
              "      <th>txt_vec121</th>\n",
              "      <th>txt_vec122</th>\n",
              "      <th>txt_vec123</th>\n",
              "      <th>txt_vec124</th>\n",
              "      <th>txt_vec125</th>\n",
              "      <th>txt_vec126</th>\n",
              "      <th>txt_vec127</th>\n",
              "      <th>img_vec0</th>\n",
              "      <th>img_vec1</th>\n",
              "      <th>img_vec2</th>\n",
              "      <th>img_vec3</th>\n",
              "      <th>img_vec4</th>\n",
              "      <th>img_vec5</th>\n",
              "      <th>img_vec6</th>\n",
              "      <th>img_vec7</th>\n",
              "      <th>img_vec8</th>\n",
              "      <th>img_vec9</th>\n",
              "      <th>img_vec10</th>\n",
              "      <th>img_vec11</th>\n",
              "      <th>img_vec12</th>\n",
              "      <th>img_vec13</th>\n",
              "      <th>img_vec14</th>\n",
              "      <th>img_vec15</th>\n",
              "      <th>img_vec16</th>\n",
              "      <th>img_vec17</th>\n",
              "      <th>img_vec18</th>\n",
              "      <th>img_vec19</th>\n",
              "      <th>img_vec20</th>\n",
              "      <th>img_vec21</th>\n",
              "      <th>img_vec22</th>\n",
              "      <th>img_vec23</th>\n",
              "      <th>img_vec24</th>\n",
              "      <th>img_vec25</th>\n",
              "      <th>img_vec26</th>\n",
              "      <th>img_vec27</th>\n",
              "      <th>img_vec28</th>\n",
              "      <th>img_vec29</th>\n",
              "      <th>img_vec30</th>\n",
              "      <th>img_vec31</th>\n",
              "      <th>img_vec32</th>\n",
              "      <th>img_vec33</th>\n",
              "      <th>img_vec34</th>\n",
              "      <th>img_vec35</th>\n",
              "      <th>img_vec36</th>\n",
              "      <th>img_vec37</th>\n",
              "      <th>img_vec38</th>\n",
              "      <th>img_vec39</th>\n",
              "      <th>img_vec40</th>\n",
              "      <th>img_vec41</th>\n",
              "      <th>img_vec42</th>\n",
              "      <th>img_vec43</th>\n",
              "      <th>img_vec44</th>\n",
              "      <th>img_vec45</th>\n",
              "      <th>img_vec46</th>\n",
              "      <th>img_vec47</th>\n",
              "      <th>img_vec48</th>\n",
              "      <th>img_vec49</th>\n",
              "      <th>img_vec50</th>\n",
              "      <th>img_vec51</th>\n",
              "      <th>img_vec52</th>\n",
              "      <th>img_vec53</th>\n",
              "      <th>img_vec54</th>\n",
              "      <th>img_vec55</th>\n",
              "      <th>img_vec56</th>\n",
              "      <th>img_vec57</th>\n",
              "      <th>img_vec58</th>\n",
              "      <th>img_vec59</th>\n",
              "      <th>img_vec60</th>\n",
              "      <th>img_vec61</th>\n",
              "      <th>img_vec62</th>\n",
              "      <th>img_vec63</th>\n",
              "      <th>img_vec64</th>\n",
              "      <th>img_vec65</th>\n",
              "      <th>img_vec66</th>\n",
              "      <th>img_vec67</th>\n",
              "      <th>img_vec68</th>\n",
              "      <th>img_vec69</th>\n",
              "      <th>img_vec70</th>\n",
              "      <th>img_vec71</th>\n",
              "      <th>img_vec72</th>\n",
              "      <th>img_vec73</th>\n",
              "      <th>img_vec74</th>\n",
              "      <th>img_vec75</th>\n",
              "      <th>img_vec76</th>\n",
              "      <th>img_vec77</th>\n",
              "      <th>img_vec78</th>\n",
              "      <th>img_vec79</th>\n",
              "      <th>img_vec80</th>\n",
              "      <th>img_vec81</th>\n",
              "      <th>img_vec82</th>\n",
              "      <th>img_vec83</th>\n",
              "      <th>img_vec84</th>\n",
              "      <th>img_vec85</th>\n",
              "      <th>img_vec86</th>\n",
              "      <th>img_vec87</th>\n",
              "      <th>img_vec88</th>\n",
              "      <th>img_vec89</th>\n",
              "      <th>img_vec90</th>\n",
              "      <th>img_vec91</th>\n",
              "      <th>img_vec92</th>\n",
              "      <th>img_vec93</th>\n",
              "      <th>img_vec94</th>\n",
              "      <th>img_vec95</th>\n",
              "      <th>img_vec96</th>\n",
              "      <th>img_vec97</th>\n",
              "      <th>img_vec98</th>\n",
              "      <th>img_vec99</th>\n",
              "      <th>img_vec100</th>\n",
              "      <th>img_vec101</th>\n",
              "      <th>img_vec102</th>\n",
              "      <th>img_vec103</th>\n",
              "      <th>img_vec104</th>\n",
              "      <th>img_vec105</th>\n",
              "      <th>img_vec106</th>\n",
              "      <th>img_vec107</th>\n",
              "      <th>img_vec108</th>\n",
              "      <th>img_vec109</th>\n",
              "      <th>img_vec110</th>\n",
              "      <th>img_vec111</th>\n",
              "      <th>img_vec112</th>\n",
              "      <th>img_vec113</th>\n",
              "      <th>img_vec114</th>\n",
              "      <th>img_vec115</th>\n",
              "      <th>img_vec116</th>\n",
              "      <th>img_vec117</th>\n",
              "      <th>img_vec118</th>\n",
              "      <th>img_vec119</th>\n",
              "      <th>img_vec120</th>\n",
              "      <th>img_vec121</th>\n",
              "      <th>img_vec122</th>\n",
              "      <th>img_vec123</th>\n",
              "      <th>img_vec124</th>\n",
              "      <th>img_vec125</th>\n",
              "      <th>img_vec126</th>\n",
              "      <th>img_vec127</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>42844</td>\n",
              "      <td>4.5149450302</td>\n",
              "      <td>-2.3837196827</td>\n",
              "      <td>0.5004140139</td>\n",
              "      <td>0.4070682824</td>\n",
              "      <td>-1.9952288866</td>\n",
              "      <td>0.1090780124</td>\n",
              "      <td>-0.6917753220</td>\n",
              "      <td>2.2274599075</td>\n",
              "      <td>-6.4379744530</td>\n",
              "      <td>-0.8248971701</td>\n",
              "      <td>-0.1387242377</td>\n",
              "      <td>-0.3793291748</td>\n",
              "      <td>0.6276600957</td>\n",
              "      <td>0.4183767140</td>\n",
              "      <td>4.4412183762</td>\n",
              "      <td>0.2998193502</td>\n",
              "      <td>0.5785568357</td>\n",
              "      <td>-4.6992893219</td>\n",
              "      <td>-0.3947401643</td>\n",
              "      <td>-2.3916513920</td>\n",
              "      <td>0.3705316782</td>\n",
              "      <td>-1.3554661274</td>\n",
              "      <td>-1.0741775036</td>\n",
              "      <td>-2.3216402531</td>\n",
              "      <td>-0.3324561715</td>\n",
              "      <td>0.1238859445</td>\n",
              "      <td>-2.4391555786</td>\n",
              "      <td>-0.3455986977</td>\n",
              "      <td>-3.3043470383</td>\n",
              "      <td>1.4852843285</td>\n",
              "      <td>0.9098017812</td>\n",
              "      <td>-1.6430019140</td>\n",
              "      <td>5.0370340347</td>\n",
              "      <td>2.7801148891</td>\n",
              "      <td>4.7764964104</td>\n",
              "      <td>2.2552747726</td>\n",
              "      <td>3.7697074413</td>\n",
              "      <td>-3.6616835594</td>\n",
              "      <td>-0.6494054794</td>\n",
              "      <td>4.1996359825</td>\n",
              "      <td>-0.6348056197</td>\n",
              "      <td>2.4303400517</td>\n",
              "      <td>-2.8740186691</td>\n",
              "      <td>-0.7861775160</td>\n",
              "      <td>-0.5049162507</td>\n",
              "      <td>-6.0077886581</td>\n",
              "      <td>1.4984948635</td>\n",
              "      <td>1.5306128263</td>\n",
              "      <td>2.3796546459</td>\n",
              "      <td>-0.0231464375</td>\n",
              "      <td>-0.7036052942</td>\n",
              "      <td>2.1469361782</td>\n",
              "      <td>3.9448320866</td>\n",
              "      <td>-3.0985984802</td>\n",
              "      <td>2.5134534836</td>\n",
              "      <td>-5.3958601952</td>\n",
              "      <td>0.7621323466</td>\n",
              "      <td>2.8018035889</td>\n",
              "      <td>0.8779643178</td>\n",
              "      <td>-0.5859798193</td>\n",
              "      <td>1.9625556469</td>\n",
              "      <td>-5.1712174416</td>\n",
              "      <td>1.1816873550</td>\n",
              "      <td>0.5419528484</td>\n",
              "      <td>0.4858333170</td>\n",
              "      <td>4.2125682831</td>\n",
              "      <td>3.4581983089</td>\n",
              "      <td>1.4029390812</td>\n",
              "      <td>-0.5462926030</td>\n",
              "      <td>2.1821005344</td>\n",
              "      <td>-0.0962546766</td>\n",
              "      <td>1.7366081476</td>\n",
              "      <td>0.6851462722</td>\n",
              "      <td>-1.6132848263</td>\n",
              "      <td>-0.9128761888</td>\n",
              "      <td>-0.5323970318</td>\n",
              "      <td>1.7248421907</td>\n",
              "      <td>2.2641146183</td>\n",
              "      <td>-2.2597558498</td>\n",
              "      <td>4.5065088272</td>\n",
              "      <td>-0.3460883200</td>\n",
              "      <td>0.9281976819</td>\n",
              "      <td>-2.0782611370</td>\n",
              "      <td>-0.1955756247</td>\n",
              "      <td>4.8475780487</td>\n",
              "      <td>-2.9586863518</td>\n",
              "      <td>1.0060796738</td>\n",
              "      <td>2.0822322369</td>\n",
              "      <td>-2.2596824169</td>\n",
              "      <td>-2.0333144665</td>\n",
              "      <td>0.2182324231</td>\n",
              "      <td>3.9753122330</td>\n",
              "      <td>2.0034470558</td>\n",
              "      <td>-0.2406283617</td>\n",
              "      <td>-2.4685480595</td>\n",
              "      <td>1.6660641432</td>\n",
              "      <td>-2.0819606781</td>\n",
              "      <td>-2.4968724251</td>\n",
              "      <td>-1.9016369581</td>\n",
              "      <td>0.2714739740</td>\n",
              "      <td>-2.2981684208</td>\n",
              "      <td>-1.7873090506</td>\n",
              "      <td>1.6180669069</td>\n",
              "      <td>-2.9975774288</td>\n",
              "      <td>0.0420643799</td>\n",
              "      <td>-1.2196398973</td>\n",
              "      <td>-2.3956730366</td>\n",
              "      <td>5.6090831757</td>\n",
              "      <td>-1.4914845228</td>\n",
              "      <td>1.7885915041</td>\n",
              "      <td>4.1772522926</td>\n",
              "      <td>4.4608173370</td>\n",
              "      <td>-1.2361496687</td>\n",
              "      <td>-2.0794692039</td>\n",
              "      <td>-4.3971495628</td>\n",
              "      <td>0.3652189076</td>\n",
              "      <td>0.8151836395</td>\n",
              "      <td>5.4751114845</td>\n",
              "      <td>4.2397766113</td>\n",
              "      <td>0.9392179847</td>\n",
              "      <td>1.1986280680</td>\n",
              "      <td>-1.4769824743</td>\n",
              "      <td>-1.5552177429</td>\n",
              "      <td>0.3611471355</td>\n",
              "      <td>2.0227699280</td>\n",
              "      <td>-1.5996438265</td>\n",
              "      <td>3.2231538296</td>\n",
              "      <td>-1.4574943781</td>\n",
              "      <td>-2.8722801208</td>\n",
              "      <td>1.4587551355</td>\n",
              "      <td>2.5790126324</td>\n",
              "      <td>-1.6097468138</td>\n",
              "      <td>1.4378223419</td>\n",
              "      <td>1.3874959946</td>\n",
              "      <td>0.7249992490</td>\n",
              "      <td>0.0203323103</td>\n",
              "      <td>0.3120986819</td>\n",
              "      <td>-1.9997732639</td>\n",
              "      <td>-1.8057322502</td>\n",
              "      <td>-0.1739237309</td>\n",
              "      <td>-2.1751496792</td>\n",
              "      <td>-0.4395467937</td>\n",
              "      <td>-1.8935351372</td>\n",
              "      <td>-0.7034621835</td>\n",
              "      <td>-1.9535105228</td>\n",
              "      <td>0.6914859414</td>\n",
              "      <td>0.6445956826</td>\n",
              "      <td>2.0112810135</td>\n",
              "      <td>-0.4342123568</td>\n",
              "      <td>2.6146309376</td>\n",
              "      <td>2.1234035492</td>\n",
              "      <td>-2.8775033951</td>\n",
              "      <td>1.0714125633</td>\n",
              "      <td>0.4730164111</td>\n",
              "      <td>2.4707813263</td>\n",
              "      <td>-1.6296484470</td>\n",
              "      <td>-2.5948154926</td>\n",
              "      <td>2.1294517517</td>\n",
              "      <td>-1.0729905367</td>\n",
              "      <td>2.4951767921</td>\n",
              "      <td>-0.6153161526</td>\n",
              "      <td>-0.3726658523</td>\n",
              "      <td>1.4416368008</td>\n",
              "      <td>-0.3869579732</td>\n",
              "      <td>0.5742669106</td>\n",
              "      <td>0.2901403606</td>\n",
              "      <td>2.1439840794</td>\n",
              "      <td>-2.1797549725</td>\n",
              "      <td>1.0018137693</td>\n",
              "      <td>1.7092645168</td>\n",
              "      <td>1.7659958601</td>\n",
              "      <td>-0.9781475067</td>\n",
              "      <td>2.3762657642</td>\n",
              "      <td>1.2863856554</td>\n",
              "      <td>-1.4987120628</td>\n",
              "      <td>-2.1206870079</td>\n",
              "      <td>-1.6261025667</td>\n",
              "      <td>-1.7383675575</td>\n",
              "      <td>-0.2232712805</td>\n",
              "      <td>1.2644373178</td>\n",
              "      <td>-0.9871305823</td>\n",
              "      <td>-1.9093743563</td>\n",
              "      <td>2.2314555645</td>\n",
              "      <td>-2.6836464405</td>\n",
              "      <td>-0.6353181005</td>\n",
              "      <td>0.0858888105</td>\n",
              "      <td>-0.8235075474</td>\n",
              "      <td>0.5569828153</td>\n",
              "      <td>2.5153543949</td>\n",
              "      <td>-3.4205298424</td>\n",
              "      <td>0.0634656399</td>\n",
              "      <td>0.0094741732</td>\n",
              "      <td>-0.0657508075</td>\n",
              "      <td>-1.0753654242</td>\n",
              "      <td>-2.9713089466</td>\n",
              "      <td>1.0196198225</td>\n",
              "      <td>2.5095589161</td>\n",
              "      <td>-1.5258373022</td>\n",
              "      <td>0.5425801277</td>\n",
              "      <td>-0.2697300315</td>\n",
              "      <td>-0.0359621942</td>\n",
              "      <td>0.3917995691</td>\n",
              "      <td>-1.2341160774</td>\n",
              "      <td>2.3140294552</td>\n",
              "      <td>1.8986169100</td>\n",
              "      <td>-2.3611283302</td>\n",
              "      <td>0.3124046326</td>\n",
              "      <td>3.4446072578</td>\n",
              "      <td>-0.8862501383</td>\n",
              "      <td>-1.3436369896</td>\n",
              "      <td>0.9544589520</td>\n",
              "      <td>0.6308349371</td>\n",
              "      <td>-2.3947217464</td>\n",
              "      <td>0.6834869981</td>\n",
              "      <td>1.1490038633</td>\n",
              "      <td>-1.3511732817</td>\n",
              "      <td>2.0239000320</td>\n",
              "      <td>1.5991983414</td>\n",
              "      <td>1.3828682899</td>\n",
              "      <td>1.6056783199</td>\n",
              "      <td>1.8806668520</td>\n",
              "      <td>-0.5081608891</td>\n",
              "      <td>0.2428404391</td>\n",
              "      <td>-0.2608487904</td>\n",
              "      <td>1.8759434223</td>\n",
              "      <td>0.2061345726</td>\n",
              "      <td>0.1869730353</td>\n",
              "      <td>2.0474455357</td>\n",
              "      <td>-0.5754722953</td>\n",
              "      <td>3.0164101124</td>\n",
              "      <td>2.7571456432</td>\n",
              "      <td>3.3537209034</td>\n",
              "      <td>-0.4572715461</td>\n",
              "      <td>-0.1253366172</td>\n",
              "      <td>2.3329634666</td>\n",
              "      <td>3.8589668274</td>\n",
              "      <td>-2.0754899979</td>\n",
              "      <td>-0.7054958344</td>\n",
              "      <td>0.2034520507</td>\n",
              "      <td>1.7197328806</td>\n",
              "      <td>2.9250385761</td>\n",
              "      <td>-0.3886387944</td>\n",
              "      <td>1.2257323265</td>\n",
              "      <td>-1.7731370926</td>\n",
              "      <td>0.0526551157</td>\n",
              "      <td>1.2799222469</td>\n",
              "      <td>-3.3747272491</td>\n",
              "      <td>-1.5069689751</td>\n",
              "      <td>-1.8201801777</td>\n",
              "      <td>-3.0246436596</td>\n",
              "      <td>0.4452633858</td>\n",
              "      <td>0.0139333047</td>\n",
              "      <td>-1.3002386093</td>\n",
              "      <td>2.7599484921</td>\n",
              "      <td>2.0561711788</td>\n",
              "      <td>0.5087034702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>67898</td>\n",
              "      <td>-2.0029051304</td>\n",
              "      <td>-0.9298805594</td>\n",
              "      <td>0.7900167108</td>\n",
              "      <td>-1.3808951378</td>\n",
              "      <td>-0.5104627609</td>\n",
              "      <td>-1.8100957870</td>\n",
              "      <td>1.3639619350</td>\n",
              "      <td>0.4974010289</td>\n",
              "      <td>-4.0389027596</td>\n",
              "      <td>-3.0578715801</td>\n",
              "      <td>0.7585576773</td>\n",
              "      <td>-1.0121546984</td>\n",
              "      <td>2.8168015480</td>\n",
              "      <td>2.0868949890</td>\n",
              "      <td>-1.4643309116</td>\n",
              "      <td>-1.8404960632</td>\n",
              "      <td>-2.0899708271</td>\n",
              "      <td>-1.5668717623</td>\n",
              "      <td>1.5453896523</td>\n",
              "      <td>1.2843413353</td>\n",
              "      <td>-2.2702617645</td>\n",
              "      <td>0.7801263332</td>\n",
              "      <td>1.6155936718</td>\n",
              "      <td>-0.5460581183</td>\n",
              "      <td>1.3707500696</td>\n",
              "      <td>-1.1781235933</td>\n",
              "      <td>1.3468424082</td>\n",
              "      <td>0.4424336255</td>\n",
              "      <td>-1.4985396862</td>\n",
              "      <td>-0.5899440646</td>\n",
              "      <td>2.0083506107</td>\n",
              "      <td>-0.4971346855</td>\n",
              "      <td>-1.6442297697</td>\n",
              "      <td>3.1406233311</td>\n",
              "      <td>3.4921784401</td>\n",
              "      <td>0.3353945315</td>\n",
              "      <td>1.8109228611</td>\n",
              "      <td>-4.0120801926</td>\n",
              "      <td>2.4195928574</td>\n",
              "      <td>0.1909409761</td>\n",
              "      <td>-0.6306105256</td>\n",
              "      <td>3.2893316746</td>\n",
              "      <td>-1.4467194080</td>\n",
              "      <td>-0.6113395691</td>\n",
              "      <td>0.7006615996</td>\n",
              "      <td>-2.4656562805</td>\n",
              "      <td>-0.5967733860</td>\n",
              "      <td>2.4982099533</td>\n",
              "      <td>3.6829156876</td>\n",
              "      <td>0.2388433963</td>\n",
              "      <td>0.5705102682</td>\n",
              "      <td>0.0946367979</td>\n",
              "      <td>2.5407283306</td>\n",
              "      <td>-1.4612874985</td>\n",
              "      <td>0.8664698601</td>\n",
              "      <td>-0.8825763464</td>\n",
              "      <td>-1.6469770670</td>\n",
              "      <td>1.9151748419</td>\n",
              "      <td>2.8002102375</td>\n",
              "      <td>1.4765350819</td>\n",
              "      <td>2.3451476097</td>\n",
              "      <td>-1.6753772497</td>\n",
              "      <td>-2.9482414722</td>\n",
              "      <td>4.3225460052</td>\n",
              "      <td>0.0064851381</td>\n",
              "      <td>1.5961343050</td>\n",
              "      <td>1.7408252954</td>\n",
              "      <td>2.5171482563</td>\n",
              "      <td>1.6526031494</td>\n",
              "      <td>2.3012015820</td>\n",
              "      <td>-1.8203756809</td>\n",
              "      <td>0.3131376207</td>\n",
              "      <td>-0.4605118036</td>\n",
              "      <td>-1.4658217430</td>\n",
              "      <td>0.0256607905</td>\n",
              "      <td>0.1975094974</td>\n",
              "      <td>0.9521799088</td>\n",
              "      <td>1.8086135387</td>\n",
              "      <td>-3.9243142605</td>\n",
              "      <td>0.8740619421</td>\n",
              "      <td>1.5076384544</td>\n",
              "      <td>-1.4749593735</td>\n",
              "      <td>-0.7281465530</td>\n",
              "      <td>1.6809406281</td>\n",
              "      <td>-2.2752487659</td>\n",
              "      <td>0.1606744528</td>\n",
              "      <td>-1.1758519411</td>\n",
              "      <td>2.7073900700</td>\n",
              "      <td>-1.5404677391</td>\n",
              "      <td>-1.7555799484</td>\n",
              "      <td>1.2667036057</td>\n",
              "      <td>0.5049359202</td>\n",
              "      <td>1.0696272850</td>\n",
              "      <td>1.8924552202</td>\n",
              "      <td>-2.8700709343</td>\n",
              "      <td>1.3147110939</td>\n",
              "      <td>-0.6476105452</td>\n",
              "      <td>-3.8642375469</td>\n",
              "      <td>-1.1287094355</td>\n",
              "      <td>-0.2163546234</td>\n",
              "      <td>0.0200870410</td>\n",
              "      <td>-1.0009949207</td>\n",
              "      <td>1.8183261156</td>\n",
              "      <td>-1.2894283533</td>\n",
              "      <td>1.3204821348</td>\n",
              "      <td>0.9189465046</td>\n",
              "      <td>2.3127784729</td>\n",
              "      <td>0.9761807323</td>\n",
              "      <td>-1.1034594774</td>\n",
              "      <td>-1.2471879721</td>\n",
              "      <td>-2.9002075195</td>\n",
              "      <td>1.2914571762</td>\n",
              "      <td>1.5193878412</td>\n",
              "      <td>-0.8292294741</td>\n",
              "      <td>-2.4343063831</td>\n",
              "      <td>-0.7656114101</td>\n",
              "      <td>0.6017384529</td>\n",
              "      <td>3.1130170822</td>\n",
              "      <td>0.7010914087</td>\n",
              "      <td>0.5787922144</td>\n",
              "      <td>0.5351995230</td>\n",
              "      <td>-0.9441672564</td>\n",
              "      <td>-0.1240377501</td>\n",
              "      <td>-1.4508235455</td>\n",
              "      <td>0.3650854230</td>\n",
              "      <td>-1.1901761293</td>\n",
              "      <td>1.6859598160</td>\n",
              "      <td>0.8126941919</td>\n",
              "      <td>-0.0705208853</td>\n",
              "      <td>-1.4393335581</td>\n",
              "      <td>0.7728728056</td>\n",
              "      <td>-2.3489952087</td>\n",
              "      <td>-0.2355124950</td>\n",
              "      <td>-0.8700022697</td>\n",
              "      <td>-0.5425865054</td>\n",
              "      <td>1.5831973553</td>\n",
              "      <td>1.7427791357</td>\n",
              "      <td>-2.9939756393</td>\n",
              "      <td>-0.8622460961</td>\n",
              "      <td>-1.2157950401</td>\n",
              "      <td>-2.3686754704</td>\n",
              "      <td>2.3326988220</td>\n",
              "      <td>1.9421590567</td>\n",
              "      <td>1.1301317215</td>\n",
              "      <td>-2.5715732574</td>\n",
              "      <td>2.0020222664</td>\n",
              "      <td>3.8542828560</td>\n",
              "      <td>-0.4467480779</td>\n",
              "      <td>0.3667028844</td>\n",
              "      <td>0.3724231422</td>\n",
              "      <td>-1.9866981506</td>\n",
              "      <td>-0.1244335026</td>\n",
              "      <td>-2.7045094967</td>\n",
              "      <td>-2.9197115898</td>\n",
              "      <td>-3.0368967056</td>\n",
              "      <td>-1.1918561459</td>\n",
              "      <td>-2.3457062244</td>\n",
              "      <td>1.7503809929</td>\n",
              "      <td>-0.7577392459</td>\n",
              "      <td>0.7082000375</td>\n",
              "      <td>-2.0362606049</td>\n",
              "      <td>-1.2478457689</td>\n",
              "      <td>1.3371763229</td>\n",
              "      <td>0.3810861111</td>\n",
              "      <td>-2.1957163811</td>\n",
              "      <td>2.3492677212</td>\n",
              "      <td>3.2342376709</td>\n",
              "      <td>-1.0737447739</td>\n",
              "      <td>2.7275660038</td>\n",
              "      <td>2.1341414452</td>\n",
              "      <td>1.3165485859</td>\n",
              "      <td>1.4014288187</td>\n",
              "      <td>0.3226478398</td>\n",
              "      <td>1.5204454660</td>\n",
              "      <td>-1.5553992987</td>\n",
              "      <td>-1.7593723536</td>\n",
              "      <td>-0.5223306417</td>\n",
              "      <td>-2.0628519058</td>\n",
              "      <td>1.2358421087</td>\n",
              "      <td>0.1661762446</td>\n",
              "      <td>-3.3796861172</td>\n",
              "      <td>-2.2228477001</td>\n",
              "      <td>1.6136515141</td>\n",
              "      <td>0.7360733747</td>\n",
              "      <td>-2.1893527508</td>\n",
              "      <td>1.2845479250</td>\n",
              "      <td>2.8726134300</td>\n",
              "      <td>2.6761150360</td>\n",
              "      <td>0.1475290209</td>\n",
              "      <td>-1.3171087503</td>\n",
              "      <td>-2.6440515518</td>\n",
              "      <td>-1.8350887299</td>\n",
              "      <td>0.9574174285</td>\n",
              "      <td>-2.3858914375</td>\n",
              "      <td>-0.6619012356</td>\n",
              "      <td>2.6582648754</td>\n",
              "      <td>-0.9451054931</td>\n",
              "      <td>-1.0119893551</td>\n",
              "      <td>-0.6547811627</td>\n",
              "      <td>-0.3363517821</td>\n",
              "      <td>-2.1268010139</td>\n",
              "      <td>1.3375129700</td>\n",
              "      <td>-1.0618399382</td>\n",
              "      <td>0.4118506312</td>\n",
              "      <td>0.2462557554</td>\n",
              "      <td>-2.2640297413</td>\n",
              "      <td>2.3994200230</td>\n",
              "      <td>2.0248627663</td>\n",
              "      <td>0.1704825163</td>\n",
              "      <td>-0.0392032042</td>\n",
              "      <td>-1.5066767931</td>\n",
              "      <td>-1.9459319115</td>\n",
              "      <td>-0.0202283077</td>\n",
              "      <td>-0.4954991639</td>\n",
              "      <td>-0.1410129666</td>\n",
              "      <td>-1.6175206900</td>\n",
              "      <td>2.6246759892</td>\n",
              "      <td>-2.5819215775</td>\n",
              "      <td>0.2208910137</td>\n",
              "      <td>0.3287933767</td>\n",
              "      <td>0.6477577090</td>\n",
              "      <td>0.2319895625</td>\n",
              "      <td>1.1014859676</td>\n",
              "      <td>1.0795272589</td>\n",
              "      <td>2.9531016350</td>\n",
              "      <td>-0.5286824107</td>\n",
              "      <td>-1.1405997276</td>\n",
              "      <td>-0.3732994497</td>\n",
              "      <td>0.1098105833</td>\n",
              "      <td>2.8135411739</td>\n",
              "      <td>0.5969979167</td>\n",
              "      <td>1.7548358440</td>\n",
              "      <td>-1.3597713709</td>\n",
              "      <td>0.4665011466</td>\n",
              "      <td>2.3774173260</td>\n",
              "      <td>-0.1806525588</td>\n",
              "      <td>-3.2593042850</td>\n",
              "      <td>0.1208329052</td>\n",
              "      <td>2.2256433964</td>\n",
              "      <td>2.2205066681</td>\n",
              "      <td>-1.1789444685</td>\n",
              "      <td>-0.8213667870</td>\n",
              "      <td>0.7172386646</td>\n",
              "      <td>-1.4558292627</td>\n",
              "      <td>-1.2605844736</td>\n",
              "      <td>2.6234674454</td>\n",
              "      <td>-0.5383300781</td>\n",
              "      <td>-2.6201636791</td>\n",
              "      <td>1.2771952152</td>\n",
              "      <td>0.6010145545</td>\n",
              "      <td>-0.3453120291</td>\n",
              "      <td>0.9934566021</td>\n",
              "      <td>1.3516329527</td>\n",
              "      <td>2.1626746655</td>\n",
              "      <td>2.7685971260</td>\n",
              "      <td>-0.9371970296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>66446</td>\n",
              "      <td>4.2216730118</td>\n",
              "      <td>-1.4971394539</td>\n",
              "      <td>1.1335701942</td>\n",
              "      <td>-2.7456068993</td>\n",
              "      <td>-4.1970448494</td>\n",
              "      <td>-0.5423920751</td>\n",
              "      <td>-1.3962563276</td>\n",
              "      <td>1.8384194374</td>\n",
              "      <td>-6.0664544106</td>\n",
              "      <td>-2.1917989254</td>\n",
              "      <td>0.7528044581</td>\n",
              "      <td>0.8686234355</td>\n",
              "      <td>6.1876621246</td>\n",
              "      <td>1.7257447243</td>\n",
              "      <td>2.8878588676</td>\n",
              "      <td>-1.4860260487</td>\n",
              "      <td>-0.1822564006</td>\n",
              "      <td>-3.7107851505</td>\n",
              "      <td>1.5128655434</td>\n",
              "      <td>-0.6364336014</td>\n",
              "      <td>0.2884352803</td>\n",
              "      <td>-3.3697171211</td>\n",
              "      <td>-0.2659978271</td>\n",
              "      <td>-3.5493185520</td>\n",
              "      <td>3.3753383160</td>\n",
              "      <td>-0.9014606476</td>\n",
              "      <td>-1.5583705902</td>\n",
              "      <td>1.6953426600</td>\n",
              "      <td>-4.4504642487</td>\n",
              "      <td>0.5454953313</td>\n",
              "      <td>1.0000962019</td>\n",
              "      <td>-3.4687514305</td>\n",
              "      <td>3.3276410103</td>\n",
              "      <td>1.5568895340</td>\n",
              "      <td>4.4932026863</td>\n",
              "      <td>0.3690885603</td>\n",
              "      <td>0.1671957970</td>\n",
              "      <td>-4.8370623589</td>\n",
              "      <td>1.2160164118</td>\n",
              "      <td>4.6991534233</td>\n",
              "      <td>-1.0945291519</td>\n",
              "      <td>3.0159423351</td>\n",
              "      <td>-1.3227412701</td>\n",
              "      <td>-0.8291716576</td>\n",
              "      <td>0.5550473332</td>\n",
              "      <td>-5.5927648544</td>\n",
              "      <td>1.2548980713</td>\n",
              "      <td>3.1824502945</td>\n",
              "      <td>3.0535736084</td>\n",
              "      <td>1.9155689478</td>\n",
              "      <td>-1.8057124615</td>\n",
              "      <td>1.4768242836</td>\n",
              "      <td>1.4456773996</td>\n",
              "      <td>-4.2865915298</td>\n",
              "      <td>3.8664577007</td>\n",
              "      <td>-4.0532517433</td>\n",
              "      <td>-0.5716705322</td>\n",
              "      <td>2.1306719780</td>\n",
              "      <td>1.0535889864</td>\n",
              "      <td>0.1100640595</td>\n",
              "      <td>2.8935914040</td>\n",
              "      <td>-4.3589577675</td>\n",
              "      <td>-1.0194541216</td>\n",
              "      <td>0.3668791652</td>\n",
              "      <td>1.8413580656</td>\n",
              "      <td>4.1702466011</td>\n",
              "      <td>4.1743388176</td>\n",
              "      <td>1.2625701427</td>\n",
              "      <td>-0.0290785655</td>\n",
              "      <td>0.3916682005</td>\n",
              "      <td>0.8510245085</td>\n",
              "      <td>2.0302724838</td>\n",
              "      <td>-0.5232113004</td>\n",
              "      <td>-2.9885025024</td>\n",
              "      <td>0.4683658183</td>\n",
              "      <td>2.1632678509</td>\n",
              "      <td>2.6002571583</td>\n",
              "      <td>3.4216189384</td>\n",
              "      <td>-3.7261285782</td>\n",
              "      <td>3.6566011906</td>\n",
              "      <td>1.3187823296</td>\n",
              "      <td>1.9449762106</td>\n",
              "      <td>-1.1189107895</td>\n",
              "      <td>2.6336503029</td>\n",
              "      <td>1.9950672388</td>\n",
              "      <td>-1.3083131313</td>\n",
              "      <td>-1.9136729240</td>\n",
              "      <td>1.8380401134</td>\n",
              "      <td>-4.9061074257</td>\n",
              "      <td>-3.0755031109</td>\n",
              "      <td>-0.6857675910</td>\n",
              "      <td>2.5223836899</td>\n",
              "      <td>0.5497792959</td>\n",
              "      <td>1.4827349186</td>\n",
              "      <td>0.8170077205</td>\n",
              "      <td>1.9330986738</td>\n",
              "      <td>-2.5392942429</td>\n",
              "      <td>-0.4976403117</td>\n",
              "      <td>-1.0175911188</td>\n",
              "      <td>-2.7609453201</td>\n",
              "      <td>-1.8073147535</td>\n",
              "      <td>-3.6103582382</td>\n",
              "      <td>4.2451257706</td>\n",
              "      <td>-4.4561161995</td>\n",
              "      <td>1.7062046528</td>\n",
              "      <td>-3.1820578575</td>\n",
              "      <td>0.1201333702</td>\n",
              "      <td>4.3089995384</td>\n",
              "      <td>-3.7071764469</td>\n",
              "      <td>3.7954654694</td>\n",
              "      <td>2.0711903572</td>\n",
              "      <td>3.6382451057</td>\n",
              "      <td>-2.5796868801</td>\n",
              "      <td>1.3196798563</td>\n",
              "      <td>-3.7506515980</td>\n",
              "      <td>2.7014789581</td>\n",
              "      <td>-0.2162129283</td>\n",
              "      <td>5.0864233971</td>\n",
              "      <td>2.7782700062</td>\n",
              "      <td>3.9552774429</td>\n",
              "      <td>0.3138726354</td>\n",
              "      <td>-2.3330941200</td>\n",
              "      <td>0.2004831731</td>\n",
              "      <td>0.6144545674</td>\n",
              "      <td>-0.2370703667</td>\n",
              "      <td>-5.3172769547</td>\n",
              "      <td>4.8742480278</td>\n",
              "      <td>0.5578527451</td>\n",
              "      <td>-5.1803641319</td>\n",
              "      <td>-0.3882471323</td>\n",
              "      <td>-0.0362354293</td>\n",
              "      <td>-1.8510223627</td>\n",
              "      <td>1.2238538265</td>\n",
              "      <td>1.9967815876</td>\n",
              "      <td>0.7940438390</td>\n",
              "      <td>-0.2907482982</td>\n",
              "      <td>0.3932960033</td>\n",
              "      <td>-1.1030144691</td>\n",
              "      <td>-2.6933064461</td>\n",
              "      <td>1.2588562965</td>\n",
              "      <td>-1.9516181946</td>\n",
              "      <td>-1.6696166992</td>\n",
              "      <td>-1.3041158915</td>\n",
              "      <td>-0.7412303686</td>\n",
              "      <td>-1.9874830246</td>\n",
              "      <td>1.1826648712</td>\n",
              "      <td>0.1876281202</td>\n",
              "      <td>2.8795382977</td>\n",
              "      <td>-1.4945707321</td>\n",
              "      <td>4.8454046249</td>\n",
              "      <td>1.6018526554</td>\n",
              "      <td>-2.2582504749</td>\n",
              "      <td>0.6056196094</td>\n",
              "      <td>1.3605409861</td>\n",
              "      <td>2.2704613209</td>\n",
              "      <td>-2.3936748505</td>\n",
              "      <td>-2.5237107277</td>\n",
              "      <td>2.3623688221</td>\n",
              "      <td>-3.7879507542</td>\n",
              "      <td>4.1489663124</td>\n",
              "      <td>0.5273576379</td>\n",
              "      <td>-0.4623291790</td>\n",
              "      <td>1.9587676525</td>\n",
              "      <td>-0.5154456496</td>\n",
              "      <td>0.6768915653</td>\n",
              "      <td>-0.3047086000</td>\n",
              "      <td>0.1290760487</td>\n",
              "      <td>-1.6329034567</td>\n",
              "      <td>-0.4164456129</td>\n",
              "      <td>0.2012564689</td>\n",
              "      <td>1.5046161413</td>\n",
              "      <td>-1.8403992653</td>\n",
              "      <td>0.7415528893</td>\n",
              "      <td>1.1971130371</td>\n",
              "      <td>0.4738982022</td>\n",
              "      <td>-0.9263385534</td>\n",
              "      <td>0.7251952887</td>\n",
              "      <td>-2.4600844383</td>\n",
              "      <td>0.6102679968</td>\n",
              "      <td>2.4189102650</td>\n",
              "      <td>-0.8073080182</td>\n",
              "      <td>-2.4715397358</td>\n",
              "      <td>2.5514853001</td>\n",
              "      <td>-1.8118276596</td>\n",
              "      <td>0.1008770168</td>\n",
              "      <td>0.7436977029</td>\n",
              "      <td>-1.1163951159</td>\n",
              "      <td>-0.3596743941</td>\n",
              "      <td>3.0285360813</td>\n",
              "      <td>-2.4324274063</td>\n",
              "      <td>1.5074805021</td>\n",
              "      <td>1.7838965654</td>\n",
              "      <td>-0.2175149024</td>\n",
              "      <td>-2.6842575073</td>\n",
              "      <td>-2.6698846817</td>\n",
              "      <td>1.3063540459</td>\n",
              "      <td>2.1978611946</td>\n",
              "      <td>0.2396692932</td>\n",
              "      <td>0.6746810079</td>\n",
              "      <td>-0.1925708055</td>\n",
              "      <td>-0.1629413515</td>\n",
              "      <td>2.5120844841</td>\n",
              "      <td>-1.0960826874</td>\n",
              "      <td>3.5255630016</td>\n",
              "      <td>1.0564339161</td>\n",
              "      <td>-2.1295158863</td>\n",
              "      <td>-0.0054923594</td>\n",
              "      <td>3.8271811008</td>\n",
              "      <td>-0.3581976295</td>\n",
              "      <td>-2.0093791485</td>\n",
              "      <td>-0.2243905813</td>\n",
              "      <td>0.8038508296</td>\n",
              "      <td>-0.9094979167</td>\n",
              "      <td>0.9628103375</td>\n",
              "      <td>2.6015825272</td>\n",
              "      <td>0.0563275069</td>\n",
              "      <td>1.8594735861</td>\n",
              "      <td>-0.3161342740</td>\n",
              "      <td>-1.1312859058</td>\n",
              "      <td>1.7012784481</td>\n",
              "      <td>2.3054049015</td>\n",
              "      <td>-1.9412707090</td>\n",
              "      <td>1.2480015755</td>\n",
              "      <td>0.2910004854</td>\n",
              "      <td>0.7920667529</td>\n",
              "      <td>1.3611664772</td>\n",
              "      <td>1.1290049553</td>\n",
              "      <td>1.9474035501</td>\n",
              "      <td>-0.8594229817</td>\n",
              "      <td>2.0232229233</td>\n",
              "      <td>2.3486514091</td>\n",
              "      <td>4.5061273575</td>\n",
              "      <td>0.6844365001</td>\n",
              "      <td>2.0649919510</td>\n",
              "      <td>0.0229008049</td>\n",
              "      <td>3.4642429352</td>\n",
              "      <td>-2.3252725601</td>\n",
              "      <td>0.1313239187</td>\n",
              "      <td>-1.8761780262</td>\n",
              "      <td>1.7703540325</td>\n",
              "      <td>2.9251759052</td>\n",
              "      <td>-1.8510544300</td>\n",
              "      <td>-0.0925873220</td>\n",
              "      <td>-0.5807421207</td>\n",
              "      <td>-0.4220193028</td>\n",
              "      <td>0.9237140417</td>\n",
              "      <td>-4.5827107430</td>\n",
              "      <td>-1.0569097996</td>\n",
              "      <td>-2.5680844784</td>\n",
              "      <td>-2.0380613804</td>\n",
              "      <td>2.5087187290</td>\n",
              "      <td>-0.7647889853</td>\n",
              "      <td>-0.6571162343</td>\n",
              "      <td>3.2527816296</td>\n",
              "      <td>2.6873664856</td>\n",
              "      <td>0.8443320990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>63651</td>\n",
              "      <td>2.6579699516</td>\n",
              "      <td>-0.9418634772</td>\n",
              "      <td>1.1215288639</td>\n",
              "      <td>-5.1094956398</td>\n",
              "      <td>-0.2790412009</td>\n",
              "      <td>-0.3519684672</td>\n",
              "      <td>-1.0869832039</td>\n",
              "      <td>2.7036073208</td>\n",
              "      <td>-6.4949769974</td>\n",
              "      <td>-0.7467688918</td>\n",
              "      <td>-0.0685710013</td>\n",
              "      <td>-3.8946695328</td>\n",
              "      <td>4.9370460510</td>\n",
              "      <td>-1.8632038832</td>\n",
              "      <td>-1.9550676346</td>\n",
              "      <td>1.9001927376</td>\n",
              "      <td>1.7438409328</td>\n",
              "      <td>-6.0247902870</td>\n",
              "      <td>1.4604135752</td>\n",
              "      <td>-2.2061042786</td>\n",
              "      <td>-1.9975721836</td>\n",
              "      <td>-3.4145364761</td>\n",
              "      <td>-0.1787390411</td>\n",
              "      <td>0.9873132110</td>\n",
              "      <td>1.2553472519</td>\n",
              "      <td>-1.1871355772</td>\n",
              "      <td>2.0705177784</td>\n",
              "      <td>2.1910212040</td>\n",
              "      <td>-2.9367015362</td>\n",
              "      <td>2.6177332401</td>\n",
              "      <td>0.9191812277</td>\n",
              "      <td>-3.0879065990</td>\n",
              "      <td>-0.3589378297</td>\n",
              "      <td>-0.4286785722</td>\n",
              "      <td>3.8155975342</td>\n",
              "      <td>2.4405581951</td>\n",
              "      <td>1.2810608149</td>\n",
              "      <td>-0.7325298190</td>\n",
              "      <td>1.5170669556</td>\n",
              "      <td>2.7903022766</td>\n",
              "      <td>-2.0191221237</td>\n",
              "      <td>2.4190418720</td>\n",
              "      <td>-2.0448062420</td>\n",
              "      <td>0.6491868496</td>\n",
              "      <td>1.9405262470</td>\n",
              "      <td>-4.9653587341</td>\n",
              "      <td>0.9304602742</td>\n",
              "      <td>-1.1520111561</td>\n",
              "      <td>0.1675943732</td>\n",
              "      <td>1.3513327837</td>\n",
              "      <td>1.4120253325</td>\n",
              "      <td>5.8572702408</td>\n",
              "      <td>2.9551832676</td>\n",
              "      <td>-5.2905402184</td>\n",
              "      <td>3.9502623081</td>\n",
              "      <td>-1.0030276775</td>\n",
              "      <td>-0.6423271894</td>\n",
              "      <td>-0.7421406507</td>\n",
              "      <td>1.8295041323</td>\n",
              "      <td>-0.3699176610</td>\n",
              "      <td>0.5510581136</td>\n",
              "      <td>-4.0429396629</td>\n",
              "      <td>-1.8587552309</td>\n",
              "      <td>1.1932451725</td>\n",
              "      <td>0.5523794889</td>\n",
              "      <td>0.8406279087</td>\n",
              "      <td>-0.1998117566</td>\n",
              "      <td>-0.5318464041</td>\n",
              "      <td>0.5840061307</td>\n",
              "      <td>0.2384417951</td>\n",
              "      <td>-0.1831949651</td>\n",
              "      <td>-0.9647368193</td>\n",
              "      <td>0.0030380934</td>\n",
              "      <td>-3.8698849678</td>\n",
              "      <td>0.1377555430</td>\n",
              "      <td>2.9626429081</td>\n",
              "      <td>0.8658820391</td>\n",
              "      <td>4.0657339096</td>\n",
              "      <td>-2.1266815662</td>\n",
              "      <td>-0.1394288242</td>\n",
              "      <td>-0.0651780367</td>\n",
              "      <td>0.0671006665</td>\n",
              "      <td>-1.7295682430</td>\n",
              "      <td>3.5149486065</td>\n",
              "      <td>1.6050981283</td>\n",
              "      <td>0.6517529488</td>\n",
              "      <td>-1.3164319992</td>\n",
              "      <td>0.4306410849</td>\n",
              "      <td>-0.9936897755</td>\n",
              "      <td>-4.6938705444</td>\n",
              "      <td>-1.9676889181</td>\n",
              "      <td>3.2283120155</td>\n",
              "      <td>1.3695452213</td>\n",
              "      <td>-0.1332462430</td>\n",
              "      <td>0.4559089541</td>\n",
              "      <td>-0.9183557034</td>\n",
              "      <td>-1.4347511530</td>\n",
              "      <td>0.9158083797</td>\n",
              "      <td>0.4877495468</td>\n",
              "      <td>1.0235780478</td>\n",
              "      <td>-0.0599985197</td>\n",
              "      <td>-4.7873816490</td>\n",
              "      <td>-1.5516570807</td>\n",
              "      <td>-3.0073292255</td>\n",
              "      <td>2.0735120773</td>\n",
              "      <td>-3.4647843838</td>\n",
              "      <td>-2.7820105553</td>\n",
              "      <td>-0.0993154496</td>\n",
              "      <td>-4.0383219719</td>\n",
              "      <td>-0.8915926218</td>\n",
              "      <td>0.6951371431</td>\n",
              "      <td>3.5863361359</td>\n",
              "      <td>1.0518940687</td>\n",
              "      <td>1.5735805035</td>\n",
              "      <td>-4.2804646492</td>\n",
              "      <td>3.1986303329</td>\n",
              "      <td>-2.7923855782</td>\n",
              "      <td>3.2322039604</td>\n",
              "      <td>-3.1985409260</td>\n",
              "      <td>2.5838351250</td>\n",
              "      <td>-1.2322738171</td>\n",
              "      <td>-2.7884037495</td>\n",
              "      <td>1.4736993313</td>\n",
              "      <td>-3.1015565395</td>\n",
              "      <td>-0.9659563899</td>\n",
              "      <td>-3.5598251820</td>\n",
              "      <td>4.0261893272</td>\n",
              "      <td>1.3633310795</td>\n",
              "      <td>-1.0772739649</td>\n",
              "      <td>2.8394529819</td>\n",
              "      <td>1.1834309101</td>\n",
              "      <td>-1.0987117290</td>\n",
              "      <td>0.9005973339</td>\n",
              "      <td>1.4222483635</td>\n",
              "      <td>0.1098280475</td>\n",
              "      <td>-3.7701313496</td>\n",
              "      <td>0.1382257044</td>\n",
              "      <td>-3.4304034710</td>\n",
              "      <td>-1.1713567972</td>\n",
              "      <td>-1.2840040922</td>\n",
              "      <td>-0.0544508547</td>\n",
              "      <td>-2.2876307964</td>\n",
              "      <td>-0.5878560543</td>\n",
              "      <td>-3.7379798889</td>\n",
              "      <td>-0.7720518112</td>\n",
              "      <td>0.6717689037</td>\n",
              "      <td>1.4492791891</td>\n",
              "      <td>-0.1424507499</td>\n",
              "      <td>-0.6465058327</td>\n",
              "      <td>2.2852480412</td>\n",
              "      <td>-1.3476312160</td>\n",
              "      <td>-0.3918263912</td>\n",
              "      <td>0.2032637298</td>\n",
              "      <td>-0.4844906628</td>\n",
              "      <td>-2.1060159206</td>\n",
              "      <td>-3.5996644497</td>\n",
              "      <td>-4.4429578781</td>\n",
              "      <td>1.7781949043</td>\n",
              "      <td>-4.1688241959</td>\n",
              "      <td>2.1066026688</td>\n",
              "      <td>-2.6107659340</td>\n",
              "      <td>-4.6652832031</td>\n",
              "      <td>4.2292447090</td>\n",
              "      <td>1.1606259346</td>\n",
              "      <td>1.1377283335</td>\n",
              "      <td>0.3503388762</td>\n",
              "      <td>3.7622182369</td>\n",
              "      <td>-1.5629478693</td>\n",
              "      <td>3.2892580032</td>\n",
              "      <td>0.6765853763</td>\n",
              "      <td>-1.1160399914</td>\n",
              "      <td>-2.3792004585</td>\n",
              "      <td>0.3785956204</td>\n",
              "      <td>0.5143413544</td>\n",
              "      <td>3.4223504066</td>\n",
              "      <td>1.5008887053</td>\n",
              "      <td>-2.3732028008</td>\n",
              "      <td>1.3730483055</td>\n",
              "      <td>-1.8183721304</td>\n",
              "      <td>0.2093314379</td>\n",
              "      <td>-4.0995993614</td>\n",
              "      <td>-2.2917511463</td>\n",
              "      <td>1.7036482096</td>\n",
              "      <td>-1.7782133818</td>\n",
              "      <td>0.2453990728</td>\n",
              "      <td>-3.7033028603</td>\n",
              "      <td>1.4522143602</td>\n",
              "      <td>2.1704957485</td>\n",
              "      <td>1.1902852058</td>\n",
              "      <td>-2.3954641819</td>\n",
              "      <td>-0.1170736402</td>\n",
              "      <td>0.6126937270</td>\n",
              "      <td>-4.3434071541</td>\n",
              "      <td>-3.7077896595</td>\n",
              "      <td>-1.9681696892</td>\n",
              "      <td>1.6769342422</td>\n",
              "      <td>-1.6965925694</td>\n",
              "      <td>0.8841276169</td>\n",
              "      <td>1.8131419420</td>\n",
              "      <td>1.8550761938</td>\n",
              "      <td>1.3032124043</td>\n",
              "      <td>2.0474886894</td>\n",
              "      <td>0.6032235622</td>\n",
              "      <td>3.9587745667</td>\n",
              "      <td>3.7462685108</td>\n",
              "      <td>-3.4980876446</td>\n",
              "      <td>-0.7330384254</td>\n",
              "      <td>-0.9137355089</td>\n",
              "      <td>-1.2961897850</td>\n",
              "      <td>4.8217391968</td>\n",
              "      <td>0.6872349381</td>\n",
              "      <td>-1.4064308405</td>\n",
              "      <td>0.6691839695</td>\n",
              "      <td>-1.8475983143</td>\n",
              "      <td>-0.8170750737</td>\n",
              "      <td>-1.1811718941</td>\n",
              "      <td>2.5885522366</td>\n",
              "      <td>-1.1231178045</td>\n",
              "      <td>0.2324265391</td>\n",
              "      <td>2.1703250408</td>\n",
              "      <td>0.5794144869</td>\n",
              "      <td>2.6014208794</td>\n",
              "      <td>-0.5961964726</td>\n",
              "      <td>-1.7986934185</td>\n",
              "      <td>0.3123261333</td>\n",
              "      <td>0.3874855340</td>\n",
              "      <td>-2.2073650360</td>\n",
              "      <td>-1.0293287039</td>\n",
              "      <td>-1.2742329836</td>\n",
              "      <td>2.0472295284</td>\n",
              "      <td>1.9285165071</td>\n",
              "      <td>2.1026327610</td>\n",
              "      <td>-0.5593834519</td>\n",
              "      <td>-0.9514183998</td>\n",
              "      <td>-2.0217494965</td>\n",
              "      <td>1.3662722111</td>\n",
              "      <td>-1.9472106695</td>\n",
              "      <td>-2.1144192219</td>\n",
              "      <td>1.1403938532</td>\n",
              "      <td>-0.7960235476</td>\n",
              "      <td>1.9063613415</td>\n",
              "      <td>-0.3575199842</td>\n",
              "      <td>3.3529679775</td>\n",
              "      <td>-3.9963769913</td>\n",
              "      <td>1.5203311443</td>\n",
              "      <td>-0.0007160828</td>\n",
              "      <td>-0.4876829982</td>\n",
              "      <td>-1.8891189098</td>\n",
              "      <td>0.9430151582</td>\n",
              "      <td>-2.8344175816</td>\n",
              "      <td>1.6331835985</td>\n",
              "      <td>2.0018005371</td>\n",
              "      <td>-2.3331520557</td>\n",
              "      <td>2.6455948353</td>\n",
              "      <td>2.2802333832</td>\n",
              "      <td>-0.6944484115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>46824</td>\n",
              "      <td>3.1921949387</td>\n",
              "      <td>-1.9366759062</td>\n",
              "      <td>1.1999093294</td>\n",
              "      <td>-2.5621519089</td>\n",
              "      <td>-2.5734560490</td>\n",
              "      <td>0.5758405328</td>\n",
              "      <td>-2.3586528301</td>\n",
              "      <td>1.6208440065</td>\n",
              "      <td>-4.3029360771</td>\n",
              "      <td>-0.4875746071</td>\n",
              "      <td>0.0208958052</td>\n",
              "      <td>-0.7633265853</td>\n",
              "      <td>4.3416938782</td>\n",
              "      <td>0.6987979412</td>\n",
              "      <td>3.3345804214</td>\n",
              "      <td>0.6076831222</td>\n",
              "      <td>-0.7186435461</td>\n",
              "      <td>-2.7301876545</td>\n",
              "      <td>0.1938284338</td>\n",
              "      <td>-1.7061960697</td>\n",
              "      <td>-0.4687266648</td>\n",
              "      <td>-2.2819042206</td>\n",
              "      <td>-1.8372744322</td>\n",
              "      <td>-2.8491399288</td>\n",
              "      <td>0.1958733052</td>\n",
              "      <td>-0.4597650468</td>\n",
              "      <td>-0.7687521577</td>\n",
              "      <td>1.0334885120</td>\n",
              "      <td>-2.4908955097</td>\n",
              "      <td>2.0775208473</td>\n",
              "      <td>-0.1719837934</td>\n",
              "      <td>-3.4063465595</td>\n",
              "      <td>2.6166696548</td>\n",
              "      <td>0.7130991220</td>\n",
              "      <td>4.4502215385</td>\n",
              "      <td>0.6064971685</td>\n",
              "      <td>0.1606716812</td>\n",
              "      <td>-2.6042177677</td>\n",
              "      <td>2.1102719307</td>\n",
              "      <td>4.7140192986</td>\n",
              "      <td>-2.2979054451</td>\n",
              "      <td>1.7008813620</td>\n",
              "      <td>-0.1956334114</td>\n",
              "      <td>-0.4040055871</td>\n",
              "      <td>2.1407785416</td>\n",
              "      <td>-5.3515763283</td>\n",
              "      <td>1.5924882889</td>\n",
              "      <td>1.3127232790</td>\n",
              "      <td>1.6108667850</td>\n",
              "      <td>0.9940723181</td>\n",
              "      <td>-1.1959708929</td>\n",
              "      <td>1.7814975977</td>\n",
              "      <td>1.7854963541</td>\n",
              "      <td>-4.0715527534</td>\n",
              "      <td>2.6540911198</td>\n",
              "      <td>-5.9325356483</td>\n",
              "      <td>-0.4189185500</td>\n",
              "      <td>-0.9260056019</td>\n",
              "      <td>-0.5426020026</td>\n",
              "      <td>0.4626600146</td>\n",
              "      <td>1.4631899595</td>\n",
              "      <td>-4.1606488228</td>\n",
              "      <td>0.1747602522</td>\n",
              "      <td>0.0668889135</td>\n",
              "      <td>1.9713603258</td>\n",
              "      <td>1.9823232889</td>\n",
              "      <td>2.5010893345</td>\n",
              "      <td>0.2407858074</td>\n",
              "      <td>-0.5280813575</td>\n",
              "      <td>0.9364103079</td>\n",
              "      <td>-0.2675441802</td>\n",
              "      <td>1.1475917101</td>\n",
              "      <td>0.2777195573</td>\n",
              "      <td>-1.5763708353</td>\n",
              "      <td>-1.3750151396</td>\n",
              "      <td>2.2555143833</td>\n",
              "      <td>2.0386326313</td>\n",
              "      <td>3.8130803108</td>\n",
              "      <td>-2.5444471836</td>\n",
              "      <td>2.7090351582</td>\n",
              "      <td>-1.2576792240</td>\n",
              "      <td>1.2818650007</td>\n",
              "      <td>-0.3754705787</td>\n",
              "      <td>1.0863946676</td>\n",
              "      <td>3.9390137196</td>\n",
              "      <td>-0.7524920106</td>\n",
              "      <td>-0.4735445082</td>\n",
              "      <td>0.2154830545</td>\n",
              "      <td>-3.9462544918</td>\n",
              "      <td>-1.3390405178</td>\n",
              "      <td>-0.5571385622</td>\n",
              "      <td>1.8416041136</td>\n",
              "      <td>-0.2635599077</td>\n",
              "      <td>-0.5724999309</td>\n",
              "      <td>1.6691718102</td>\n",
              "      <td>-0.0412875786</td>\n",
              "      <td>-1.7513698339</td>\n",
              "      <td>-0.9225690961</td>\n",
              "      <td>-0.8901174664</td>\n",
              "      <td>-0.7344263792</td>\n",
              "      <td>-0.1985396743</td>\n",
              "      <td>-4.6947107315</td>\n",
              "      <td>2.3384141922</td>\n",
              "      <td>-3.1651930809</td>\n",
              "      <td>-0.6592266560</td>\n",
              "      <td>-2.2427787781</td>\n",
              "      <td>-0.2026949227</td>\n",
              "      <td>2.8271911144</td>\n",
              "      <td>-3.3360562325</td>\n",
              "      <td>3.8229005337</td>\n",
              "      <td>0.8821620941</td>\n",
              "      <td>2.8626224995</td>\n",
              "      <td>-2.6367087364</td>\n",
              "      <td>0.5635325909</td>\n",
              "      <td>-2.7188420296</td>\n",
              "      <td>2.0029742718</td>\n",
              "      <td>1.4403909445</td>\n",
              "      <td>4.0350317955</td>\n",
              "      <td>0.6819838881</td>\n",
              "      <td>4.4928522110</td>\n",
              "      <td>-0.8764061332</td>\n",
              "      <td>-2.3473026752</td>\n",
              "      <td>0.0668368563</td>\n",
              "      <td>-1.4170516729</td>\n",
              "      <td>-0.0014237612</td>\n",
              "      <td>-3.9701452255</td>\n",
              "      <td>4.4187226295</td>\n",
              "      <td>0.2834067345</td>\n",
              "      <td>-3.2601945400</td>\n",
              "      <td>0.4988903403</td>\n",
              "      <td>2.5831427574</td>\n",
              "      <td>-2.5513806343</td>\n",
              "      <td>1.4665173292</td>\n",
              "      <td>-0.1956336200</td>\n",
              "      <td>1.2730638981</td>\n",
              "      <td>0.4443459213</td>\n",
              "      <td>1.9116442204</td>\n",
              "      <td>-1.8641946316</td>\n",
              "      <td>0.4185179174</td>\n",
              "      <td>-2.4434888363</td>\n",
              "      <td>-1.9919613600</td>\n",
              "      <td>-0.6361541748</td>\n",
              "      <td>-1.0268591642</td>\n",
              "      <td>-0.8774957061</td>\n",
              "      <td>0.7087628841</td>\n",
              "      <td>1.8621208668</td>\n",
              "      <td>0.8565728068</td>\n",
              "      <td>1.7871872187</td>\n",
              "      <td>-0.2045107186</td>\n",
              "      <td>1.8074589968</td>\n",
              "      <td>-1.2486822605</td>\n",
              "      <td>-2.0458302498</td>\n",
              "      <td>-0.6823843718</td>\n",
              "      <td>-1.0407505035</td>\n",
              "      <td>-0.1911843121</td>\n",
              "      <td>-1.1757192612</td>\n",
              "      <td>-3.0022175312</td>\n",
              "      <td>1.3092085123</td>\n",
              "      <td>0.7799966335</td>\n",
              "      <td>1.5844647884</td>\n",
              "      <td>-0.2545006573</td>\n",
              "      <td>-1.9702123404</td>\n",
              "      <td>2.6014389992</td>\n",
              "      <td>0.7656390667</td>\n",
              "      <td>-0.3065223992</td>\n",
              "      <td>1.4117398262</td>\n",
              "      <td>2.0450096130</td>\n",
              "      <td>-1.4351650476</td>\n",
              "      <td>0.6078616381</td>\n",
              "      <td>1.8148971796</td>\n",
              "      <td>1.9150559902</td>\n",
              "      <td>1.3558405638</td>\n",
              "      <td>0.3710158169</td>\n",
              "      <td>1.5915417671</td>\n",
              "      <td>-1.3562458754</td>\n",
              "      <td>-2.0786681175</td>\n",
              "      <td>-1.4965167046</td>\n",
              "      <td>-1.5357089043</td>\n",
              "      <td>0.5223278999</td>\n",
              "      <td>1.3364672661</td>\n",
              "      <td>-2.0848152637</td>\n",
              "      <td>-2.3919889927</td>\n",
              "      <td>1.2798339128</td>\n",
              "      <td>-0.4796919227</td>\n",
              "      <td>0.8068606853</td>\n",
              "      <td>0.0033650771</td>\n",
              "      <td>0.1334796101</td>\n",
              "      <td>1.9405741692</td>\n",
              "      <td>0.3472729027</td>\n",
              "      <td>-3.2160534859</td>\n",
              "      <td>-1.1251442432</td>\n",
              "      <td>-0.4129741192</td>\n",
              "      <td>-0.4549874365</td>\n",
              "      <td>-1.5074959993</td>\n",
              "      <td>-1.0031266212</td>\n",
              "      <td>1.4596577883</td>\n",
              "      <td>0.3572512269</td>\n",
              "      <td>-1.2548041344</td>\n",
              "      <td>-0.3108480573</td>\n",
              "      <td>-1.8746677637</td>\n",
              "      <td>-1.0605058670</td>\n",
              "      <td>0.0878456458</td>\n",
              "      <td>-1.9225060940</td>\n",
              "      <td>1.1394615173</td>\n",
              "      <td>0.2324949801</td>\n",
              "      <td>-1.6677292585</td>\n",
              "      <td>1.0865254402</td>\n",
              "      <td>3.2355041504</td>\n",
              "      <td>-1.3600406647</td>\n",
              "      <td>-0.5736263990</td>\n",
              "      <td>-0.3438729644</td>\n",
              "      <td>-0.8621111512</td>\n",
              "      <td>-3.0362601280</td>\n",
              "      <td>-1.0166102648</td>\n",
              "      <td>-1.1497695446</td>\n",
              "      <td>0.4641397595</td>\n",
              "      <td>2.4124057293</td>\n",
              "      <td>-0.6541346908</td>\n",
              "      <td>0.4868938923</td>\n",
              "      <td>1.1680536270</td>\n",
              "      <td>-0.2714197040</td>\n",
              "      <td>0.6670907736</td>\n",
              "      <td>1.1635572910</td>\n",
              "      <td>-0.1322363019</td>\n",
              "      <td>0.6684629917</td>\n",
              "      <td>-0.2281846255</td>\n",
              "      <td>0.1557677239</td>\n",
              "      <td>1.5468212366</td>\n",
              "      <td>0.3076400459</td>\n",
              "      <td>2.5429413319</td>\n",
              "      <td>1.2409851551</td>\n",
              "      <td>2.1445691586</td>\n",
              "      <td>-1.0797533989</td>\n",
              "      <td>0.3351914585</td>\n",
              "      <td>0.2451588660</td>\n",
              "      <td>2.1501686573</td>\n",
              "      <td>-1.9914399385</td>\n",
              "      <td>-2.3307268620</td>\n",
              "      <td>0.7368552089</td>\n",
              "      <td>2.1269307137</td>\n",
              "      <td>0.5560612679</td>\n",
              "      <td>-1.6114931107</td>\n",
              "      <td>2.7221329212</td>\n",
              "      <td>-1.1859402657</td>\n",
              "      <td>0.3992010057</td>\n",
              "      <td>1.5986174345</td>\n",
              "      <td>-0.6214751601</td>\n",
              "      <td>-2.0914101601</td>\n",
              "      <td>0.5015996695</td>\n",
              "      <td>-3.0838639736</td>\n",
              "      <td>-1.0600911379</td>\n",
              "      <td>2.0536000729</td>\n",
              "      <td>-2.0250082016</td>\n",
              "      <td>2.3992507458</td>\n",
              "      <td>2.5623166561</td>\n",
              "      <td>0.6941336393</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   item_id      txt_vec0      txt_vec1      txt_vec2      txt_vec3  \\\n",
              "0    42844  4.5149450302 -2.3837196827  0.5004140139  0.4070682824   \n",
              "1    67898 -2.0029051304 -0.9298805594  0.7900167108 -1.3808951378   \n",
              "2    66446  4.2216730118 -1.4971394539  1.1335701942 -2.7456068993   \n",
              "3    63651  2.6579699516 -0.9418634772  1.1215288639 -5.1094956398   \n",
              "4    46824  3.1921949387 -1.9366759062  1.1999093294 -2.5621519089   \n",
              "\n",
              "       txt_vec4      txt_vec5      txt_vec6      txt_vec7      txt_vec8  \\\n",
              "0 -1.9952288866  0.1090780124 -0.6917753220  2.2274599075 -6.4379744530   \n",
              "1 -0.5104627609 -1.8100957870  1.3639619350  0.4974010289 -4.0389027596   \n",
              "2 -4.1970448494 -0.5423920751 -1.3962563276  1.8384194374 -6.0664544106   \n",
              "3 -0.2790412009 -0.3519684672 -1.0869832039  2.7036073208 -6.4949769974   \n",
              "4 -2.5734560490  0.5758405328 -2.3586528301  1.6208440065 -4.3029360771   \n",
              "\n",
              "       txt_vec9     txt_vec10     txt_vec11     txt_vec12     txt_vec13  \\\n",
              "0 -0.8248971701 -0.1387242377 -0.3793291748  0.6276600957  0.4183767140   \n",
              "1 -3.0578715801  0.7585576773 -1.0121546984  2.8168015480  2.0868949890   \n",
              "2 -2.1917989254  0.7528044581  0.8686234355  6.1876621246  1.7257447243   \n",
              "3 -0.7467688918 -0.0685710013 -3.8946695328  4.9370460510 -1.8632038832   \n",
              "4 -0.4875746071  0.0208958052 -0.7633265853  4.3416938782  0.6987979412   \n",
              "\n",
              "      txt_vec14     txt_vec15     txt_vec16     txt_vec17     txt_vec18  \\\n",
              "0  4.4412183762  0.2998193502  0.5785568357 -4.6992893219 -0.3947401643   \n",
              "1 -1.4643309116 -1.8404960632 -2.0899708271 -1.5668717623  1.5453896523   \n",
              "2  2.8878588676 -1.4860260487 -0.1822564006 -3.7107851505  1.5128655434   \n",
              "3 -1.9550676346  1.9001927376  1.7438409328 -6.0247902870  1.4604135752   \n",
              "4  3.3345804214  0.6076831222 -0.7186435461 -2.7301876545  0.1938284338   \n",
              "\n",
              "      txt_vec19     txt_vec20     txt_vec21     txt_vec22     txt_vec23  \\\n",
              "0 -2.3916513920  0.3705316782 -1.3554661274 -1.0741775036 -2.3216402531   \n",
              "1  1.2843413353 -2.2702617645  0.7801263332  1.6155936718 -0.5460581183   \n",
              "2 -0.6364336014  0.2884352803 -3.3697171211 -0.2659978271 -3.5493185520   \n",
              "3 -2.2061042786 -1.9975721836 -3.4145364761 -0.1787390411  0.9873132110   \n",
              "4 -1.7061960697 -0.4687266648 -2.2819042206 -1.8372744322 -2.8491399288   \n",
              "\n",
              "      txt_vec24     txt_vec25     txt_vec26     txt_vec27     txt_vec28  \\\n",
              "0 -0.3324561715  0.1238859445 -2.4391555786 -0.3455986977 -3.3043470383   \n",
              "1  1.3707500696 -1.1781235933  1.3468424082  0.4424336255 -1.4985396862   \n",
              "2  3.3753383160 -0.9014606476 -1.5583705902  1.6953426600 -4.4504642487   \n",
              "3  1.2553472519 -1.1871355772  2.0705177784  2.1910212040 -2.9367015362   \n",
              "4  0.1958733052 -0.4597650468 -0.7687521577  1.0334885120 -2.4908955097   \n",
              "\n",
              "      txt_vec29     txt_vec30     txt_vec31     txt_vec32     txt_vec33  \\\n",
              "0  1.4852843285  0.9098017812 -1.6430019140  5.0370340347  2.7801148891   \n",
              "1 -0.5899440646  2.0083506107 -0.4971346855 -1.6442297697  3.1406233311   \n",
              "2  0.5454953313  1.0000962019 -3.4687514305  3.3276410103  1.5568895340   \n",
              "3  2.6177332401  0.9191812277 -3.0879065990 -0.3589378297 -0.4286785722   \n",
              "4  2.0775208473 -0.1719837934 -3.4063465595  2.6166696548  0.7130991220   \n",
              "\n",
              "      txt_vec34     txt_vec35     txt_vec36     txt_vec37     txt_vec38  \\\n",
              "0  4.7764964104  2.2552747726  3.7697074413 -3.6616835594 -0.6494054794   \n",
              "1  3.4921784401  0.3353945315  1.8109228611 -4.0120801926  2.4195928574   \n",
              "2  4.4932026863  0.3690885603  0.1671957970 -4.8370623589  1.2160164118   \n",
              "3  3.8155975342  2.4405581951  1.2810608149 -0.7325298190  1.5170669556   \n",
              "4  4.4502215385  0.6064971685  0.1606716812 -2.6042177677  2.1102719307   \n",
              "\n",
              "      txt_vec39     txt_vec40     txt_vec41     txt_vec42     txt_vec43  \\\n",
              "0  4.1996359825 -0.6348056197  2.4303400517 -2.8740186691 -0.7861775160   \n",
              "1  0.1909409761 -0.6306105256  3.2893316746 -1.4467194080 -0.6113395691   \n",
              "2  4.6991534233 -1.0945291519  3.0159423351 -1.3227412701 -0.8291716576   \n",
              "3  2.7903022766 -2.0191221237  2.4190418720 -2.0448062420  0.6491868496   \n",
              "4  4.7140192986 -2.2979054451  1.7008813620 -0.1956334114 -0.4040055871   \n",
              "\n",
              "      txt_vec44     txt_vec45     txt_vec46     txt_vec47     txt_vec48  \\\n",
              "0 -0.5049162507 -6.0077886581  1.4984948635  1.5306128263  2.3796546459   \n",
              "1  0.7006615996 -2.4656562805 -0.5967733860  2.4982099533  3.6829156876   \n",
              "2  0.5550473332 -5.5927648544  1.2548980713  3.1824502945  3.0535736084   \n",
              "3  1.9405262470 -4.9653587341  0.9304602742 -1.1520111561  0.1675943732   \n",
              "4  2.1407785416 -5.3515763283  1.5924882889  1.3127232790  1.6108667850   \n",
              "\n",
              "      txt_vec49     txt_vec50     txt_vec51     txt_vec52     txt_vec53  \\\n",
              "0 -0.0231464375 -0.7036052942  2.1469361782  3.9448320866 -3.0985984802   \n",
              "1  0.2388433963  0.5705102682  0.0946367979  2.5407283306 -1.4612874985   \n",
              "2  1.9155689478 -1.8057124615  1.4768242836  1.4456773996 -4.2865915298   \n",
              "3  1.3513327837  1.4120253325  5.8572702408  2.9551832676 -5.2905402184   \n",
              "4  0.9940723181 -1.1959708929  1.7814975977  1.7854963541 -4.0715527534   \n",
              "\n",
              "      txt_vec54     txt_vec55     txt_vec56     txt_vec57     txt_vec58  \\\n",
              "0  2.5134534836 -5.3958601952  0.7621323466  2.8018035889  0.8779643178   \n",
              "1  0.8664698601 -0.8825763464 -1.6469770670  1.9151748419  2.8002102375   \n",
              "2  3.8664577007 -4.0532517433 -0.5716705322  2.1306719780  1.0535889864   \n",
              "3  3.9502623081 -1.0030276775 -0.6423271894 -0.7421406507  1.8295041323   \n",
              "4  2.6540911198 -5.9325356483 -0.4189185500 -0.9260056019 -0.5426020026   \n",
              "\n",
              "      txt_vec59     txt_vec60     txt_vec61     txt_vec62     txt_vec63  \\\n",
              "0 -0.5859798193  1.9625556469 -5.1712174416  1.1816873550  0.5419528484   \n",
              "1  1.4765350819  2.3451476097 -1.6753772497 -2.9482414722  4.3225460052   \n",
              "2  0.1100640595  2.8935914040 -4.3589577675 -1.0194541216  0.3668791652   \n",
              "3 -0.3699176610  0.5510581136 -4.0429396629 -1.8587552309  1.1932451725   \n",
              "4  0.4626600146  1.4631899595 -4.1606488228  0.1747602522  0.0668889135   \n",
              "\n",
              "      txt_vec64     txt_vec65     txt_vec66     txt_vec67     txt_vec68  \\\n",
              "0  0.4858333170  4.2125682831  3.4581983089  1.4029390812 -0.5462926030   \n",
              "1  0.0064851381  1.5961343050  1.7408252954  2.5171482563  1.6526031494   \n",
              "2  1.8413580656  4.1702466011  4.1743388176  1.2625701427 -0.0290785655   \n",
              "3  0.5523794889  0.8406279087 -0.1998117566 -0.5318464041  0.5840061307   \n",
              "4  1.9713603258  1.9823232889  2.5010893345  0.2407858074 -0.5280813575   \n",
              "\n",
              "      txt_vec69     txt_vec70     txt_vec71     txt_vec72     txt_vec73  \\\n",
              "0  2.1821005344 -0.0962546766  1.7366081476  0.6851462722 -1.6132848263   \n",
              "1  2.3012015820 -1.8203756809  0.3131376207 -0.4605118036 -1.4658217430   \n",
              "2  0.3916682005  0.8510245085  2.0302724838 -0.5232113004 -2.9885025024   \n",
              "3  0.2384417951 -0.1831949651 -0.9647368193  0.0030380934 -3.8698849678   \n",
              "4  0.9364103079 -0.2675441802  1.1475917101  0.2777195573 -1.5763708353   \n",
              "\n",
              "      txt_vec74     txt_vec75     txt_vec76     txt_vec77     txt_vec78  \\\n",
              "0 -0.9128761888 -0.5323970318  1.7248421907  2.2641146183 -2.2597558498   \n",
              "1  0.0256607905  0.1975094974  0.9521799088  1.8086135387 -3.9243142605   \n",
              "2  0.4683658183  2.1632678509  2.6002571583  3.4216189384 -3.7261285782   \n",
              "3  0.1377555430  2.9626429081  0.8658820391  4.0657339096 -2.1266815662   \n",
              "4 -1.3750151396  2.2555143833  2.0386326313  3.8130803108 -2.5444471836   \n",
              "\n",
              "      txt_vec79     txt_vec80     txt_vec81     txt_vec82     txt_vec83  \\\n",
              "0  4.5065088272 -0.3460883200  0.9281976819 -2.0782611370 -0.1955756247   \n",
              "1  0.8740619421  1.5076384544 -1.4749593735 -0.7281465530  1.6809406281   \n",
              "2  3.6566011906  1.3187823296  1.9449762106 -1.1189107895  2.6336503029   \n",
              "3 -0.1394288242 -0.0651780367  0.0671006665 -1.7295682430  3.5149486065   \n",
              "4  2.7090351582 -1.2576792240  1.2818650007 -0.3754705787  1.0863946676   \n",
              "\n",
              "      txt_vec84     txt_vec85     txt_vec86     txt_vec87     txt_vec88  \\\n",
              "0  4.8475780487 -2.9586863518  1.0060796738  2.0822322369 -2.2596824169   \n",
              "1 -2.2752487659  0.1606744528 -1.1758519411  2.7073900700 -1.5404677391   \n",
              "2  1.9950672388 -1.3083131313 -1.9136729240  1.8380401134 -4.9061074257   \n",
              "3  1.6050981283  0.6517529488 -1.3164319992  0.4306410849 -0.9936897755   \n",
              "4  3.9390137196 -0.7524920106 -0.4735445082  0.2154830545 -3.9462544918   \n",
              "\n",
              "      txt_vec89     txt_vec90     txt_vec91     txt_vec92     txt_vec93  \\\n",
              "0 -2.0333144665  0.2182324231  3.9753122330  2.0034470558 -0.2406283617   \n",
              "1 -1.7555799484  1.2667036057  0.5049359202  1.0696272850  1.8924552202   \n",
              "2 -3.0755031109 -0.6857675910  2.5223836899  0.5497792959  1.4827349186   \n",
              "3 -4.6938705444 -1.9676889181  3.2283120155  1.3695452213 -0.1332462430   \n",
              "4 -1.3390405178 -0.5571385622  1.8416041136 -0.2635599077 -0.5724999309   \n",
              "\n",
              "      txt_vec94     txt_vec95     txt_vec96     txt_vec97     txt_vec98  \\\n",
              "0 -2.4685480595  1.6660641432 -2.0819606781 -2.4968724251 -1.9016369581   \n",
              "1 -2.8700709343  1.3147110939 -0.6476105452 -3.8642375469 -1.1287094355   \n",
              "2  0.8170077205  1.9330986738 -2.5392942429 -0.4976403117 -1.0175911188   \n",
              "3  0.4559089541 -0.9183557034 -1.4347511530  0.9158083797  0.4877495468   \n",
              "4  1.6691718102 -0.0412875786 -1.7513698339 -0.9225690961 -0.8901174664   \n",
              "\n",
              "      txt_vec99    txt_vec100    txt_vec101    txt_vec102    txt_vec103  \\\n",
              "0  0.2714739740 -2.2981684208 -1.7873090506  1.6180669069 -2.9975774288   \n",
              "1 -0.2163546234  0.0200870410 -1.0009949207  1.8183261156 -1.2894283533   \n",
              "2 -2.7609453201 -1.8073147535 -3.6103582382  4.2451257706 -4.4561161995   \n",
              "3  1.0235780478 -0.0599985197 -4.7873816490 -1.5516570807 -3.0073292255   \n",
              "4 -0.7344263792 -0.1985396743 -4.6947107315  2.3384141922 -3.1651930809   \n",
              "\n",
              "     txt_vec104    txt_vec105    txt_vec106    txt_vec107    txt_vec108  \\\n",
              "0  0.0420643799 -1.2196398973 -2.3956730366  5.6090831757 -1.4914845228   \n",
              "1  1.3204821348  0.9189465046  2.3127784729  0.9761807323 -1.1034594774   \n",
              "2  1.7062046528 -3.1820578575  0.1201333702  4.3089995384 -3.7071764469   \n",
              "3  2.0735120773 -3.4647843838 -2.7820105553 -0.0993154496 -4.0383219719   \n",
              "4 -0.6592266560 -2.2427787781 -0.2026949227  2.8271911144 -3.3360562325   \n",
              "\n",
              "     txt_vec109    txt_vec110    txt_vec111    txt_vec112    txt_vec113  \\\n",
              "0  1.7885915041  4.1772522926  4.4608173370 -1.2361496687 -2.0794692039   \n",
              "1 -1.2471879721 -2.9002075195  1.2914571762  1.5193878412 -0.8292294741   \n",
              "2  3.7954654694  2.0711903572  3.6382451057 -2.5796868801  1.3196798563   \n",
              "3 -0.8915926218  0.6951371431  3.5863361359  1.0518940687  1.5735805035   \n",
              "4  3.8229005337  0.8821620941  2.8626224995 -2.6367087364  0.5635325909   \n",
              "\n",
              "     txt_vec114    txt_vec115    txt_vec116    txt_vec117    txt_vec118  \\\n",
              "0 -4.3971495628  0.3652189076  0.8151836395  5.4751114845  4.2397766113   \n",
              "1 -2.4343063831 -0.7656114101  0.6017384529  3.1130170822  0.7010914087   \n",
              "2 -3.7506515980  2.7014789581 -0.2162129283  5.0864233971  2.7782700062   \n",
              "3 -4.2804646492  3.1986303329 -2.7923855782  3.2322039604 -3.1985409260   \n",
              "4 -2.7188420296  2.0029742718  1.4403909445  4.0350317955  0.6819838881   \n",
              "\n",
              "     txt_vec119    txt_vec120    txt_vec121    txt_vec122    txt_vec123  \\\n",
              "0  0.9392179847  1.1986280680 -1.4769824743 -1.5552177429  0.3611471355   \n",
              "1  0.5787922144  0.5351995230 -0.9441672564 -0.1240377501 -1.4508235455   \n",
              "2  3.9552774429  0.3138726354 -2.3330941200  0.2004831731  0.6144545674   \n",
              "3  2.5838351250 -1.2322738171 -2.7884037495  1.4736993313 -3.1015565395   \n",
              "4  4.4928522110 -0.8764061332 -2.3473026752  0.0668368563 -1.4170516729   \n",
              "\n",
              "     txt_vec124    txt_vec125    txt_vec126    txt_vec127      img_vec0  \\\n",
              "0  2.0227699280 -1.5996438265  3.2231538296 -1.4574943781 -2.8722801208   \n",
              "1  0.3650854230 -1.1901761293  1.6859598160  0.8126941919 -0.0705208853   \n",
              "2 -0.2370703667 -5.3172769547  4.8742480278  0.5578527451 -5.1803641319   \n",
              "3 -0.9659563899 -3.5598251820  4.0261893272  1.3633310795 -1.0772739649   \n",
              "4 -0.0014237612 -3.9701452255  4.4187226295  0.2834067345 -3.2601945400   \n",
              "\n",
              "       img_vec1      img_vec2      img_vec3      img_vec4      img_vec5  \\\n",
              "0  1.4587551355  2.5790126324 -1.6097468138  1.4378223419  1.3874959946   \n",
              "1 -1.4393335581  0.7728728056 -2.3489952087 -0.2355124950 -0.8700022697   \n",
              "2 -0.3882471323 -0.0362354293 -1.8510223627  1.2238538265  1.9967815876   \n",
              "3  2.8394529819  1.1834309101 -1.0987117290  0.9005973339  1.4222483635   \n",
              "4  0.4988903403  2.5831427574 -2.5513806343  1.4665173292 -0.1956336200   \n",
              "\n",
              "       img_vec6      img_vec7      img_vec8      img_vec9     img_vec10  \\\n",
              "0  0.7249992490  0.0203323103  0.3120986819 -1.9997732639 -1.8057322502   \n",
              "1 -0.5425865054  1.5831973553  1.7427791357 -2.9939756393 -0.8622460961   \n",
              "2  0.7940438390 -0.2907482982  0.3932960033 -1.1030144691 -2.6933064461   \n",
              "3  0.1098280475 -3.7701313496  0.1382257044 -3.4304034710 -1.1713567972   \n",
              "4  1.2730638981  0.4443459213  1.9116442204 -1.8641946316  0.4185179174   \n",
              "\n",
              "      img_vec11     img_vec12     img_vec13     img_vec14     img_vec15  \\\n",
              "0 -0.1739237309 -2.1751496792 -0.4395467937 -1.8935351372 -0.7034621835   \n",
              "1 -1.2157950401 -2.3686754704  2.3326988220  1.9421590567  1.1301317215   \n",
              "2  1.2588562965 -1.9516181946 -1.6696166992 -1.3041158915 -0.7412303686   \n",
              "3 -1.2840040922 -0.0544508547 -2.2876307964 -0.5878560543 -3.7379798889   \n",
              "4 -2.4434888363 -1.9919613600 -0.6361541748 -1.0268591642 -0.8774957061   \n",
              "\n",
              "      img_vec16     img_vec17     img_vec18     img_vec19     img_vec20  \\\n",
              "0 -1.9535105228  0.6914859414  0.6445956826  2.0112810135 -0.4342123568   \n",
              "1 -2.5715732574  2.0020222664  3.8542828560 -0.4467480779  0.3667028844   \n",
              "2 -1.9874830246  1.1826648712  0.1876281202  2.8795382977 -1.4945707321   \n",
              "3 -0.7720518112  0.6717689037  1.4492791891 -0.1424507499 -0.6465058327   \n",
              "4  0.7087628841  1.8621208668  0.8565728068  1.7871872187 -0.2045107186   \n",
              "\n",
              "      img_vec21     img_vec22     img_vec23     img_vec24     img_vec25  \\\n",
              "0  2.6146309376  2.1234035492 -2.8775033951  1.0714125633  0.4730164111   \n",
              "1  0.3724231422 -1.9866981506 -0.1244335026 -2.7045094967 -2.9197115898   \n",
              "2  4.8454046249  1.6018526554 -2.2582504749  0.6056196094  1.3605409861   \n",
              "3  2.2852480412 -1.3476312160 -0.3918263912  0.2032637298 -0.4844906628   \n",
              "4  1.8074589968 -1.2486822605 -2.0458302498 -0.6823843718 -1.0407505035   \n",
              "\n",
              "      img_vec26     img_vec27     img_vec28     img_vec29     img_vec30  \\\n",
              "0  2.4707813263 -1.6296484470 -2.5948154926  2.1294517517 -1.0729905367   \n",
              "1 -3.0368967056 -1.1918561459 -2.3457062244  1.7503809929 -0.7577392459   \n",
              "2  2.2704613209 -2.3936748505 -2.5237107277  2.3623688221 -3.7879507542   \n",
              "3 -2.1060159206 -3.5996644497 -4.4429578781  1.7781949043 -4.1688241959   \n",
              "4 -0.1911843121 -1.1757192612 -3.0022175312  1.3092085123  0.7799966335   \n",
              "\n",
              "      img_vec31     img_vec32     img_vec33     img_vec34     img_vec35  \\\n",
              "0  2.4951767921 -0.6153161526 -0.3726658523  1.4416368008 -0.3869579732   \n",
              "1  0.7082000375 -2.0362606049 -1.2478457689  1.3371763229  0.3810861111   \n",
              "2  4.1489663124  0.5273576379 -0.4623291790  1.9587676525 -0.5154456496   \n",
              "3  2.1066026688 -2.6107659340 -4.6652832031  4.2292447090  1.1606259346   \n",
              "4  1.5844647884 -0.2545006573 -1.9702123404  2.6014389992  0.7656390667   \n",
              "\n",
              "      img_vec36     img_vec37     img_vec38     img_vec39     img_vec40  \\\n",
              "0  0.5742669106  0.2901403606  2.1439840794 -2.1797549725  1.0018137693   \n",
              "1 -2.1957163811  2.3492677212  3.2342376709 -1.0737447739  2.7275660038   \n",
              "2  0.6768915653 -0.3047086000  0.1290760487 -1.6329034567 -0.4164456129   \n",
              "3  1.1377283335  0.3503388762  3.7622182369 -1.5629478693  3.2892580032   \n",
              "4 -0.3065223992  1.4117398262  2.0450096130 -1.4351650476  0.6078616381   \n",
              "\n",
              "      img_vec41     img_vec42     img_vec43     img_vec44     img_vec45  \\\n",
              "0  1.7092645168  1.7659958601 -0.9781475067  2.3762657642  1.2863856554   \n",
              "1  2.1341414452  1.3165485859  1.4014288187  0.3226478398  1.5204454660   \n",
              "2  0.2012564689  1.5046161413 -1.8403992653  0.7415528893  1.1971130371   \n",
              "3  0.6765853763 -1.1160399914 -2.3792004585  0.3785956204  0.5143413544   \n",
              "4  1.8148971796  1.9150559902  1.3558405638  0.3710158169  1.5915417671   \n",
              "\n",
              "      img_vec46     img_vec47     img_vec48     img_vec49     img_vec50  \\\n",
              "0 -1.4987120628 -2.1206870079 -1.6261025667 -1.7383675575 -0.2232712805   \n",
              "1 -1.5553992987 -1.7593723536 -0.5223306417 -2.0628519058  1.2358421087   \n",
              "2  0.4738982022 -0.9263385534  0.7251952887 -2.4600844383  0.6102679968   \n",
              "3  3.4223504066  1.5008887053 -2.3732028008  1.3730483055 -1.8183721304   \n",
              "4 -1.3562458754 -2.0786681175 -1.4965167046 -1.5357089043  0.5223278999   \n",
              "\n",
              "      img_vec51     img_vec52     img_vec53     img_vec54     img_vec55  \\\n",
              "0  1.2644373178 -0.9871305823 -1.9093743563  2.2314555645 -2.6836464405   \n",
              "1  0.1661762446 -3.3796861172 -2.2228477001  1.6136515141  0.7360733747   \n",
              "2  2.4189102650 -0.8073080182 -2.4715397358  2.5514853001 -1.8118276596   \n",
              "3  0.2093314379 -4.0995993614 -2.2917511463  1.7036482096 -1.7782133818   \n",
              "4  1.3364672661 -2.0848152637 -2.3919889927  1.2798339128 -0.4796919227   \n",
              "\n",
              "      img_vec56     img_vec57     img_vec58     img_vec59     img_vec60  \\\n",
              "0 -0.6353181005  0.0858888105 -0.8235075474  0.5569828153  2.5153543949   \n",
              "1 -2.1893527508  1.2845479250  2.8726134300  2.6761150360  0.1475290209   \n",
              "2  0.1008770168  0.7436977029 -1.1163951159 -0.3596743941  3.0285360813   \n",
              "3  0.2453990728 -3.7033028603  1.4522143602  2.1704957485  1.1902852058   \n",
              "4  0.8068606853  0.0033650771  0.1334796101  1.9405741692  0.3472729027   \n",
              "\n",
              "      img_vec61     img_vec62     img_vec63     img_vec64     img_vec65  \\\n",
              "0 -3.4205298424  0.0634656399  0.0094741732 -0.0657508075 -1.0753654242   \n",
              "1 -1.3171087503 -2.6440515518 -1.8350887299  0.9574174285 -2.3858914375   \n",
              "2 -2.4324274063  1.5074805021  1.7838965654 -0.2175149024 -2.6842575073   \n",
              "3 -2.3954641819 -0.1170736402  0.6126937270 -4.3434071541 -3.7077896595   \n",
              "4 -3.2160534859 -1.1251442432 -0.4129741192 -0.4549874365 -1.5074959993   \n",
              "\n",
              "      img_vec66     img_vec67     img_vec68     img_vec69     img_vec70  \\\n",
              "0 -2.9713089466  1.0196198225  2.5095589161 -1.5258373022  0.5425801277   \n",
              "1 -0.6619012356  2.6582648754 -0.9451054931 -1.0119893551 -0.6547811627   \n",
              "2 -2.6698846817  1.3063540459  2.1978611946  0.2396692932  0.6746810079   \n",
              "3 -1.9681696892  1.6769342422 -1.6965925694  0.8841276169  1.8131419420   \n",
              "4 -1.0031266212  1.4596577883  0.3572512269 -1.2548041344 -0.3108480573   \n",
              "\n",
              "      img_vec71     img_vec72     img_vec73     img_vec74     img_vec75  \\\n",
              "0 -0.2697300315 -0.0359621942  0.3917995691 -1.2341160774  2.3140294552   \n",
              "1 -0.3363517821 -2.1268010139  1.3375129700 -1.0618399382  0.4118506312   \n",
              "2 -0.1925708055 -0.1629413515  2.5120844841 -1.0960826874  3.5255630016   \n",
              "3  1.8550761938  1.3032124043  2.0474886894  0.6032235622  3.9587745667   \n",
              "4 -1.8746677637 -1.0605058670  0.0878456458 -1.9225060940  1.1394615173   \n",
              "\n",
              "      img_vec76     img_vec77     img_vec78     img_vec79     img_vec80  \\\n",
              "0  1.8986169100 -2.3611283302  0.3124046326  3.4446072578 -0.8862501383   \n",
              "1  0.2462557554 -2.2640297413  2.3994200230  2.0248627663  0.1704825163   \n",
              "2  1.0564339161 -2.1295158863 -0.0054923594  3.8271811008 -0.3581976295   \n",
              "3  3.7462685108 -3.4980876446 -0.7330384254 -0.9137355089 -1.2961897850   \n",
              "4  0.2324949801 -1.6677292585  1.0865254402  3.2355041504 -1.3600406647   \n",
              "\n",
              "      img_vec81     img_vec82     img_vec83     img_vec84     img_vec85  \\\n",
              "0 -1.3436369896  0.9544589520  0.6308349371 -2.3947217464  0.6834869981   \n",
              "1 -0.0392032042 -1.5066767931 -1.9459319115 -0.0202283077 -0.4954991639   \n",
              "2 -2.0093791485 -0.2243905813  0.8038508296 -0.9094979167  0.9628103375   \n",
              "3  4.8217391968  0.6872349381 -1.4064308405  0.6691839695 -1.8475983143   \n",
              "4 -0.5736263990 -0.3438729644 -0.8621111512 -3.0362601280 -1.0166102648   \n",
              "\n",
              "      img_vec86     img_vec87     img_vec88     img_vec89     img_vec90  \\\n",
              "0  1.1490038633 -1.3511732817  2.0239000320  1.5991983414  1.3828682899   \n",
              "1 -0.1410129666 -1.6175206900  2.6246759892 -2.5819215775  0.2208910137   \n",
              "2  2.6015825272  0.0563275069  1.8594735861 -0.3161342740 -1.1312859058   \n",
              "3 -0.8170750737 -1.1811718941  2.5885522366 -1.1231178045  0.2324265391   \n",
              "4 -1.1497695446  0.4641397595  2.4124057293 -0.6541346908  0.4868938923   \n",
              "\n",
              "      img_vec91     img_vec92     img_vec93     img_vec94     img_vec95  \\\n",
              "0  1.6056783199  1.8806668520 -0.5081608891  0.2428404391 -0.2608487904   \n",
              "1  0.3287933767  0.6477577090  0.2319895625  1.1014859676  1.0795272589   \n",
              "2  1.7012784481  2.3054049015 -1.9412707090  1.2480015755  0.2910004854   \n",
              "3  2.1703250408  0.5794144869  2.6014208794 -0.5961964726 -1.7986934185   \n",
              "4  1.1680536270 -0.2714197040  0.6670907736  1.1635572910 -0.1322363019   \n",
              "\n",
              "      img_vec96     img_vec97     img_vec98     img_vec99    img_vec100  \\\n",
              "0  1.8759434223  0.2061345726  0.1869730353  2.0474455357 -0.5754722953   \n",
              "1  2.9531016350 -0.5286824107 -1.1405997276 -0.3732994497  0.1098105833   \n",
              "2  0.7920667529  1.3611664772  1.1290049553  1.9474035501 -0.8594229817   \n",
              "3  0.3123261333  0.3874855340 -2.2073650360 -1.0293287039 -1.2742329836   \n",
              "4  0.6684629917 -0.2281846255  0.1557677239  1.5468212366  0.3076400459   \n",
              "\n",
              "     img_vec101    img_vec102    img_vec103    img_vec104    img_vec105  \\\n",
              "0  3.0164101124  2.7571456432  3.3537209034 -0.4572715461 -0.1253366172   \n",
              "1  2.8135411739  0.5969979167  1.7548358440 -1.3597713709  0.4665011466   \n",
              "2  2.0232229233  2.3486514091  4.5061273575  0.6844365001  2.0649919510   \n",
              "3  2.0472295284  1.9285165071  2.1026327610 -0.5593834519 -0.9514183998   \n",
              "4  2.5429413319  1.2409851551  2.1445691586 -1.0797533989  0.3351914585   \n",
              "\n",
              "     img_vec106    img_vec107    img_vec108    img_vec109    img_vec110  \\\n",
              "0  2.3329634666  3.8589668274 -2.0754899979 -0.7054958344  0.2034520507   \n",
              "1  2.3774173260 -0.1806525588 -3.2593042850  0.1208329052  2.2256433964   \n",
              "2  0.0229008049  3.4642429352 -2.3252725601  0.1313239187 -1.8761780262   \n",
              "3 -2.0217494965  1.3662722111 -1.9472106695 -2.1144192219  1.1403938532   \n",
              "4  0.2451588660  2.1501686573 -1.9914399385 -2.3307268620  0.7368552089   \n",
              "\n",
              "     img_vec111    img_vec112    img_vec113    img_vec114    img_vec115  \\\n",
              "0  1.7197328806  2.9250385761 -0.3886387944  1.2257323265 -1.7731370926   \n",
              "1  2.2205066681 -1.1789444685 -0.8213667870  0.7172386646 -1.4558292627   \n",
              "2  1.7703540325  2.9251759052 -1.8510544300 -0.0925873220 -0.5807421207   \n",
              "3 -0.7960235476  1.9063613415 -0.3575199842  3.3529679775 -3.9963769913   \n",
              "4  2.1269307137  0.5560612679 -1.6114931107  2.7221329212 -1.1859402657   \n",
              "\n",
              "     img_vec116    img_vec117    img_vec118    img_vec119    img_vec120  \\\n",
              "0  0.0526551157  1.2799222469 -3.3747272491 -1.5069689751 -1.8201801777   \n",
              "1 -1.2605844736  2.6234674454 -0.5383300781 -2.6201636791  1.2771952152   \n",
              "2 -0.4220193028  0.9237140417 -4.5827107430 -1.0569097996 -2.5680844784   \n",
              "3  1.5203311443 -0.0007160828 -0.4876829982 -1.8891189098  0.9430151582   \n",
              "4  0.3992010057  1.5986174345 -0.6214751601 -2.0914101601  0.5015996695   \n",
              "\n",
              "     img_vec121    img_vec122    img_vec123    img_vec124    img_vec125  \\\n",
              "0 -3.0246436596  0.4452633858  0.0139333047 -1.3002386093  2.7599484921   \n",
              "1  0.6010145545 -0.3453120291  0.9934566021  1.3516329527  2.1626746655   \n",
              "2 -2.0380613804  2.5087187290 -0.7647889853 -0.6571162343  3.2527816296   \n",
              "3 -2.8344175816  1.6331835985  2.0018005371 -2.3331520557  2.6455948353   \n",
              "4 -3.0838639736 -1.0600911379  2.0536000729 -2.0250082016  2.3992507458   \n",
              "\n",
              "     img_vec126    img_vec127  \n",
              "0  2.0561711788  0.5087034702  \n",
              "1  2.7685971260 -0.9371970296  \n",
              "2  2.6873664856  0.8443320990  \n",
              "3  2.2802333832 -0.6944484115  \n",
              "4  2.5623166561  0.6941336393  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yhL4Dg5bV_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#combine\n",
        "df_txt_vec = df_item[['item_id'] + ['txt_vec' + str(i) for i in range(128)]]\n",
        "df_txt_vec['item_txt_vec'] = df_txt_vec.apply(lambda x: np.array(x.values[1:].tolist()), axis=1)\n",
        "items = df_txt_vec['item_id'].values.tolist()\n",
        "txt_vecs = df_txt_vec['item_txt_vec'].values.tolist()\n",
        "df_txt_vec[['item_id','item_txt_vec']].to_pickle('kdd2020_data/my_model/item_txt_vec.pkl')\n",
        "\n",
        "item_vec_map = dict(zip(items, txt_vecs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86fKa0LUbwmT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "727841cf-48a8-462d-b697-37eddf02ae78"
      },
      "source": [
        "# setup index for item_txt \n",
        "index_to_item_dict = {}\n",
        "item_to_index_dict = {}\n",
        "\n",
        "item_index = AnnoyIndex(128, 'angular')\n",
        "item_index.set_seed(2020)\n",
        "\n",
        "for i, row in tqdm(df_item.iterrows()):\n",
        "    emb = row[-128 - 128:-128].values\n",
        "\n",
        "    item = row[0]\n",
        "    index_to_item_dict[i] = item\n",
        "    item_to_index_dict[item] = i\n",
        "\n",
        "    item_index.add_item(i, emb)\n",
        "\n",
        "item_index.build(100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "108916it [00:22, 4802.68it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXhMUVAmclPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rec3(df_qtime, user_embs, item_index, index_to_item_dict):\n",
        "    data_list = []\n",
        "    for user_id, query_time, item_id, phase in tqdm(df_qtime.values):\n",
        "        user_emb = user_embs[user_id]\n",
        "        ids, distances = item_index.get_nns_by_vector(user_emb,100,include_distances=True)\n",
        "        item_ids = [index_to_item_dict[id] for id in ids]\n",
        "        # the smaller distance, the higher score\n",
        "        item_sim_scores = [2 - distance for distance in distances]\n",
        "\n",
        "        df_temp = pd.DataFrame()\n",
        "        df_temp['item_id'] = item_ids\n",
        "        df_temp['sim_score'] = item_sim_scores\n",
        "        df_temp['user_id'] = user_id\n",
        "        df_temp['query_time'] = query_time\n",
        "        df_temp['phase'] = phase\n",
        "\n",
        "        if item_id == -1:\n",
        "            df_temp['label'] = np.nan\n",
        "        else:\n",
        "            df_temp['label'] = 0\n",
        "            df_temp.loc[df_temp['item_id'] == item_id, 'label'] = 1\n",
        "\n",
        "        df_temp.sort_values(['sim_score'], inplace=True, ascending=False)\n",
        "\n",
        "        df_temp = df_temp[['user_id', 'phase', 'query_time', 'item_id', 'sim_score', 'label']]\n",
        "        df_temp['user_id'] = df_temp['user_id'].astype('int')\n",
        "        df_temp['item_id'] = df_temp['item_id'].astype('int')\n",
        "\n",
        "        data_list.append(df_temp)\n",
        "\n",
        "    df_data = pd.concat(data_list, sort=False)\n",
        "    return df_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B34v27_jdgDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@multitasking.task\n",
        "def work(phase, force=False):\n",
        "    os.makedirs('kdd2020_data/my_model/recall_3', exist_ok=True)\n",
        "\n",
        "    if force or (not os.path.exists('kdd2020_data/my_model/recall_3/user_txt_vec_{}.pkl'.format(phase))\n",
        "                 or not os.path.exists('kdd2020_data/my_model/recall_3/recall_{}.pkl'.format(phase))):\n",
        "      \n",
        "        df_click_phase = df_click[df_click['phase'] == phase]\n",
        "\n",
        "        tmp = df_click_phase.groupby('user_id', as_index=False)['item_id'].agg({'list': list})\n",
        "        sentences = tmp['list'].values.tolist()\n",
        "        del tmp['list']\n",
        "\n",
        "        emb_matrix = []\n",
        "        for seq in sentences:\n",
        "            seq = seq[::-1]\n",
        "\n",
        "            vec = []\n",
        "            for pos, w in enumerate(seq):\n",
        "                if w in item_vec_map.keys():\n",
        "                    vec.append(np.asarray(item_vec_map[w]) * (0.7**pos))\n",
        "            if len(vec) > 0:\n",
        "            #we get the seq vec by average all the item's vec in the seq\n",
        "                emb_matrix.append(np.mean(vec, axis=0))\n",
        "            else:\n",
        "                emb_matrix.append([0] * 128)\n",
        "\n",
        "        df_user_txt_vec = tmp\n",
        "        df_user_txt_vec['user_txt_vec'] = emb_matrix\n",
        "        df_user_txt_vec['phase'] = phase\n",
        "        df_user_txt_vec.to_pickle('kdd2020_data/my_model/recall_3/user_txt_vec_{}.pkl'.format(phase))\n",
        "\n",
        "        users = tmp['user_id'].values.tolist()\n",
        "        user_embs = dict(zip(users, emb_matrix))\n",
        "\n",
        "        df_qtime_phase = df_qtime[df_qtime['phase'] == phase]\n",
        "        df_data = rec3(df_qtime_phase, user_embs, item_index,index_to_item_dict)\n",
        "        df_data.to_pickle('kdd2020_data/my_model/recall_3/recall_{}.pkl'.format(phase))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzyS7GRseM5t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "77652067-d23a-460a-d787-46da0faad53e"
      },
      "source": [
        "force = False\n",
        "\n",
        "for phase in phases:\n",
        "    work(phase, force)\n",
        "\n",
        "multitasking.wait_for_tasks()\n",
        "print('over')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18398/18398 [08:14<00:00, 37.24it/s]\n",
            "100%|██████████| 18505/18505 [08:22<00:00, 36.80it/s]\n",
            "100%|██████████| 18672/18672 [08:29<00:00, 36.63it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "over\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28dgCfWYglge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(df, median_item_degree, item_degree_map, num_cases_full, num_cases_half):\n",
        "    gg = df.groupby(['user_id'])\n",
        "\n",
        "    ndcg_50_full = 0.0\n",
        "    hitrate_50_full = 0.0\n",
        "\n",
        "    ndcg_50_half = 0.0\n",
        "    hitrate_50_half = 0.0\n",
        "\n",
        "    for _, g in tqdm(gg):\n",
        "        try:\n",
        "            item_id = g[g['label'] == 1]['item_id'].values[0]\n",
        "            item_degree = item_degree_map[item_id]\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "        predictions = g['item_id'].values.tolist()\n",
        "\n",
        "        rank = 0\n",
        "        while rank < 50 and predictions[rank] != item_id:\n",
        "            rank += 1\n",
        "\n",
        "        if rank < 50:\n",
        "            ndcg_50_full += 1.0 / np.log2(rank + 2.0)\n",
        "            hitrate_50_full += 1.0\n",
        "\n",
        "        if item_degree <= median_item_degree:\n",
        "            if rank < 50:\n",
        "                ndcg_50_half += 1.0 / np.log2(rank + 2.0)\n",
        "                hitrate_50_half += 1.0\n",
        "\n",
        "    ndcg_50_full /= num_cases_full\n",
        "    hitrate_50_full /= num_cases_full\n",
        "\n",
        "    ndcg_50_half /= num_cases_half\n",
        "    hitrate_50_half /= num_cases_half\n",
        "\n",
        "    return ndcg_50_full, hitrate_50_full, ndcg_50_half, hitrate_50_half"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS-lNdVZgrGb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_scores(df, phase):\n",
        "    df_qtime = pd.read_pickle('kdd2020_data/recall/qtime.pkl')\n",
        "    df_click = pd.read_pickle('kdd2020_data/recall/click.pkl')\n",
        "    \n",
        "    df_qtime = df_qtime[df_qtime['phase']==phase]\n",
        "    df_click = df_click[df_click['phase']==phase]\n",
        "\n",
        "    oof_answer = df_qtime[df_qtime['item_id'] != -1]\n",
        "    num_cases_full = oof_answer.shape[0]\n",
        "\n",
        "    answer_items = oof_answer['item_id'].values\n",
        "    item_degree = df_click['item_id'].value_counts().reset_index()\n",
        "    item_degree.columns = ['item_id', 'degree']\n",
        "\n",
        "    answer_item_degree = item_degree[item_degree['item_id'].isin(answer_items)]\n",
        "    list_item_degress = answer_item_degree['degree'].values.tolist()\n",
        "    median_item_degree = list_item_degress[len(list_item_degress) // 2]\n",
        "    item_degree_map = dict(zip(item_degree['item_id'], item_degree['degree']))\n",
        "    num_cases_half = answer_item_degree[answer_item_degree['degree']\n",
        "                                        <= median_item_degree].shape[0]\n",
        "\n",
        "    ndcg_50_full, hitrate_50_full, ndcg_50_half, hitrate_50_half = evaluate(\n",
        "        df, median_item_degree, item_degree_map, num_cases_full, num_cases_half)\n",
        "    return ndcg_50_full, hitrate_50_full, ndcg_50_half, hitrate_50_half"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXFndWENguLH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "129c63af-c6fa-4770-8013-2c7c42acb0ed"
      },
      "source": [
        "df_user_txt_vec_phase = pd.DataFrame()\n",
        "df_recall = pd.DataFrame()\n",
        "val_score = np.array([0.0, 0.0, 0.0, 0.0])\n",
        "df_user_txt_vec_phase = pd.DataFrame()\n",
        "for phase in phases:\n",
        "    df_user_txt_vec = pd.read_pickle('kdd2020_data/my_model/recall_3/user_txt_vec_{}.pkl'.format(phase))\n",
        "    df_data = pd.read_pickle('kdd2020_data/my_model/recall_3/recall_{}.pkl'.format(phase))\n",
        "\n",
        "    df_user_txt_vec_phase = df_user_txt_vec_phase.append(df_user_txt_vec)\n",
        "    df_recall = df_recall.append(df_data)\n",
        "\n",
        "    score = evaluate_scores(df_data, phase)\n",
        "    val_score += score\n",
        "\n",
        "    print('phase', phase, score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18505/18505 [00:20<00:00, 920.10it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "phase 0 (0.014335585410384724, 0.04666904168151051, 0.017106936269604182, 0.055030094582975066)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18672/18672 [00:19<00:00, 960.31it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "phase 1 (0.014106905161240297, 0.046795704000944176, 0.0170518460540908, 0.056074766355140186)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18398/18398 [00:19<00:00, 934.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "phase 2 (0.013887293792433884, 0.04626526214986833, 0.016732289354645706, 0.05547337278106509)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pashTj_g-0G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "41a27bf4-4bee-4c75-9078-175b90fc236c"
      },
      "source": [
        "df_user_txt_vec_phase.to_pickle('kdd2020_data/my_model/user_txt_vec.pkl')\n",
        "val_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.04232978, 0.13973001, 0.05089107, 0.16657823])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8l8KXtXhPGT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ef5aaf2a-4bbd-420a-f93d-671867d98583"
      },
      "source": [
        "df_recall.sort_values(['user_id', 'phase', 'query_time'], inplace=True)\n",
        "df_recall.to_pickle('kdd2020_data/my_model/recall_3.pkl')\n",
        "df_recall.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>phase</th>\n",
              "      <th>query_time</th>\n",
              "      <th>item_id</th>\n",
              "      <th>sim_score</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>17887</td>\n",
              "      <td>1.8132899106</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>31443</td>\n",
              "      <td>1.7760233581</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>35217</td>\n",
              "      <td>1.7182781398</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>58507</td>\n",
              "      <td>1.6969851553</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>101535</td>\n",
              "      <td>1.6884627044</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  phase    query_time  item_id     sim_score  label\n",
              "0        1    0.0  0.9839419315    17887  1.8132899106    0.0\n",
              "1        1    0.0  0.9839419315    31443  1.7760233581    0.0\n",
              "2        1    0.0  0.9839419315    35217  1.7182781398    0.0\n",
              "3        1    0.0  0.9839419315    58507  1.6969851553    0.0\n",
              "4        1    0.0  0.9839419315   101535  1.6884627044    0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uk-ktoCmos2c",
        "colab_type": "text"
      },
      "source": [
        "# Recall_4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1ZYNa_3ozmz",
        "colab_type": "text"
      },
      "source": [
        "* get item img embedding\n",
        "* calculate distance by Annoy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98ExTZ43o5g0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from annoy import AnnoyIndex\n",
        "import os\n",
        "import warnings\n",
        "import multitasking\n",
        "import signal\n",
        "\n",
        "multitasking.set_max_threads(10)\n",
        "multitasking.set_engine('process')\n",
        "signal.signal(signal.SIGINT, multitasking.killall)\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('precision', 10)\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WamY-NNGo-n2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_qtime = pd.read_pickle('kdd2020_data/recall/qtime.pkl')\n",
        "df_click = pd.read_pickle('kdd2020_data/recall/click.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wh1sd2LtpGa6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "befc0b03-7426-4f76-dcf1-9826d9ec516f"
      },
      "source": [
        "phases = sorted(list(df_qtime['phase'].unique()))\n",
        "phases"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7fUTFF5px0E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "c175c3ac-0742-45f0-a0e5-e42ae2e760d0"
      },
      "source": [
        "df_item = pd.read_csv('kdd2020_data/underexpose_train/underexpose_item_feat.csv',header=None)\n",
        "df_item.columns = ['item_id'] + ['txt_vec' + str(i) for i in range(128)] + ['img_vec' + str(i) for i in range(128)]\n",
        "df_item['txt_vec0'] = df_item['txt_vec0'].apply(lambda x: float(x[1:]))\n",
        "df_item['txt_vec127'] = df_item['txt_vec127'].apply(lambda x: float(x[:-1]))\n",
        "df_item['img_vec0'] = df_item['img_vec0'].apply(lambda x: float(x[1:]))\n",
        "df_item['img_vec127'] = df_item['img_vec127'].apply(lambda x: float(x[:-1]))\n",
        "df_item.drop_duplicates(['item_id'], inplace=True)\n",
        "df_item.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_id</th>\n",
              "      <th>txt_vec0</th>\n",
              "      <th>txt_vec1</th>\n",
              "      <th>txt_vec2</th>\n",
              "      <th>txt_vec3</th>\n",
              "      <th>txt_vec4</th>\n",
              "      <th>txt_vec5</th>\n",
              "      <th>txt_vec6</th>\n",
              "      <th>txt_vec7</th>\n",
              "      <th>txt_vec8</th>\n",
              "      <th>txt_vec9</th>\n",
              "      <th>txt_vec10</th>\n",
              "      <th>txt_vec11</th>\n",
              "      <th>txt_vec12</th>\n",
              "      <th>txt_vec13</th>\n",
              "      <th>txt_vec14</th>\n",
              "      <th>txt_vec15</th>\n",
              "      <th>txt_vec16</th>\n",
              "      <th>txt_vec17</th>\n",
              "      <th>txt_vec18</th>\n",
              "      <th>txt_vec19</th>\n",
              "      <th>txt_vec20</th>\n",
              "      <th>txt_vec21</th>\n",
              "      <th>txt_vec22</th>\n",
              "      <th>txt_vec23</th>\n",
              "      <th>txt_vec24</th>\n",
              "      <th>txt_vec25</th>\n",
              "      <th>txt_vec26</th>\n",
              "      <th>txt_vec27</th>\n",
              "      <th>txt_vec28</th>\n",
              "      <th>txt_vec29</th>\n",
              "      <th>txt_vec30</th>\n",
              "      <th>txt_vec31</th>\n",
              "      <th>txt_vec32</th>\n",
              "      <th>txt_vec33</th>\n",
              "      <th>txt_vec34</th>\n",
              "      <th>txt_vec35</th>\n",
              "      <th>txt_vec36</th>\n",
              "      <th>txt_vec37</th>\n",
              "      <th>txt_vec38</th>\n",
              "      <th>txt_vec39</th>\n",
              "      <th>txt_vec40</th>\n",
              "      <th>txt_vec41</th>\n",
              "      <th>txt_vec42</th>\n",
              "      <th>txt_vec43</th>\n",
              "      <th>txt_vec44</th>\n",
              "      <th>txt_vec45</th>\n",
              "      <th>txt_vec46</th>\n",
              "      <th>txt_vec47</th>\n",
              "      <th>txt_vec48</th>\n",
              "      <th>txt_vec49</th>\n",
              "      <th>txt_vec50</th>\n",
              "      <th>txt_vec51</th>\n",
              "      <th>txt_vec52</th>\n",
              "      <th>txt_vec53</th>\n",
              "      <th>txt_vec54</th>\n",
              "      <th>txt_vec55</th>\n",
              "      <th>txt_vec56</th>\n",
              "      <th>txt_vec57</th>\n",
              "      <th>txt_vec58</th>\n",
              "      <th>txt_vec59</th>\n",
              "      <th>txt_vec60</th>\n",
              "      <th>txt_vec61</th>\n",
              "      <th>txt_vec62</th>\n",
              "      <th>txt_vec63</th>\n",
              "      <th>txt_vec64</th>\n",
              "      <th>txt_vec65</th>\n",
              "      <th>txt_vec66</th>\n",
              "      <th>txt_vec67</th>\n",
              "      <th>txt_vec68</th>\n",
              "      <th>txt_vec69</th>\n",
              "      <th>txt_vec70</th>\n",
              "      <th>txt_vec71</th>\n",
              "      <th>txt_vec72</th>\n",
              "      <th>txt_vec73</th>\n",
              "      <th>txt_vec74</th>\n",
              "      <th>txt_vec75</th>\n",
              "      <th>txt_vec76</th>\n",
              "      <th>txt_vec77</th>\n",
              "      <th>txt_vec78</th>\n",
              "      <th>txt_vec79</th>\n",
              "      <th>txt_vec80</th>\n",
              "      <th>txt_vec81</th>\n",
              "      <th>txt_vec82</th>\n",
              "      <th>txt_vec83</th>\n",
              "      <th>txt_vec84</th>\n",
              "      <th>txt_vec85</th>\n",
              "      <th>txt_vec86</th>\n",
              "      <th>txt_vec87</th>\n",
              "      <th>txt_vec88</th>\n",
              "      <th>txt_vec89</th>\n",
              "      <th>txt_vec90</th>\n",
              "      <th>txt_vec91</th>\n",
              "      <th>txt_vec92</th>\n",
              "      <th>txt_vec93</th>\n",
              "      <th>txt_vec94</th>\n",
              "      <th>txt_vec95</th>\n",
              "      <th>txt_vec96</th>\n",
              "      <th>txt_vec97</th>\n",
              "      <th>txt_vec98</th>\n",
              "      <th>txt_vec99</th>\n",
              "      <th>txt_vec100</th>\n",
              "      <th>txt_vec101</th>\n",
              "      <th>txt_vec102</th>\n",
              "      <th>txt_vec103</th>\n",
              "      <th>txt_vec104</th>\n",
              "      <th>txt_vec105</th>\n",
              "      <th>txt_vec106</th>\n",
              "      <th>txt_vec107</th>\n",
              "      <th>txt_vec108</th>\n",
              "      <th>txt_vec109</th>\n",
              "      <th>txt_vec110</th>\n",
              "      <th>txt_vec111</th>\n",
              "      <th>txt_vec112</th>\n",
              "      <th>txt_vec113</th>\n",
              "      <th>txt_vec114</th>\n",
              "      <th>txt_vec115</th>\n",
              "      <th>txt_vec116</th>\n",
              "      <th>txt_vec117</th>\n",
              "      <th>txt_vec118</th>\n",
              "      <th>txt_vec119</th>\n",
              "      <th>txt_vec120</th>\n",
              "      <th>txt_vec121</th>\n",
              "      <th>txt_vec122</th>\n",
              "      <th>txt_vec123</th>\n",
              "      <th>txt_vec124</th>\n",
              "      <th>txt_vec125</th>\n",
              "      <th>txt_vec126</th>\n",
              "      <th>txt_vec127</th>\n",
              "      <th>img_vec0</th>\n",
              "      <th>img_vec1</th>\n",
              "      <th>img_vec2</th>\n",
              "      <th>img_vec3</th>\n",
              "      <th>img_vec4</th>\n",
              "      <th>img_vec5</th>\n",
              "      <th>img_vec6</th>\n",
              "      <th>img_vec7</th>\n",
              "      <th>img_vec8</th>\n",
              "      <th>img_vec9</th>\n",
              "      <th>img_vec10</th>\n",
              "      <th>img_vec11</th>\n",
              "      <th>img_vec12</th>\n",
              "      <th>img_vec13</th>\n",
              "      <th>img_vec14</th>\n",
              "      <th>img_vec15</th>\n",
              "      <th>img_vec16</th>\n",
              "      <th>img_vec17</th>\n",
              "      <th>img_vec18</th>\n",
              "      <th>img_vec19</th>\n",
              "      <th>img_vec20</th>\n",
              "      <th>img_vec21</th>\n",
              "      <th>img_vec22</th>\n",
              "      <th>img_vec23</th>\n",
              "      <th>img_vec24</th>\n",
              "      <th>img_vec25</th>\n",
              "      <th>img_vec26</th>\n",
              "      <th>img_vec27</th>\n",
              "      <th>img_vec28</th>\n",
              "      <th>img_vec29</th>\n",
              "      <th>img_vec30</th>\n",
              "      <th>img_vec31</th>\n",
              "      <th>img_vec32</th>\n",
              "      <th>img_vec33</th>\n",
              "      <th>img_vec34</th>\n",
              "      <th>img_vec35</th>\n",
              "      <th>img_vec36</th>\n",
              "      <th>img_vec37</th>\n",
              "      <th>img_vec38</th>\n",
              "      <th>img_vec39</th>\n",
              "      <th>img_vec40</th>\n",
              "      <th>img_vec41</th>\n",
              "      <th>img_vec42</th>\n",
              "      <th>img_vec43</th>\n",
              "      <th>img_vec44</th>\n",
              "      <th>img_vec45</th>\n",
              "      <th>img_vec46</th>\n",
              "      <th>img_vec47</th>\n",
              "      <th>img_vec48</th>\n",
              "      <th>img_vec49</th>\n",
              "      <th>img_vec50</th>\n",
              "      <th>img_vec51</th>\n",
              "      <th>img_vec52</th>\n",
              "      <th>img_vec53</th>\n",
              "      <th>img_vec54</th>\n",
              "      <th>img_vec55</th>\n",
              "      <th>img_vec56</th>\n",
              "      <th>img_vec57</th>\n",
              "      <th>img_vec58</th>\n",
              "      <th>img_vec59</th>\n",
              "      <th>img_vec60</th>\n",
              "      <th>img_vec61</th>\n",
              "      <th>img_vec62</th>\n",
              "      <th>img_vec63</th>\n",
              "      <th>img_vec64</th>\n",
              "      <th>img_vec65</th>\n",
              "      <th>img_vec66</th>\n",
              "      <th>img_vec67</th>\n",
              "      <th>img_vec68</th>\n",
              "      <th>img_vec69</th>\n",
              "      <th>img_vec70</th>\n",
              "      <th>img_vec71</th>\n",
              "      <th>img_vec72</th>\n",
              "      <th>img_vec73</th>\n",
              "      <th>img_vec74</th>\n",
              "      <th>img_vec75</th>\n",
              "      <th>img_vec76</th>\n",
              "      <th>img_vec77</th>\n",
              "      <th>img_vec78</th>\n",
              "      <th>img_vec79</th>\n",
              "      <th>img_vec80</th>\n",
              "      <th>img_vec81</th>\n",
              "      <th>img_vec82</th>\n",
              "      <th>img_vec83</th>\n",
              "      <th>img_vec84</th>\n",
              "      <th>img_vec85</th>\n",
              "      <th>img_vec86</th>\n",
              "      <th>img_vec87</th>\n",
              "      <th>img_vec88</th>\n",
              "      <th>img_vec89</th>\n",
              "      <th>img_vec90</th>\n",
              "      <th>img_vec91</th>\n",
              "      <th>img_vec92</th>\n",
              "      <th>img_vec93</th>\n",
              "      <th>img_vec94</th>\n",
              "      <th>img_vec95</th>\n",
              "      <th>img_vec96</th>\n",
              "      <th>img_vec97</th>\n",
              "      <th>img_vec98</th>\n",
              "      <th>img_vec99</th>\n",
              "      <th>img_vec100</th>\n",
              "      <th>img_vec101</th>\n",
              "      <th>img_vec102</th>\n",
              "      <th>img_vec103</th>\n",
              "      <th>img_vec104</th>\n",
              "      <th>img_vec105</th>\n",
              "      <th>img_vec106</th>\n",
              "      <th>img_vec107</th>\n",
              "      <th>img_vec108</th>\n",
              "      <th>img_vec109</th>\n",
              "      <th>img_vec110</th>\n",
              "      <th>img_vec111</th>\n",
              "      <th>img_vec112</th>\n",
              "      <th>img_vec113</th>\n",
              "      <th>img_vec114</th>\n",
              "      <th>img_vec115</th>\n",
              "      <th>img_vec116</th>\n",
              "      <th>img_vec117</th>\n",
              "      <th>img_vec118</th>\n",
              "      <th>img_vec119</th>\n",
              "      <th>img_vec120</th>\n",
              "      <th>img_vec121</th>\n",
              "      <th>img_vec122</th>\n",
              "      <th>img_vec123</th>\n",
              "      <th>img_vec124</th>\n",
              "      <th>img_vec125</th>\n",
              "      <th>img_vec126</th>\n",
              "      <th>img_vec127</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>42844</td>\n",
              "      <td>4.5149450302</td>\n",
              "      <td>-2.3837196827</td>\n",
              "      <td>0.5004140139</td>\n",
              "      <td>0.4070682824</td>\n",
              "      <td>-1.9952288866</td>\n",
              "      <td>0.1090780124</td>\n",
              "      <td>-0.6917753220</td>\n",
              "      <td>2.2274599075</td>\n",
              "      <td>-6.4379744530</td>\n",
              "      <td>-0.8248971701</td>\n",
              "      <td>-0.1387242377</td>\n",
              "      <td>-0.3793291748</td>\n",
              "      <td>0.6276600957</td>\n",
              "      <td>0.4183767140</td>\n",
              "      <td>4.4412183762</td>\n",
              "      <td>0.2998193502</td>\n",
              "      <td>0.5785568357</td>\n",
              "      <td>-4.6992893219</td>\n",
              "      <td>-0.3947401643</td>\n",
              "      <td>-2.3916513920</td>\n",
              "      <td>0.3705316782</td>\n",
              "      <td>-1.3554661274</td>\n",
              "      <td>-1.0741775036</td>\n",
              "      <td>-2.3216402531</td>\n",
              "      <td>-0.3324561715</td>\n",
              "      <td>0.1238859445</td>\n",
              "      <td>-2.4391555786</td>\n",
              "      <td>-0.3455986977</td>\n",
              "      <td>-3.3043470383</td>\n",
              "      <td>1.4852843285</td>\n",
              "      <td>0.9098017812</td>\n",
              "      <td>-1.6430019140</td>\n",
              "      <td>5.0370340347</td>\n",
              "      <td>2.7801148891</td>\n",
              "      <td>4.7764964104</td>\n",
              "      <td>2.2552747726</td>\n",
              "      <td>3.7697074413</td>\n",
              "      <td>-3.6616835594</td>\n",
              "      <td>-0.6494054794</td>\n",
              "      <td>4.1996359825</td>\n",
              "      <td>-0.6348056197</td>\n",
              "      <td>2.4303400517</td>\n",
              "      <td>-2.8740186691</td>\n",
              "      <td>-0.7861775160</td>\n",
              "      <td>-0.5049162507</td>\n",
              "      <td>-6.0077886581</td>\n",
              "      <td>1.4984948635</td>\n",
              "      <td>1.5306128263</td>\n",
              "      <td>2.3796546459</td>\n",
              "      <td>-0.0231464375</td>\n",
              "      <td>-0.7036052942</td>\n",
              "      <td>2.1469361782</td>\n",
              "      <td>3.9448320866</td>\n",
              "      <td>-3.0985984802</td>\n",
              "      <td>2.5134534836</td>\n",
              "      <td>-5.3958601952</td>\n",
              "      <td>0.7621323466</td>\n",
              "      <td>2.8018035889</td>\n",
              "      <td>0.8779643178</td>\n",
              "      <td>-0.5859798193</td>\n",
              "      <td>1.9625556469</td>\n",
              "      <td>-5.1712174416</td>\n",
              "      <td>1.1816873550</td>\n",
              "      <td>0.5419528484</td>\n",
              "      <td>0.4858333170</td>\n",
              "      <td>4.2125682831</td>\n",
              "      <td>3.4581983089</td>\n",
              "      <td>1.4029390812</td>\n",
              "      <td>-0.5462926030</td>\n",
              "      <td>2.1821005344</td>\n",
              "      <td>-0.0962546766</td>\n",
              "      <td>1.7366081476</td>\n",
              "      <td>0.6851462722</td>\n",
              "      <td>-1.6132848263</td>\n",
              "      <td>-0.9128761888</td>\n",
              "      <td>-0.5323970318</td>\n",
              "      <td>1.7248421907</td>\n",
              "      <td>2.2641146183</td>\n",
              "      <td>-2.2597558498</td>\n",
              "      <td>4.5065088272</td>\n",
              "      <td>-0.3460883200</td>\n",
              "      <td>0.9281976819</td>\n",
              "      <td>-2.0782611370</td>\n",
              "      <td>-0.1955756247</td>\n",
              "      <td>4.8475780487</td>\n",
              "      <td>-2.9586863518</td>\n",
              "      <td>1.0060796738</td>\n",
              "      <td>2.0822322369</td>\n",
              "      <td>-2.2596824169</td>\n",
              "      <td>-2.0333144665</td>\n",
              "      <td>0.2182324231</td>\n",
              "      <td>3.9753122330</td>\n",
              "      <td>2.0034470558</td>\n",
              "      <td>-0.2406283617</td>\n",
              "      <td>-2.4685480595</td>\n",
              "      <td>1.6660641432</td>\n",
              "      <td>-2.0819606781</td>\n",
              "      <td>-2.4968724251</td>\n",
              "      <td>-1.9016369581</td>\n",
              "      <td>0.2714739740</td>\n",
              "      <td>-2.2981684208</td>\n",
              "      <td>-1.7873090506</td>\n",
              "      <td>1.6180669069</td>\n",
              "      <td>-2.9975774288</td>\n",
              "      <td>0.0420643799</td>\n",
              "      <td>-1.2196398973</td>\n",
              "      <td>-2.3956730366</td>\n",
              "      <td>5.6090831757</td>\n",
              "      <td>-1.4914845228</td>\n",
              "      <td>1.7885915041</td>\n",
              "      <td>4.1772522926</td>\n",
              "      <td>4.4608173370</td>\n",
              "      <td>-1.2361496687</td>\n",
              "      <td>-2.0794692039</td>\n",
              "      <td>-4.3971495628</td>\n",
              "      <td>0.3652189076</td>\n",
              "      <td>0.8151836395</td>\n",
              "      <td>5.4751114845</td>\n",
              "      <td>4.2397766113</td>\n",
              "      <td>0.9392179847</td>\n",
              "      <td>1.1986280680</td>\n",
              "      <td>-1.4769824743</td>\n",
              "      <td>-1.5552177429</td>\n",
              "      <td>0.3611471355</td>\n",
              "      <td>2.0227699280</td>\n",
              "      <td>-1.5996438265</td>\n",
              "      <td>3.2231538296</td>\n",
              "      <td>-1.4574943781</td>\n",
              "      <td>-2.8722801208</td>\n",
              "      <td>1.4587551355</td>\n",
              "      <td>2.5790126324</td>\n",
              "      <td>-1.6097468138</td>\n",
              "      <td>1.4378223419</td>\n",
              "      <td>1.3874959946</td>\n",
              "      <td>0.7249992490</td>\n",
              "      <td>0.0203323103</td>\n",
              "      <td>0.3120986819</td>\n",
              "      <td>-1.9997732639</td>\n",
              "      <td>-1.8057322502</td>\n",
              "      <td>-0.1739237309</td>\n",
              "      <td>-2.1751496792</td>\n",
              "      <td>-0.4395467937</td>\n",
              "      <td>-1.8935351372</td>\n",
              "      <td>-0.7034621835</td>\n",
              "      <td>-1.9535105228</td>\n",
              "      <td>0.6914859414</td>\n",
              "      <td>0.6445956826</td>\n",
              "      <td>2.0112810135</td>\n",
              "      <td>-0.4342123568</td>\n",
              "      <td>2.6146309376</td>\n",
              "      <td>2.1234035492</td>\n",
              "      <td>-2.8775033951</td>\n",
              "      <td>1.0714125633</td>\n",
              "      <td>0.4730164111</td>\n",
              "      <td>2.4707813263</td>\n",
              "      <td>-1.6296484470</td>\n",
              "      <td>-2.5948154926</td>\n",
              "      <td>2.1294517517</td>\n",
              "      <td>-1.0729905367</td>\n",
              "      <td>2.4951767921</td>\n",
              "      <td>-0.6153161526</td>\n",
              "      <td>-0.3726658523</td>\n",
              "      <td>1.4416368008</td>\n",
              "      <td>-0.3869579732</td>\n",
              "      <td>0.5742669106</td>\n",
              "      <td>0.2901403606</td>\n",
              "      <td>2.1439840794</td>\n",
              "      <td>-2.1797549725</td>\n",
              "      <td>1.0018137693</td>\n",
              "      <td>1.7092645168</td>\n",
              "      <td>1.7659958601</td>\n",
              "      <td>-0.9781475067</td>\n",
              "      <td>2.3762657642</td>\n",
              "      <td>1.2863856554</td>\n",
              "      <td>-1.4987120628</td>\n",
              "      <td>-2.1206870079</td>\n",
              "      <td>-1.6261025667</td>\n",
              "      <td>-1.7383675575</td>\n",
              "      <td>-0.2232712805</td>\n",
              "      <td>1.2644373178</td>\n",
              "      <td>-0.9871305823</td>\n",
              "      <td>-1.9093743563</td>\n",
              "      <td>2.2314555645</td>\n",
              "      <td>-2.6836464405</td>\n",
              "      <td>-0.6353181005</td>\n",
              "      <td>0.0858888105</td>\n",
              "      <td>-0.8235075474</td>\n",
              "      <td>0.5569828153</td>\n",
              "      <td>2.5153543949</td>\n",
              "      <td>-3.4205298424</td>\n",
              "      <td>0.0634656399</td>\n",
              "      <td>0.0094741732</td>\n",
              "      <td>-0.0657508075</td>\n",
              "      <td>-1.0753654242</td>\n",
              "      <td>-2.9713089466</td>\n",
              "      <td>1.0196198225</td>\n",
              "      <td>2.5095589161</td>\n",
              "      <td>-1.5258373022</td>\n",
              "      <td>0.5425801277</td>\n",
              "      <td>-0.2697300315</td>\n",
              "      <td>-0.0359621942</td>\n",
              "      <td>0.3917995691</td>\n",
              "      <td>-1.2341160774</td>\n",
              "      <td>2.3140294552</td>\n",
              "      <td>1.8986169100</td>\n",
              "      <td>-2.3611283302</td>\n",
              "      <td>0.3124046326</td>\n",
              "      <td>3.4446072578</td>\n",
              "      <td>-0.8862501383</td>\n",
              "      <td>-1.3436369896</td>\n",
              "      <td>0.9544589520</td>\n",
              "      <td>0.6308349371</td>\n",
              "      <td>-2.3947217464</td>\n",
              "      <td>0.6834869981</td>\n",
              "      <td>1.1490038633</td>\n",
              "      <td>-1.3511732817</td>\n",
              "      <td>2.0239000320</td>\n",
              "      <td>1.5991983414</td>\n",
              "      <td>1.3828682899</td>\n",
              "      <td>1.6056783199</td>\n",
              "      <td>1.8806668520</td>\n",
              "      <td>-0.5081608891</td>\n",
              "      <td>0.2428404391</td>\n",
              "      <td>-0.2608487904</td>\n",
              "      <td>1.8759434223</td>\n",
              "      <td>0.2061345726</td>\n",
              "      <td>0.1869730353</td>\n",
              "      <td>2.0474455357</td>\n",
              "      <td>-0.5754722953</td>\n",
              "      <td>3.0164101124</td>\n",
              "      <td>2.7571456432</td>\n",
              "      <td>3.3537209034</td>\n",
              "      <td>-0.4572715461</td>\n",
              "      <td>-0.1253366172</td>\n",
              "      <td>2.3329634666</td>\n",
              "      <td>3.8589668274</td>\n",
              "      <td>-2.0754899979</td>\n",
              "      <td>-0.7054958344</td>\n",
              "      <td>0.2034520507</td>\n",
              "      <td>1.7197328806</td>\n",
              "      <td>2.9250385761</td>\n",
              "      <td>-0.3886387944</td>\n",
              "      <td>1.2257323265</td>\n",
              "      <td>-1.7731370926</td>\n",
              "      <td>0.0526551157</td>\n",
              "      <td>1.2799222469</td>\n",
              "      <td>-3.3747272491</td>\n",
              "      <td>-1.5069689751</td>\n",
              "      <td>-1.8201801777</td>\n",
              "      <td>-3.0246436596</td>\n",
              "      <td>0.4452633858</td>\n",
              "      <td>0.0139333047</td>\n",
              "      <td>-1.3002386093</td>\n",
              "      <td>2.7599484921</td>\n",
              "      <td>2.0561711788</td>\n",
              "      <td>0.5087034702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>67898</td>\n",
              "      <td>-2.0029051304</td>\n",
              "      <td>-0.9298805594</td>\n",
              "      <td>0.7900167108</td>\n",
              "      <td>-1.3808951378</td>\n",
              "      <td>-0.5104627609</td>\n",
              "      <td>-1.8100957870</td>\n",
              "      <td>1.3639619350</td>\n",
              "      <td>0.4974010289</td>\n",
              "      <td>-4.0389027596</td>\n",
              "      <td>-3.0578715801</td>\n",
              "      <td>0.7585576773</td>\n",
              "      <td>-1.0121546984</td>\n",
              "      <td>2.8168015480</td>\n",
              "      <td>2.0868949890</td>\n",
              "      <td>-1.4643309116</td>\n",
              "      <td>-1.8404960632</td>\n",
              "      <td>-2.0899708271</td>\n",
              "      <td>-1.5668717623</td>\n",
              "      <td>1.5453896523</td>\n",
              "      <td>1.2843413353</td>\n",
              "      <td>-2.2702617645</td>\n",
              "      <td>0.7801263332</td>\n",
              "      <td>1.6155936718</td>\n",
              "      <td>-0.5460581183</td>\n",
              "      <td>1.3707500696</td>\n",
              "      <td>-1.1781235933</td>\n",
              "      <td>1.3468424082</td>\n",
              "      <td>0.4424336255</td>\n",
              "      <td>-1.4985396862</td>\n",
              "      <td>-0.5899440646</td>\n",
              "      <td>2.0083506107</td>\n",
              "      <td>-0.4971346855</td>\n",
              "      <td>-1.6442297697</td>\n",
              "      <td>3.1406233311</td>\n",
              "      <td>3.4921784401</td>\n",
              "      <td>0.3353945315</td>\n",
              "      <td>1.8109228611</td>\n",
              "      <td>-4.0120801926</td>\n",
              "      <td>2.4195928574</td>\n",
              "      <td>0.1909409761</td>\n",
              "      <td>-0.6306105256</td>\n",
              "      <td>3.2893316746</td>\n",
              "      <td>-1.4467194080</td>\n",
              "      <td>-0.6113395691</td>\n",
              "      <td>0.7006615996</td>\n",
              "      <td>-2.4656562805</td>\n",
              "      <td>-0.5967733860</td>\n",
              "      <td>2.4982099533</td>\n",
              "      <td>3.6829156876</td>\n",
              "      <td>0.2388433963</td>\n",
              "      <td>0.5705102682</td>\n",
              "      <td>0.0946367979</td>\n",
              "      <td>2.5407283306</td>\n",
              "      <td>-1.4612874985</td>\n",
              "      <td>0.8664698601</td>\n",
              "      <td>-0.8825763464</td>\n",
              "      <td>-1.6469770670</td>\n",
              "      <td>1.9151748419</td>\n",
              "      <td>2.8002102375</td>\n",
              "      <td>1.4765350819</td>\n",
              "      <td>2.3451476097</td>\n",
              "      <td>-1.6753772497</td>\n",
              "      <td>-2.9482414722</td>\n",
              "      <td>4.3225460052</td>\n",
              "      <td>0.0064851381</td>\n",
              "      <td>1.5961343050</td>\n",
              "      <td>1.7408252954</td>\n",
              "      <td>2.5171482563</td>\n",
              "      <td>1.6526031494</td>\n",
              "      <td>2.3012015820</td>\n",
              "      <td>-1.8203756809</td>\n",
              "      <td>0.3131376207</td>\n",
              "      <td>-0.4605118036</td>\n",
              "      <td>-1.4658217430</td>\n",
              "      <td>0.0256607905</td>\n",
              "      <td>0.1975094974</td>\n",
              "      <td>0.9521799088</td>\n",
              "      <td>1.8086135387</td>\n",
              "      <td>-3.9243142605</td>\n",
              "      <td>0.8740619421</td>\n",
              "      <td>1.5076384544</td>\n",
              "      <td>-1.4749593735</td>\n",
              "      <td>-0.7281465530</td>\n",
              "      <td>1.6809406281</td>\n",
              "      <td>-2.2752487659</td>\n",
              "      <td>0.1606744528</td>\n",
              "      <td>-1.1758519411</td>\n",
              "      <td>2.7073900700</td>\n",
              "      <td>-1.5404677391</td>\n",
              "      <td>-1.7555799484</td>\n",
              "      <td>1.2667036057</td>\n",
              "      <td>0.5049359202</td>\n",
              "      <td>1.0696272850</td>\n",
              "      <td>1.8924552202</td>\n",
              "      <td>-2.8700709343</td>\n",
              "      <td>1.3147110939</td>\n",
              "      <td>-0.6476105452</td>\n",
              "      <td>-3.8642375469</td>\n",
              "      <td>-1.1287094355</td>\n",
              "      <td>-0.2163546234</td>\n",
              "      <td>0.0200870410</td>\n",
              "      <td>-1.0009949207</td>\n",
              "      <td>1.8183261156</td>\n",
              "      <td>-1.2894283533</td>\n",
              "      <td>1.3204821348</td>\n",
              "      <td>0.9189465046</td>\n",
              "      <td>2.3127784729</td>\n",
              "      <td>0.9761807323</td>\n",
              "      <td>-1.1034594774</td>\n",
              "      <td>-1.2471879721</td>\n",
              "      <td>-2.9002075195</td>\n",
              "      <td>1.2914571762</td>\n",
              "      <td>1.5193878412</td>\n",
              "      <td>-0.8292294741</td>\n",
              "      <td>-2.4343063831</td>\n",
              "      <td>-0.7656114101</td>\n",
              "      <td>0.6017384529</td>\n",
              "      <td>3.1130170822</td>\n",
              "      <td>0.7010914087</td>\n",
              "      <td>0.5787922144</td>\n",
              "      <td>0.5351995230</td>\n",
              "      <td>-0.9441672564</td>\n",
              "      <td>-0.1240377501</td>\n",
              "      <td>-1.4508235455</td>\n",
              "      <td>0.3650854230</td>\n",
              "      <td>-1.1901761293</td>\n",
              "      <td>1.6859598160</td>\n",
              "      <td>0.8126941919</td>\n",
              "      <td>-0.0705208853</td>\n",
              "      <td>-1.4393335581</td>\n",
              "      <td>0.7728728056</td>\n",
              "      <td>-2.3489952087</td>\n",
              "      <td>-0.2355124950</td>\n",
              "      <td>-0.8700022697</td>\n",
              "      <td>-0.5425865054</td>\n",
              "      <td>1.5831973553</td>\n",
              "      <td>1.7427791357</td>\n",
              "      <td>-2.9939756393</td>\n",
              "      <td>-0.8622460961</td>\n",
              "      <td>-1.2157950401</td>\n",
              "      <td>-2.3686754704</td>\n",
              "      <td>2.3326988220</td>\n",
              "      <td>1.9421590567</td>\n",
              "      <td>1.1301317215</td>\n",
              "      <td>-2.5715732574</td>\n",
              "      <td>2.0020222664</td>\n",
              "      <td>3.8542828560</td>\n",
              "      <td>-0.4467480779</td>\n",
              "      <td>0.3667028844</td>\n",
              "      <td>0.3724231422</td>\n",
              "      <td>-1.9866981506</td>\n",
              "      <td>-0.1244335026</td>\n",
              "      <td>-2.7045094967</td>\n",
              "      <td>-2.9197115898</td>\n",
              "      <td>-3.0368967056</td>\n",
              "      <td>-1.1918561459</td>\n",
              "      <td>-2.3457062244</td>\n",
              "      <td>1.7503809929</td>\n",
              "      <td>-0.7577392459</td>\n",
              "      <td>0.7082000375</td>\n",
              "      <td>-2.0362606049</td>\n",
              "      <td>-1.2478457689</td>\n",
              "      <td>1.3371763229</td>\n",
              "      <td>0.3810861111</td>\n",
              "      <td>-2.1957163811</td>\n",
              "      <td>2.3492677212</td>\n",
              "      <td>3.2342376709</td>\n",
              "      <td>-1.0737447739</td>\n",
              "      <td>2.7275660038</td>\n",
              "      <td>2.1341414452</td>\n",
              "      <td>1.3165485859</td>\n",
              "      <td>1.4014288187</td>\n",
              "      <td>0.3226478398</td>\n",
              "      <td>1.5204454660</td>\n",
              "      <td>-1.5553992987</td>\n",
              "      <td>-1.7593723536</td>\n",
              "      <td>-0.5223306417</td>\n",
              "      <td>-2.0628519058</td>\n",
              "      <td>1.2358421087</td>\n",
              "      <td>0.1661762446</td>\n",
              "      <td>-3.3796861172</td>\n",
              "      <td>-2.2228477001</td>\n",
              "      <td>1.6136515141</td>\n",
              "      <td>0.7360733747</td>\n",
              "      <td>-2.1893527508</td>\n",
              "      <td>1.2845479250</td>\n",
              "      <td>2.8726134300</td>\n",
              "      <td>2.6761150360</td>\n",
              "      <td>0.1475290209</td>\n",
              "      <td>-1.3171087503</td>\n",
              "      <td>-2.6440515518</td>\n",
              "      <td>-1.8350887299</td>\n",
              "      <td>0.9574174285</td>\n",
              "      <td>-2.3858914375</td>\n",
              "      <td>-0.6619012356</td>\n",
              "      <td>2.6582648754</td>\n",
              "      <td>-0.9451054931</td>\n",
              "      <td>-1.0119893551</td>\n",
              "      <td>-0.6547811627</td>\n",
              "      <td>-0.3363517821</td>\n",
              "      <td>-2.1268010139</td>\n",
              "      <td>1.3375129700</td>\n",
              "      <td>-1.0618399382</td>\n",
              "      <td>0.4118506312</td>\n",
              "      <td>0.2462557554</td>\n",
              "      <td>-2.2640297413</td>\n",
              "      <td>2.3994200230</td>\n",
              "      <td>2.0248627663</td>\n",
              "      <td>0.1704825163</td>\n",
              "      <td>-0.0392032042</td>\n",
              "      <td>-1.5066767931</td>\n",
              "      <td>-1.9459319115</td>\n",
              "      <td>-0.0202283077</td>\n",
              "      <td>-0.4954991639</td>\n",
              "      <td>-0.1410129666</td>\n",
              "      <td>-1.6175206900</td>\n",
              "      <td>2.6246759892</td>\n",
              "      <td>-2.5819215775</td>\n",
              "      <td>0.2208910137</td>\n",
              "      <td>0.3287933767</td>\n",
              "      <td>0.6477577090</td>\n",
              "      <td>0.2319895625</td>\n",
              "      <td>1.1014859676</td>\n",
              "      <td>1.0795272589</td>\n",
              "      <td>2.9531016350</td>\n",
              "      <td>-0.5286824107</td>\n",
              "      <td>-1.1405997276</td>\n",
              "      <td>-0.3732994497</td>\n",
              "      <td>0.1098105833</td>\n",
              "      <td>2.8135411739</td>\n",
              "      <td>0.5969979167</td>\n",
              "      <td>1.7548358440</td>\n",
              "      <td>-1.3597713709</td>\n",
              "      <td>0.4665011466</td>\n",
              "      <td>2.3774173260</td>\n",
              "      <td>-0.1806525588</td>\n",
              "      <td>-3.2593042850</td>\n",
              "      <td>0.1208329052</td>\n",
              "      <td>2.2256433964</td>\n",
              "      <td>2.2205066681</td>\n",
              "      <td>-1.1789444685</td>\n",
              "      <td>-0.8213667870</td>\n",
              "      <td>0.7172386646</td>\n",
              "      <td>-1.4558292627</td>\n",
              "      <td>-1.2605844736</td>\n",
              "      <td>2.6234674454</td>\n",
              "      <td>-0.5383300781</td>\n",
              "      <td>-2.6201636791</td>\n",
              "      <td>1.2771952152</td>\n",
              "      <td>0.6010145545</td>\n",
              "      <td>-0.3453120291</td>\n",
              "      <td>0.9934566021</td>\n",
              "      <td>1.3516329527</td>\n",
              "      <td>2.1626746655</td>\n",
              "      <td>2.7685971260</td>\n",
              "      <td>-0.9371970296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>66446</td>\n",
              "      <td>4.2216730118</td>\n",
              "      <td>-1.4971394539</td>\n",
              "      <td>1.1335701942</td>\n",
              "      <td>-2.7456068993</td>\n",
              "      <td>-4.1970448494</td>\n",
              "      <td>-0.5423920751</td>\n",
              "      <td>-1.3962563276</td>\n",
              "      <td>1.8384194374</td>\n",
              "      <td>-6.0664544106</td>\n",
              "      <td>-2.1917989254</td>\n",
              "      <td>0.7528044581</td>\n",
              "      <td>0.8686234355</td>\n",
              "      <td>6.1876621246</td>\n",
              "      <td>1.7257447243</td>\n",
              "      <td>2.8878588676</td>\n",
              "      <td>-1.4860260487</td>\n",
              "      <td>-0.1822564006</td>\n",
              "      <td>-3.7107851505</td>\n",
              "      <td>1.5128655434</td>\n",
              "      <td>-0.6364336014</td>\n",
              "      <td>0.2884352803</td>\n",
              "      <td>-3.3697171211</td>\n",
              "      <td>-0.2659978271</td>\n",
              "      <td>-3.5493185520</td>\n",
              "      <td>3.3753383160</td>\n",
              "      <td>-0.9014606476</td>\n",
              "      <td>-1.5583705902</td>\n",
              "      <td>1.6953426600</td>\n",
              "      <td>-4.4504642487</td>\n",
              "      <td>0.5454953313</td>\n",
              "      <td>1.0000962019</td>\n",
              "      <td>-3.4687514305</td>\n",
              "      <td>3.3276410103</td>\n",
              "      <td>1.5568895340</td>\n",
              "      <td>4.4932026863</td>\n",
              "      <td>0.3690885603</td>\n",
              "      <td>0.1671957970</td>\n",
              "      <td>-4.8370623589</td>\n",
              "      <td>1.2160164118</td>\n",
              "      <td>4.6991534233</td>\n",
              "      <td>-1.0945291519</td>\n",
              "      <td>3.0159423351</td>\n",
              "      <td>-1.3227412701</td>\n",
              "      <td>-0.8291716576</td>\n",
              "      <td>0.5550473332</td>\n",
              "      <td>-5.5927648544</td>\n",
              "      <td>1.2548980713</td>\n",
              "      <td>3.1824502945</td>\n",
              "      <td>3.0535736084</td>\n",
              "      <td>1.9155689478</td>\n",
              "      <td>-1.8057124615</td>\n",
              "      <td>1.4768242836</td>\n",
              "      <td>1.4456773996</td>\n",
              "      <td>-4.2865915298</td>\n",
              "      <td>3.8664577007</td>\n",
              "      <td>-4.0532517433</td>\n",
              "      <td>-0.5716705322</td>\n",
              "      <td>2.1306719780</td>\n",
              "      <td>1.0535889864</td>\n",
              "      <td>0.1100640595</td>\n",
              "      <td>2.8935914040</td>\n",
              "      <td>-4.3589577675</td>\n",
              "      <td>-1.0194541216</td>\n",
              "      <td>0.3668791652</td>\n",
              "      <td>1.8413580656</td>\n",
              "      <td>4.1702466011</td>\n",
              "      <td>4.1743388176</td>\n",
              "      <td>1.2625701427</td>\n",
              "      <td>-0.0290785655</td>\n",
              "      <td>0.3916682005</td>\n",
              "      <td>0.8510245085</td>\n",
              "      <td>2.0302724838</td>\n",
              "      <td>-0.5232113004</td>\n",
              "      <td>-2.9885025024</td>\n",
              "      <td>0.4683658183</td>\n",
              "      <td>2.1632678509</td>\n",
              "      <td>2.6002571583</td>\n",
              "      <td>3.4216189384</td>\n",
              "      <td>-3.7261285782</td>\n",
              "      <td>3.6566011906</td>\n",
              "      <td>1.3187823296</td>\n",
              "      <td>1.9449762106</td>\n",
              "      <td>-1.1189107895</td>\n",
              "      <td>2.6336503029</td>\n",
              "      <td>1.9950672388</td>\n",
              "      <td>-1.3083131313</td>\n",
              "      <td>-1.9136729240</td>\n",
              "      <td>1.8380401134</td>\n",
              "      <td>-4.9061074257</td>\n",
              "      <td>-3.0755031109</td>\n",
              "      <td>-0.6857675910</td>\n",
              "      <td>2.5223836899</td>\n",
              "      <td>0.5497792959</td>\n",
              "      <td>1.4827349186</td>\n",
              "      <td>0.8170077205</td>\n",
              "      <td>1.9330986738</td>\n",
              "      <td>-2.5392942429</td>\n",
              "      <td>-0.4976403117</td>\n",
              "      <td>-1.0175911188</td>\n",
              "      <td>-2.7609453201</td>\n",
              "      <td>-1.8073147535</td>\n",
              "      <td>-3.6103582382</td>\n",
              "      <td>4.2451257706</td>\n",
              "      <td>-4.4561161995</td>\n",
              "      <td>1.7062046528</td>\n",
              "      <td>-3.1820578575</td>\n",
              "      <td>0.1201333702</td>\n",
              "      <td>4.3089995384</td>\n",
              "      <td>-3.7071764469</td>\n",
              "      <td>3.7954654694</td>\n",
              "      <td>2.0711903572</td>\n",
              "      <td>3.6382451057</td>\n",
              "      <td>-2.5796868801</td>\n",
              "      <td>1.3196798563</td>\n",
              "      <td>-3.7506515980</td>\n",
              "      <td>2.7014789581</td>\n",
              "      <td>-0.2162129283</td>\n",
              "      <td>5.0864233971</td>\n",
              "      <td>2.7782700062</td>\n",
              "      <td>3.9552774429</td>\n",
              "      <td>0.3138726354</td>\n",
              "      <td>-2.3330941200</td>\n",
              "      <td>0.2004831731</td>\n",
              "      <td>0.6144545674</td>\n",
              "      <td>-0.2370703667</td>\n",
              "      <td>-5.3172769547</td>\n",
              "      <td>4.8742480278</td>\n",
              "      <td>0.5578527451</td>\n",
              "      <td>-5.1803641319</td>\n",
              "      <td>-0.3882471323</td>\n",
              "      <td>-0.0362354293</td>\n",
              "      <td>-1.8510223627</td>\n",
              "      <td>1.2238538265</td>\n",
              "      <td>1.9967815876</td>\n",
              "      <td>0.7940438390</td>\n",
              "      <td>-0.2907482982</td>\n",
              "      <td>0.3932960033</td>\n",
              "      <td>-1.1030144691</td>\n",
              "      <td>-2.6933064461</td>\n",
              "      <td>1.2588562965</td>\n",
              "      <td>-1.9516181946</td>\n",
              "      <td>-1.6696166992</td>\n",
              "      <td>-1.3041158915</td>\n",
              "      <td>-0.7412303686</td>\n",
              "      <td>-1.9874830246</td>\n",
              "      <td>1.1826648712</td>\n",
              "      <td>0.1876281202</td>\n",
              "      <td>2.8795382977</td>\n",
              "      <td>-1.4945707321</td>\n",
              "      <td>4.8454046249</td>\n",
              "      <td>1.6018526554</td>\n",
              "      <td>-2.2582504749</td>\n",
              "      <td>0.6056196094</td>\n",
              "      <td>1.3605409861</td>\n",
              "      <td>2.2704613209</td>\n",
              "      <td>-2.3936748505</td>\n",
              "      <td>-2.5237107277</td>\n",
              "      <td>2.3623688221</td>\n",
              "      <td>-3.7879507542</td>\n",
              "      <td>4.1489663124</td>\n",
              "      <td>0.5273576379</td>\n",
              "      <td>-0.4623291790</td>\n",
              "      <td>1.9587676525</td>\n",
              "      <td>-0.5154456496</td>\n",
              "      <td>0.6768915653</td>\n",
              "      <td>-0.3047086000</td>\n",
              "      <td>0.1290760487</td>\n",
              "      <td>-1.6329034567</td>\n",
              "      <td>-0.4164456129</td>\n",
              "      <td>0.2012564689</td>\n",
              "      <td>1.5046161413</td>\n",
              "      <td>-1.8403992653</td>\n",
              "      <td>0.7415528893</td>\n",
              "      <td>1.1971130371</td>\n",
              "      <td>0.4738982022</td>\n",
              "      <td>-0.9263385534</td>\n",
              "      <td>0.7251952887</td>\n",
              "      <td>-2.4600844383</td>\n",
              "      <td>0.6102679968</td>\n",
              "      <td>2.4189102650</td>\n",
              "      <td>-0.8073080182</td>\n",
              "      <td>-2.4715397358</td>\n",
              "      <td>2.5514853001</td>\n",
              "      <td>-1.8118276596</td>\n",
              "      <td>0.1008770168</td>\n",
              "      <td>0.7436977029</td>\n",
              "      <td>-1.1163951159</td>\n",
              "      <td>-0.3596743941</td>\n",
              "      <td>3.0285360813</td>\n",
              "      <td>-2.4324274063</td>\n",
              "      <td>1.5074805021</td>\n",
              "      <td>1.7838965654</td>\n",
              "      <td>-0.2175149024</td>\n",
              "      <td>-2.6842575073</td>\n",
              "      <td>-2.6698846817</td>\n",
              "      <td>1.3063540459</td>\n",
              "      <td>2.1978611946</td>\n",
              "      <td>0.2396692932</td>\n",
              "      <td>0.6746810079</td>\n",
              "      <td>-0.1925708055</td>\n",
              "      <td>-0.1629413515</td>\n",
              "      <td>2.5120844841</td>\n",
              "      <td>-1.0960826874</td>\n",
              "      <td>3.5255630016</td>\n",
              "      <td>1.0564339161</td>\n",
              "      <td>-2.1295158863</td>\n",
              "      <td>-0.0054923594</td>\n",
              "      <td>3.8271811008</td>\n",
              "      <td>-0.3581976295</td>\n",
              "      <td>-2.0093791485</td>\n",
              "      <td>-0.2243905813</td>\n",
              "      <td>0.8038508296</td>\n",
              "      <td>-0.9094979167</td>\n",
              "      <td>0.9628103375</td>\n",
              "      <td>2.6015825272</td>\n",
              "      <td>0.0563275069</td>\n",
              "      <td>1.8594735861</td>\n",
              "      <td>-0.3161342740</td>\n",
              "      <td>-1.1312859058</td>\n",
              "      <td>1.7012784481</td>\n",
              "      <td>2.3054049015</td>\n",
              "      <td>-1.9412707090</td>\n",
              "      <td>1.2480015755</td>\n",
              "      <td>0.2910004854</td>\n",
              "      <td>0.7920667529</td>\n",
              "      <td>1.3611664772</td>\n",
              "      <td>1.1290049553</td>\n",
              "      <td>1.9474035501</td>\n",
              "      <td>-0.8594229817</td>\n",
              "      <td>2.0232229233</td>\n",
              "      <td>2.3486514091</td>\n",
              "      <td>4.5061273575</td>\n",
              "      <td>0.6844365001</td>\n",
              "      <td>2.0649919510</td>\n",
              "      <td>0.0229008049</td>\n",
              "      <td>3.4642429352</td>\n",
              "      <td>-2.3252725601</td>\n",
              "      <td>0.1313239187</td>\n",
              "      <td>-1.8761780262</td>\n",
              "      <td>1.7703540325</td>\n",
              "      <td>2.9251759052</td>\n",
              "      <td>-1.8510544300</td>\n",
              "      <td>-0.0925873220</td>\n",
              "      <td>-0.5807421207</td>\n",
              "      <td>-0.4220193028</td>\n",
              "      <td>0.9237140417</td>\n",
              "      <td>-4.5827107430</td>\n",
              "      <td>-1.0569097996</td>\n",
              "      <td>-2.5680844784</td>\n",
              "      <td>-2.0380613804</td>\n",
              "      <td>2.5087187290</td>\n",
              "      <td>-0.7647889853</td>\n",
              "      <td>-0.6571162343</td>\n",
              "      <td>3.2527816296</td>\n",
              "      <td>2.6873664856</td>\n",
              "      <td>0.8443320990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>63651</td>\n",
              "      <td>2.6579699516</td>\n",
              "      <td>-0.9418634772</td>\n",
              "      <td>1.1215288639</td>\n",
              "      <td>-5.1094956398</td>\n",
              "      <td>-0.2790412009</td>\n",
              "      <td>-0.3519684672</td>\n",
              "      <td>-1.0869832039</td>\n",
              "      <td>2.7036073208</td>\n",
              "      <td>-6.4949769974</td>\n",
              "      <td>-0.7467688918</td>\n",
              "      <td>-0.0685710013</td>\n",
              "      <td>-3.8946695328</td>\n",
              "      <td>4.9370460510</td>\n",
              "      <td>-1.8632038832</td>\n",
              "      <td>-1.9550676346</td>\n",
              "      <td>1.9001927376</td>\n",
              "      <td>1.7438409328</td>\n",
              "      <td>-6.0247902870</td>\n",
              "      <td>1.4604135752</td>\n",
              "      <td>-2.2061042786</td>\n",
              "      <td>-1.9975721836</td>\n",
              "      <td>-3.4145364761</td>\n",
              "      <td>-0.1787390411</td>\n",
              "      <td>0.9873132110</td>\n",
              "      <td>1.2553472519</td>\n",
              "      <td>-1.1871355772</td>\n",
              "      <td>2.0705177784</td>\n",
              "      <td>2.1910212040</td>\n",
              "      <td>-2.9367015362</td>\n",
              "      <td>2.6177332401</td>\n",
              "      <td>0.9191812277</td>\n",
              "      <td>-3.0879065990</td>\n",
              "      <td>-0.3589378297</td>\n",
              "      <td>-0.4286785722</td>\n",
              "      <td>3.8155975342</td>\n",
              "      <td>2.4405581951</td>\n",
              "      <td>1.2810608149</td>\n",
              "      <td>-0.7325298190</td>\n",
              "      <td>1.5170669556</td>\n",
              "      <td>2.7903022766</td>\n",
              "      <td>-2.0191221237</td>\n",
              "      <td>2.4190418720</td>\n",
              "      <td>-2.0448062420</td>\n",
              "      <td>0.6491868496</td>\n",
              "      <td>1.9405262470</td>\n",
              "      <td>-4.9653587341</td>\n",
              "      <td>0.9304602742</td>\n",
              "      <td>-1.1520111561</td>\n",
              "      <td>0.1675943732</td>\n",
              "      <td>1.3513327837</td>\n",
              "      <td>1.4120253325</td>\n",
              "      <td>5.8572702408</td>\n",
              "      <td>2.9551832676</td>\n",
              "      <td>-5.2905402184</td>\n",
              "      <td>3.9502623081</td>\n",
              "      <td>-1.0030276775</td>\n",
              "      <td>-0.6423271894</td>\n",
              "      <td>-0.7421406507</td>\n",
              "      <td>1.8295041323</td>\n",
              "      <td>-0.3699176610</td>\n",
              "      <td>0.5510581136</td>\n",
              "      <td>-4.0429396629</td>\n",
              "      <td>-1.8587552309</td>\n",
              "      <td>1.1932451725</td>\n",
              "      <td>0.5523794889</td>\n",
              "      <td>0.8406279087</td>\n",
              "      <td>-0.1998117566</td>\n",
              "      <td>-0.5318464041</td>\n",
              "      <td>0.5840061307</td>\n",
              "      <td>0.2384417951</td>\n",
              "      <td>-0.1831949651</td>\n",
              "      <td>-0.9647368193</td>\n",
              "      <td>0.0030380934</td>\n",
              "      <td>-3.8698849678</td>\n",
              "      <td>0.1377555430</td>\n",
              "      <td>2.9626429081</td>\n",
              "      <td>0.8658820391</td>\n",
              "      <td>4.0657339096</td>\n",
              "      <td>-2.1266815662</td>\n",
              "      <td>-0.1394288242</td>\n",
              "      <td>-0.0651780367</td>\n",
              "      <td>0.0671006665</td>\n",
              "      <td>-1.7295682430</td>\n",
              "      <td>3.5149486065</td>\n",
              "      <td>1.6050981283</td>\n",
              "      <td>0.6517529488</td>\n",
              "      <td>-1.3164319992</td>\n",
              "      <td>0.4306410849</td>\n",
              "      <td>-0.9936897755</td>\n",
              "      <td>-4.6938705444</td>\n",
              "      <td>-1.9676889181</td>\n",
              "      <td>3.2283120155</td>\n",
              "      <td>1.3695452213</td>\n",
              "      <td>-0.1332462430</td>\n",
              "      <td>0.4559089541</td>\n",
              "      <td>-0.9183557034</td>\n",
              "      <td>-1.4347511530</td>\n",
              "      <td>0.9158083797</td>\n",
              "      <td>0.4877495468</td>\n",
              "      <td>1.0235780478</td>\n",
              "      <td>-0.0599985197</td>\n",
              "      <td>-4.7873816490</td>\n",
              "      <td>-1.5516570807</td>\n",
              "      <td>-3.0073292255</td>\n",
              "      <td>2.0735120773</td>\n",
              "      <td>-3.4647843838</td>\n",
              "      <td>-2.7820105553</td>\n",
              "      <td>-0.0993154496</td>\n",
              "      <td>-4.0383219719</td>\n",
              "      <td>-0.8915926218</td>\n",
              "      <td>0.6951371431</td>\n",
              "      <td>3.5863361359</td>\n",
              "      <td>1.0518940687</td>\n",
              "      <td>1.5735805035</td>\n",
              "      <td>-4.2804646492</td>\n",
              "      <td>3.1986303329</td>\n",
              "      <td>-2.7923855782</td>\n",
              "      <td>3.2322039604</td>\n",
              "      <td>-3.1985409260</td>\n",
              "      <td>2.5838351250</td>\n",
              "      <td>-1.2322738171</td>\n",
              "      <td>-2.7884037495</td>\n",
              "      <td>1.4736993313</td>\n",
              "      <td>-3.1015565395</td>\n",
              "      <td>-0.9659563899</td>\n",
              "      <td>-3.5598251820</td>\n",
              "      <td>4.0261893272</td>\n",
              "      <td>1.3633310795</td>\n",
              "      <td>-1.0772739649</td>\n",
              "      <td>2.8394529819</td>\n",
              "      <td>1.1834309101</td>\n",
              "      <td>-1.0987117290</td>\n",
              "      <td>0.9005973339</td>\n",
              "      <td>1.4222483635</td>\n",
              "      <td>0.1098280475</td>\n",
              "      <td>-3.7701313496</td>\n",
              "      <td>0.1382257044</td>\n",
              "      <td>-3.4304034710</td>\n",
              "      <td>-1.1713567972</td>\n",
              "      <td>-1.2840040922</td>\n",
              "      <td>-0.0544508547</td>\n",
              "      <td>-2.2876307964</td>\n",
              "      <td>-0.5878560543</td>\n",
              "      <td>-3.7379798889</td>\n",
              "      <td>-0.7720518112</td>\n",
              "      <td>0.6717689037</td>\n",
              "      <td>1.4492791891</td>\n",
              "      <td>-0.1424507499</td>\n",
              "      <td>-0.6465058327</td>\n",
              "      <td>2.2852480412</td>\n",
              "      <td>-1.3476312160</td>\n",
              "      <td>-0.3918263912</td>\n",
              "      <td>0.2032637298</td>\n",
              "      <td>-0.4844906628</td>\n",
              "      <td>-2.1060159206</td>\n",
              "      <td>-3.5996644497</td>\n",
              "      <td>-4.4429578781</td>\n",
              "      <td>1.7781949043</td>\n",
              "      <td>-4.1688241959</td>\n",
              "      <td>2.1066026688</td>\n",
              "      <td>-2.6107659340</td>\n",
              "      <td>-4.6652832031</td>\n",
              "      <td>4.2292447090</td>\n",
              "      <td>1.1606259346</td>\n",
              "      <td>1.1377283335</td>\n",
              "      <td>0.3503388762</td>\n",
              "      <td>3.7622182369</td>\n",
              "      <td>-1.5629478693</td>\n",
              "      <td>3.2892580032</td>\n",
              "      <td>0.6765853763</td>\n",
              "      <td>-1.1160399914</td>\n",
              "      <td>-2.3792004585</td>\n",
              "      <td>0.3785956204</td>\n",
              "      <td>0.5143413544</td>\n",
              "      <td>3.4223504066</td>\n",
              "      <td>1.5008887053</td>\n",
              "      <td>-2.3732028008</td>\n",
              "      <td>1.3730483055</td>\n",
              "      <td>-1.8183721304</td>\n",
              "      <td>0.2093314379</td>\n",
              "      <td>-4.0995993614</td>\n",
              "      <td>-2.2917511463</td>\n",
              "      <td>1.7036482096</td>\n",
              "      <td>-1.7782133818</td>\n",
              "      <td>0.2453990728</td>\n",
              "      <td>-3.7033028603</td>\n",
              "      <td>1.4522143602</td>\n",
              "      <td>2.1704957485</td>\n",
              "      <td>1.1902852058</td>\n",
              "      <td>-2.3954641819</td>\n",
              "      <td>-0.1170736402</td>\n",
              "      <td>0.6126937270</td>\n",
              "      <td>-4.3434071541</td>\n",
              "      <td>-3.7077896595</td>\n",
              "      <td>-1.9681696892</td>\n",
              "      <td>1.6769342422</td>\n",
              "      <td>-1.6965925694</td>\n",
              "      <td>0.8841276169</td>\n",
              "      <td>1.8131419420</td>\n",
              "      <td>1.8550761938</td>\n",
              "      <td>1.3032124043</td>\n",
              "      <td>2.0474886894</td>\n",
              "      <td>0.6032235622</td>\n",
              "      <td>3.9587745667</td>\n",
              "      <td>3.7462685108</td>\n",
              "      <td>-3.4980876446</td>\n",
              "      <td>-0.7330384254</td>\n",
              "      <td>-0.9137355089</td>\n",
              "      <td>-1.2961897850</td>\n",
              "      <td>4.8217391968</td>\n",
              "      <td>0.6872349381</td>\n",
              "      <td>-1.4064308405</td>\n",
              "      <td>0.6691839695</td>\n",
              "      <td>-1.8475983143</td>\n",
              "      <td>-0.8170750737</td>\n",
              "      <td>-1.1811718941</td>\n",
              "      <td>2.5885522366</td>\n",
              "      <td>-1.1231178045</td>\n",
              "      <td>0.2324265391</td>\n",
              "      <td>2.1703250408</td>\n",
              "      <td>0.5794144869</td>\n",
              "      <td>2.6014208794</td>\n",
              "      <td>-0.5961964726</td>\n",
              "      <td>-1.7986934185</td>\n",
              "      <td>0.3123261333</td>\n",
              "      <td>0.3874855340</td>\n",
              "      <td>-2.2073650360</td>\n",
              "      <td>-1.0293287039</td>\n",
              "      <td>-1.2742329836</td>\n",
              "      <td>2.0472295284</td>\n",
              "      <td>1.9285165071</td>\n",
              "      <td>2.1026327610</td>\n",
              "      <td>-0.5593834519</td>\n",
              "      <td>-0.9514183998</td>\n",
              "      <td>-2.0217494965</td>\n",
              "      <td>1.3662722111</td>\n",
              "      <td>-1.9472106695</td>\n",
              "      <td>-2.1144192219</td>\n",
              "      <td>1.1403938532</td>\n",
              "      <td>-0.7960235476</td>\n",
              "      <td>1.9063613415</td>\n",
              "      <td>-0.3575199842</td>\n",
              "      <td>3.3529679775</td>\n",
              "      <td>-3.9963769913</td>\n",
              "      <td>1.5203311443</td>\n",
              "      <td>-0.0007160828</td>\n",
              "      <td>-0.4876829982</td>\n",
              "      <td>-1.8891189098</td>\n",
              "      <td>0.9430151582</td>\n",
              "      <td>-2.8344175816</td>\n",
              "      <td>1.6331835985</td>\n",
              "      <td>2.0018005371</td>\n",
              "      <td>-2.3331520557</td>\n",
              "      <td>2.6455948353</td>\n",
              "      <td>2.2802333832</td>\n",
              "      <td>-0.6944484115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>46824</td>\n",
              "      <td>3.1921949387</td>\n",
              "      <td>-1.9366759062</td>\n",
              "      <td>1.1999093294</td>\n",
              "      <td>-2.5621519089</td>\n",
              "      <td>-2.5734560490</td>\n",
              "      <td>0.5758405328</td>\n",
              "      <td>-2.3586528301</td>\n",
              "      <td>1.6208440065</td>\n",
              "      <td>-4.3029360771</td>\n",
              "      <td>-0.4875746071</td>\n",
              "      <td>0.0208958052</td>\n",
              "      <td>-0.7633265853</td>\n",
              "      <td>4.3416938782</td>\n",
              "      <td>0.6987979412</td>\n",
              "      <td>3.3345804214</td>\n",
              "      <td>0.6076831222</td>\n",
              "      <td>-0.7186435461</td>\n",
              "      <td>-2.7301876545</td>\n",
              "      <td>0.1938284338</td>\n",
              "      <td>-1.7061960697</td>\n",
              "      <td>-0.4687266648</td>\n",
              "      <td>-2.2819042206</td>\n",
              "      <td>-1.8372744322</td>\n",
              "      <td>-2.8491399288</td>\n",
              "      <td>0.1958733052</td>\n",
              "      <td>-0.4597650468</td>\n",
              "      <td>-0.7687521577</td>\n",
              "      <td>1.0334885120</td>\n",
              "      <td>-2.4908955097</td>\n",
              "      <td>2.0775208473</td>\n",
              "      <td>-0.1719837934</td>\n",
              "      <td>-3.4063465595</td>\n",
              "      <td>2.6166696548</td>\n",
              "      <td>0.7130991220</td>\n",
              "      <td>4.4502215385</td>\n",
              "      <td>0.6064971685</td>\n",
              "      <td>0.1606716812</td>\n",
              "      <td>-2.6042177677</td>\n",
              "      <td>2.1102719307</td>\n",
              "      <td>4.7140192986</td>\n",
              "      <td>-2.2979054451</td>\n",
              "      <td>1.7008813620</td>\n",
              "      <td>-0.1956334114</td>\n",
              "      <td>-0.4040055871</td>\n",
              "      <td>2.1407785416</td>\n",
              "      <td>-5.3515763283</td>\n",
              "      <td>1.5924882889</td>\n",
              "      <td>1.3127232790</td>\n",
              "      <td>1.6108667850</td>\n",
              "      <td>0.9940723181</td>\n",
              "      <td>-1.1959708929</td>\n",
              "      <td>1.7814975977</td>\n",
              "      <td>1.7854963541</td>\n",
              "      <td>-4.0715527534</td>\n",
              "      <td>2.6540911198</td>\n",
              "      <td>-5.9325356483</td>\n",
              "      <td>-0.4189185500</td>\n",
              "      <td>-0.9260056019</td>\n",
              "      <td>-0.5426020026</td>\n",
              "      <td>0.4626600146</td>\n",
              "      <td>1.4631899595</td>\n",
              "      <td>-4.1606488228</td>\n",
              "      <td>0.1747602522</td>\n",
              "      <td>0.0668889135</td>\n",
              "      <td>1.9713603258</td>\n",
              "      <td>1.9823232889</td>\n",
              "      <td>2.5010893345</td>\n",
              "      <td>0.2407858074</td>\n",
              "      <td>-0.5280813575</td>\n",
              "      <td>0.9364103079</td>\n",
              "      <td>-0.2675441802</td>\n",
              "      <td>1.1475917101</td>\n",
              "      <td>0.2777195573</td>\n",
              "      <td>-1.5763708353</td>\n",
              "      <td>-1.3750151396</td>\n",
              "      <td>2.2555143833</td>\n",
              "      <td>2.0386326313</td>\n",
              "      <td>3.8130803108</td>\n",
              "      <td>-2.5444471836</td>\n",
              "      <td>2.7090351582</td>\n",
              "      <td>-1.2576792240</td>\n",
              "      <td>1.2818650007</td>\n",
              "      <td>-0.3754705787</td>\n",
              "      <td>1.0863946676</td>\n",
              "      <td>3.9390137196</td>\n",
              "      <td>-0.7524920106</td>\n",
              "      <td>-0.4735445082</td>\n",
              "      <td>0.2154830545</td>\n",
              "      <td>-3.9462544918</td>\n",
              "      <td>-1.3390405178</td>\n",
              "      <td>-0.5571385622</td>\n",
              "      <td>1.8416041136</td>\n",
              "      <td>-0.2635599077</td>\n",
              "      <td>-0.5724999309</td>\n",
              "      <td>1.6691718102</td>\n",
              "      <td>-0.0412875786</td>\n",
              "      <td>-1.7513698339</td>\n",
              "      <td>-0.9225690961</td>\n",
              "      <td>-0.8901174664</td>\n",
              "      <td>-0.7344263792</td>\n",
              "      <td>-0.1985396743</td>\n",
              "      <td>-4.6947107315</td>\n",
              "      <td>2.3384141922</td>\n",
              "      <td>-3.1651930809</td>\n",
              "      <td>-0.6592266560</td>\n",
              "      <td>-2.2427787781</td>\n",
              "      <td>-0.2026949227</td>\n",
              "      <td>2.8271911144</td>\n",
              "      <td>-3.3360562325</td>\n",
              "      <td>3.8229005337</td>\n",
              "      <td>0.8821620941</td>\n",
              "      <td>2.8626224995</td>\n",
              "      <td>-2.6367087364</td>\n",
              "      <td>0.5635325909</td>\n",
              "      <td>-2.7188420296</td>\n",
              "      <td>2.0029742718</td>\n",
              "      <td>1.4403909445</td>\n",
              "      <td>4.0350317955</td>\n",
              "      <td>0.6819838881</td>\n",
              "      <td>4.4928522110</td>\n",
              "      <td>-0.8764061332</td>\n",
              "      <td>-2.3473026752</td>\n",
              "      <td>0.0668368563</td>\n",
              "      <td>-1.4170516729</td>\n",
              "      <td>-0.0014237612</td>\n",
              "      <td>-3.9701452255</td>\n",
              "      <td>4.4187226295</td>\n",
              "      <td>0.2834067345</td>\n",
              "      <td>-3.2601945400</td>\n",
              "      <td>0.4988903403</td>\n",
              "      <td>2.5831427574</td>\n",
              "      <td>-2.5513806343</td>\n",
              "      <td>1.4665173292</td>\n",
              "      <td>-0.1956336200</td>\n",
              "      <td>1.2730638981</td>\n",
              "      <td>0.4443459213</td>\n",
              "      <td>1.9116442204</td>\n",
              "      <td>-1.8641946316</td>\n",
              "      <td>0.4185179174</td>\n",
              "      <td>-2.4434888363</td>\n",
              "      <td>-1.9919613600</td>\n",
              "      <td>-0.6361541748</td>\n",
              "      <td>-1.0268591642</td>\n",
              "      <td>-0.8774957061</td>\n",
              "      <td>0.7087628841</td>\n",
              "      <td>1.8621208668</td>\n",
              "      <td>0.8565728068</td>\n",
              "      <td>1.7871872187</td>\n",
              "      <td>-0.2045107186</td>\n",
              "      <td>1.8074589968</td>\n",
              "      <td>-1.2486822605</td>\n",
              "      <td>-2.0458302498</td>\n",
              "      <td>-0.6823843718</td>\n",
              "      <td>-1.0407505035</td>\n",
              "      <td>-0.1911843121</td>\n",
              "      <td>-1.1757192612</td>\n",
              "      <td>-3.0022175312</td>\n",
              "      <td>1.3092085123</td>\n",
              "      <td>0.7799966335</td>\n",
              "      <td>1.5844647884</td>\n",
              "      <td>-0.2545006573</td>\n",
              "      <td>-1.9702123404</td>\n",
              "      <td>2.6014389992</td>\n",
              "      <td>0.7656390667</td>\n",
              "      <td>-0.3065223992</td>\n",
              "      <td>1.4117398262</td>\n",
              "      <td>2.0450096130</td>\n",
              "      <td>-1.4351650476</td>\n",
              "      <td>0.6078616381</td>\n",
              "      <td>1.8148971796</td>\n",
              "      <td>1.9150559902</td>\n",
              "      <td>1.3558405638</td>\n",
              "      <td>0.3710158169</td>\n",
              "      <td>1.5915417671</td>\n",
              "      <td>-1.3562458754</td>\n",
              "      <td>-2.0786681175</td>\n",
              "      <td>-1.4965167046</td>\n",
              "      <td>-1.5357089043</td>\n",
              "      <td>0.5223278999</td>\n",
              "      <td>1.3364672661</td>\n",
              "      <td>-2.0848152637</td>\n",
              "      <td>-2.3919889927</td>\n",
              "      <td>1.2798339128</td>\n",
              "      <td>-0.4796919227</td>\n",
              "      <td>0.8068606853</td>\n",
              "      <td>0.0033650771</td>\n",
              "      <td>0.1334796101</td>\n",
              "      <td>1.9405741692</td>\n",
              "      <td>0.3472729027</td>\n",
              "      <td>-3.2160534859</td>\n",
              "      <td>-1.1251442432</td>\n",
              "      <td>-0.4129741192</td>\n",
              "      <td>-0.4549874365</td>\n",
              "      <td>-1.5074959993</td>\n",
              "      <td>-1.0031266212</td>\n",
              "      <td>1.4596577883</td>\n",
              "      <td>0.3572512269</td>\n",
              "      <td>-1.2548041344</td>\n",
              "      <td>-0.3108480573</td>\n",
              "      <td>-1.8746677637</td>\n",
              "      <td>-1.0605058670</td>\n",
              "      <td>0.0878456458</td>\n",
              "      <td>-1.9225060940</td>\n",
              "      <td>1.1394615173</td>\n",
              "      <td>0.2324949801</td>\n",
              "      <td>-1.6677292585</td>\n",
              "      <td>1.0865254402</td>\n",
              "      <td>3.2355041504</td>\n",
              "      <td>-1.3600406647</td>\n",
              "      <td>-0.5736263990</td>\n",
              "      <td>-0.3438729644</td>\n",
              "      <td>-0.8621111512</td>\n",
              "      <td>-3.0362601280</td>\n",
              "      <td>-1.0166102648</td>\n",
              "      <td>-1.1497695446</td>\n",
              "      <td>0.4641397595</td>\n",
              "      <td>2.4124057293</td>\n",
              "      <td>-0.6541346908</td>\n",
              "      <td>0.4868938923</td>\n",
              "      <td>1.1680536270</td>\n",
              "      <td>-0.2714197040</td>\n",
              "      <td>0.6670907736</td>\n",
              "      <td>1.1635572910</td>\n",
              "      <td>-0.1322363019</td>\n",
              "      <td>0.6684629917</td>\n",
              "      <td>-0.2281846255</td>\n",
              "      <td>0.1557677239</td>\n",
              "      <td>1.5468212366</td>\n",
              "      <td>0.3076400459</td>\n",
              "      <td>2.5429413319</td>\n",
              "      <td>1.2409851551</td>\n",
              "      <td>2.1445691586</td>\n",
              "      <td>-1.0797533989</td>\n",
              "      <td>0.3351914585</td>\n",
              "      <td>0.2451588660</td>\n",
              "      <td>2.1501686573</td>\n",
              "      <td>-1.9914399385</td>\n",
              "      <td>-2.3307268620</td>\n",
              "      <td>0.7368552089</td>\n",
              "      <td>2.1269307137</td>\n",
              "      <td>0.5560612679</td>\n",
              "      <td>-1.6114931107</td>\n",
              "      <td>2.7221329212</td>\n",
              "      <td>-1.1859402657</td>\n",
              "      <td>0.3992010057</td>\n",
              "      <td>1.5986174345</td>\n",
              "      <td>-0.6214751601</td>\n",
              "      <td>-2.0914101601</td>\n",
              "      <td>0.5015996695</td>\n",
              "      <td>-3.0838639736</td>\n",
              "      <td>-1.0600911379</td>\n",
              "      <td>2.0536000729</td>\n",
              "      <td>-2.0250082016</td>\n",
              "      <td>2.3992507458</td>\n",
              "      <td>2.5623166561</td>\n",
              "      <td>0.6941336393</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   item_id      txt_vec0      txt_vec1      txt_vec2      txt_vec3  \\\n",
              "0    42844  4.5149450302 -2.3837196827  0.5004140139  0.4070682824   \n",
              "1    67898 -2.0029051304 -0.9298805594  0.7900167108 -1.3808951378   \n",
              "2    66446  4.2216730118 -1.4971394539  1.1335701942 -2.7456068993   \n",
              "3    63651  2.6579699516 -0.9418634772  1.1215288639 -5.1094956398   \n",
              "4    46824  3.1921949387 -1.9366759062  1.1999093294 -2.5621519089   \n",
              "\n",
              "       txt_vec4      txt_vec5      txt_vec6      txt_vec7      txt_vec8  \\\n",
              "0 -1.9952288866  0.1090780124 -0.6917753220  2.2274599075 -6.4379744530   \n",
              "1 -0.5104627609 -1.8100957870  1.3639619350  0.4974010289 -4.0389027596   \n",
              "2 -4.1970448494 -0.5423920751 -1.3962563276  1.8384194374 -6.0664544106   \n",
              "3 -0.2790412009 -0.3519684672 -1.0869832039  2.7036073208 -6.4949769974   \n",
              "4 -2.5734560490  0.5758405328 -2.3586528301  1.6208440065 -4.3029360771   \n",
              "\n",
              "       txt_vec9     txt_vec10     txt_vec11     txt_vec12     txt_vec13  \\\n",
              "0 -0.8248971701 -0.1387242377 -0.3793291748  0.6276600957  0.4183767140   \n",
              "1 -3.0578715801  0.7585576773 -1.0121546984  2.8168015480  2.0868949890   \n",
              "2 -2.1917989254  0.7528044581  0.8686234355  6.1876621246  1.7257447243   \n",
              "3 -0.7467688918 -0.0685710013 -3.8946695328  4.9370460510 -1.8632038832   \n",
              "4 -0.4875746071  0.0208958052 -0.7633265853  4.3416938782  0.6987979412   \n",
              "\n",
              "      txt_vec14     txt_vec15     txt_vec16     txt_vec17     txt_vec18  \\\n",
              "0  4.4412183762  0.2998193502  0.5785568357 -4.6992893219 -0.3947401643   \n",
              "1 -1.4643309116 -1.8404960632 -2.0899708271 -1.5668717623  1.5453896523   \n",
              "2  2.8878588676 -1.4860260487 -0.1822564006 -3.7107851505  1.5128655434   \n",
              "3 -1.9550676346  1.9001927376  1.7438409328 -6.0247902870  1.4604135752   \n",
              "4  3.3345804214  0.6076831222 -0.7186435461 -2.7301876545  0.1938284338   \n",
              "\n",
              "      txt_vec19     txt_vec20     txt_vec21     txt_vec22     txt_vec23  \\\n",
              "0 -2.3916513920  0.3705316782 -1.3554661274 -1.0741775036 -2.3216402531   \n",
              "1  1.2843413353 -2.2702617645  0.7801263332  1.6155936718 -0.5460581183   \n",
              "2 -0.6364336014  0.2884352803 -3.3697171211 -0.2659978271 -3.5493185520   \n",
              "3 -2.2061042786 -1.9975721836 -3.4145364761 -0.1787390411  0.9873132110   \n",
              "4 -1.7061960697 -0.4687266648 -2.2819042206 -1.8372744322 -2.8491399288   \n",
              "\n",
              "      txt_vec24     txt_vec25     txt_vec26     txt_vec27     txt_vec28  \\\n",
              "0 -0.3324561715  0.1238859445 -2.4391555786 -0.3455986977 -3.3043470383   \n",
              "1  1.3707500696 -1.1781235933  1.3468424082  0.4424336255 -1.4985396862   \n",
              "2  3.3753383160 -0.9014606476 -1.5583705902  1.6953426600 -4.4504642487   \n",
              "3  1.2553472519 -1.1871355772  2.0705177784  2.1910212040 -2.9367015362   \n",
              "4  0.1958733052 -0.4597650468 -0.7687521577  1.0334885120 -2.4908955097   \n",
              "\n",
              "      txt_vec29     txt_vec30     txt_vec31     txt_vec32     txt_vec33  \\\n",
              "0  1.4852843285  0.9098017812 -1.6430019140  5.0370340347  2.7801148891   \n",
              "1 -0.5899440646  2.0083506107 -0.4971346855 -1.6442297697  3.1406233311   \n",
              "2  0.5454953313  1.0000962019 -3.4687514305  3.3276410103  1.5568895340   \n",
              "3  2.6177332401  0.9191812277 -3.0879065990 -0.3589378297 -0.4286785722   \n",
              "4  2.0775208473 -0.1719837934 -3.4063465595  2.6166696548  0.7130991220   \n",
              "\n",
              "      txt_vec34     txt_vec35     txt_vec36     txt_vec37     txt_vec38  \\\n",
              "0  4.7764964104  2.2552747726  3.7697074413 -3.6616835594 -0.6494054794   \n",
              "1  3.4921784401  0.3353945315  1.8109228611 -4.0120801926  2.4195928574   \n",
              "2  4.4932026863  0.3690885603  0.1671957970 -4.8370623589  1.2160164118   \n",
              "3  3.8155975342  2.4405581951  1.2810608149 -0.7325298190  1.5170669556   \n",
              "4  4.4502215385  0.6064971685  0.1606716812 -2.6042177677  2.1102719307   \n",
              "\n",
              "      txt_vec39     txt_vec40     txt_vec41     txt_vec42     txt_vec43  \\\n",
              "0  4.1996359825 -0.6348056197  2.4303400517 -2.8740186691 -0.7861775160   \n",
              "1  0.1909409761 -0.6306105256  3.2893316746 -1.4467194080 -0.6113395691   \n",
              "2  4.6991534233 -1.0945291519  3.0159423351 -1.3227412701 -0.8291716576   \n",
              "3  2.7903022766 -2.0191221237  2.4190418720 -2.0448062420  0.6491868496   \n",
              "4  4.7140192986 -2.2979054451  1.7008813620 -0.1956334114 -0.4040055871   \n",
              "\n",
              "      txt_vec44     txt_vec45     txt_vec46     txt_vec47     txt_vec48  \\\n",
              "0 -0.5049162507 -6.0077886581  1.4984948635  1.5306128263  2.3796546459   \n",
              "1  0.7006615996 -2.4656562805 -0.5967733860  2.4982099533  3.6829156876   \n",
              "2  0.5550473332 -5.5927648544  1.2548980713  3.1824502945  3.0535736084   \n",
              "3  1.9405262470 -4.9653587341  0.9304602742 -1.1520111561  0.1675943732   \n",
              "4  2.1407785416 -5.3515763283  1.5924882889  1.3127232790  1.6108667850   \n",
              "\n",
              "      txt_vec49     txt_vec50     txt_vec51     txt_vec52     txt_vec53  \\\n",
              "0 -0.0231464375 -0.7036052942  2.1469361782  3.9448320866 -3.0985984802   \n",
              "1  0.2388433963  0.5705102682  0.0946367979  2.5407283306 -1.4612874985   \n",
              "2  1.9155689478 -1.8057124615  1.4768242836  1.4456773996 -4.2865915298   \n",
              "3  1.3513327837  1.4120253325  5.8572702408  2.9551832676 -5.2905402184   \n",
              "4  0.9940723181 -1.1959708929  1.7814975977  1.7854963541 -4.0715527534   \n",
              "\n",
              "      txt_vec54     txt_vec55     txt_vec56     txt_vec57     txt_vec58  \\\n",
              "0  2.5134534836 -5.3958601952  0.7621323466  2.8018035889  0.8779643178   \n",
              "1  0.8664698601 -0.8825763464 -1.6469770670  1.9151748419  2.8002102375   \n",
              "2  3.8664577007 -4.0532517433 -0.5716705322  2.1306719780  1.0535889864   \n",
              "3  3.9502623081 -1.0030276775 -0.6423271894 -0.7421406507  1.8295041323   \n",
              "4  2.6540911198 -5.9325356483 -0.4189185500 -0.9260056019 -0.5426020026   \n",
              "\n",
              "      txt_vec59     txt_vec60     txt_vec61     txt_vec62     txt_vec63  \\\n",
              "0 -0.5859798193  1.9625556469 -5.1712174416  1.1816873550  0.5419528484   \n",
              "1  1.4765350819  2.3451476097 -1.6753772497 -2.9482414722  4.3225460052   \n",
              "2  0.1100640595  2.8935914040 -4.3589577675 -1.0194541216  0.3668791652   \n",
              "3 -0.3699176610  0.5510581136 -4.0429396629 -1.8587552309  1.1932451725   \n",
              "4  0.4626600146  1.4631899595 -4.1606488228  0.1747602522  0.0668889135   \n",
              "\n",
              "      txt_vec64     txt_vec65     txt_vec66     txt_vec67     txt_vec68  \\\n",
              "0  0.4858333170  4.2125682831  3.4581983089  1.4029390812 -0.5462926030   \n",
              "1  0.0064851381  1.5961343050  1.7408252954  2.5171482563  1.6526031494   \n",
              "2  1.8413580656  4.1702466011  4.1743388176  1.2625701427 -0.0290785655   \n",
              "3  0.5523794889  0.8406279087 -0.1998117566 -0.5318464041  0.5840061307   \n",
              "4  1.9713603258  1.9823232889  2.5010893345  0.2407858074 -0.5280813575   \n",
              "\n",
              "      txt_vec69     txt_vec70     txt_vec71     txt_vec72     txt_vec73  \\\n",
              "0  2.1821005344 -0.0962546766  1.7366081476  0.6851462722 -1.6132848263   \n",
              "1  2.3012015820 -1.8203756809  0.3131376207 -0.4605118036 -1.4658217430   \n",
              "2  0.3916682005  0.8510245085  2.0302724838 -0.5232113004 -2.9885025024   \n",
              "3  0.2384417951 -0.1831949651 -0.9647368193  0.0030380934 -3.8698849678   \n",
              "4  0.9364103079 -0.2675441802  1.1475917101  0.2777195573 -1.5763708353   \n",
              "\n",
              "      txt_vec74     txt_vec75     txt_vec76     txt_vec77     txt_vec78  \\\n",
              "0 -0.9128761888 -0.5323970318  1.7248421907  2.2641146183 -2.2597558498   \n",
              "1  0.0256607905  0.1975094974  0.9521799088  1.8086135387 -3.9243142605   \n",
              "2  0.4683658183  2.1632678509  2.6002571583  3.4216189384 -3.7261285782   \n",
              "3  0.1377555430  2.9626429081  0.8658820391  4.0657339096 -2.1266815662   \n",
              "4 -1.3750151396  2.2555143833  2.0386326313  3.8130803108 -2.5444471836   \n",
              "\n",
              "      txt_vec79     txt_vec80     txt_vec81     txt_vec82     txt_vec83  \\\n",
              "0  4.5065088272 -0.3460883200  0.9281976819 -2.0782611370 -0.1955756247   \n",
              "1  0.8740619421  1.5076384544 -1.4749593735 -0.7281465530  1.6809406281   \n",
              "2  3.6566011906  1.3187823296  1.9449762106 -1.1189107895  2.6336503029   \n",
              "3 -0.1394288242 -0.0651780367  0.0671006665 -1.7295682430  3.5149486065   \n",
              "4  2.7090351582 -1.2576792240  1.2818650007 -0.3754705787  1.0863946676   \n",
              "\n",
              "      txt_vec84     txt_vec85     txt_vec86     txt_vec87     txt_vec88  \\\n",
              "0  4.8475780487 -2.9586863518  1.0060796738  2.0822322369 -2.2596824169   \n",
              "1 -2.2752487659  0.1606744528 -1.1758519411  2.7073900700 -1.5404677391   \n",
              "2  1.9950672388 -1.3083131313 -1.9136729240  1.8380401134 -4.9061074257   \n",
              "3  1.6050981283  0.6517529488 -1.3164319992  0.4306410849 -0.9936897755   \n",
              "4  3.9390137196 -0.7524920106 -0.4735445082  0.2154830545 -3.9462544918   \n",
              "\n",
              "      txt_vec89     txt_vec90     txt_vec91     txt_vec92     txt_vec93  \\\n",
              "0 -2.0333144665  0.2182324231  3.9753122330  2.0034470558 -0.2406283617   \n",
              "1 -1.7555799484  1.2667036057  0.5049359202  1.0696272850  1.8924552202   \n",
              "2 -3.0755031109 -0.6857675910  2.5223836899  0.5497792959  1.4827349186   \n",
              "3 -4.6938705444 -1.9676889181  3.2283120155  1.3695452213 -0.1332462430   \n",
              "4 -1.3390405178 -0.5571385622  1.8416041136 -0.2635599077 -0.5724999309   \n",
              "\n",
              "      txt_vec94     txt_vec95     txt_vec96     txt_vec97     txt_vec98  \\\n",
              "0 -2.4685480595  1.6660641432 -2.0819606781 -2.4968724251 -1.9016369581   \n",
              "1 -2.8700709343  1.3147110939 -0.6476105452 -3.8642375469 -1.1287094355   \n",
              "2  0.8170077205  1.9330986738 -2.5392942429 -0.4976403117 -1.0175911188   \n",
              "3  0.4559089541 -0.9183557034 -1.4347511530  0.9158083797  0.4877495468   \n",
              "4  1.6691718102 -0.0412875786 -1.7513698339 -0.9225690961 -0.8901174664   \n",
              "\n",
              "      txt_vec99    txt_vec100    txt_vec101    txt_vec102    txt_vec103  \\\n",
              "0  0.2714739740 -2.2981684208 -1.7873090506  1.6180669069 -2.9975774288   \n",
              "1 -0.2163546234  0.0200870410 -1.0009949207  1.8183261156 -1.2894283533   \n",
              "2 -2.7609453201 -1.8073147535 -3.6103582382  4.2451257706 -4.4561161995   \n",
              "3  1.0235780478 -0.0599985197 -4.7873816490 -1.5516570807 -3.0073292255   \n",
              "4 -0.7344263792 -0.1985396743 -4.6947107315  2.3384141922 -3.1651930809   \n",
              "\n",
              "     txt_vec104    txt_vec105    txt_vec106    txt_vec107    txt_vec108  \\\n",
              "0  0.0420643799 -1.2196398973 -2.3956730366  5.6090831757 -1.4914845228   \n",
              "1  1.3204821348  0.9189465046  2.3127784729  0.9761807323 -1.1034594774   \n",
              "2  1.7062046528 -3.1820578575  0.1201333702  4.3089995384 -3.7071764469   \n",
              "3  2.0735120773 -3.4647843838 -2.7820105553 -0.0993154496 -4.0383219719   \n",
              "4 -0.6592266560 -2.2427787781 -0.2026949227  2.8271911144 -3.3360562325   \n",
              "\n",
              "     txt_vec109    txt_vec110    txt_vec111    txt_vec112    txt_vec113  \\\n",
              "0  1.7885915041  4.1772522926  4.4608173370 -1.2361496687 -2.0794692039   \n",
              "1 -1.2471879721 -2.9002075195  1.2914571762  1.5193878412 -0.8292294741   \n",
              "2  3.7954654694  2.0711903572  3.6382451057 -2.5796868801  1.3196798563   \n",
              "3 -0.8915926218  0.6951371431  3.5863361359  1.0518940687  1.5735805035   \n",
              "4  3.8229005337  0.8821620941  2.8626224995 -2.6367087364  0.5635325909   \n",
              "\n",
              "     txt_vec114    txt_vec115    txt_vec116    txt_vec117    txt_vec118  \\\n",
              "0 -4.3971495628  0.3652189076  0.8151836395  5.4751114845  4.2397766113   \n",
              "1 -2.4343063831 -0.7656114101  0.6017384529  3.1130170822  0.7010914087   \n",
              "2 -3.7506515980  2.7014789581 -0.2162129283  5.0864233971  2.7782700062   \n",
              "3 -4.2804646492  3.1986303329 -2.7923855782  3.2322039604 -3.1985409260   \n",
              "4 -2.7188420296  2.0029742718  1.4403909445  4.0350317955  0.6819838881   \n",
              "\n",
              "     txt_vec119    txt_vec120    txt_vec121    txt_vec122    txt_vec123  \\\n",
              "0  0.9392179847  1.1986280680 -1.4769824743 -1.5552177429  0.3611471355   \n",
              "1  0.5787922144  0.5351995230 -0.9441672564 -0.1240377501 -1.4508235455   \n",
              "2  3.9552774429  0.3138726354 -2.3330941200  0.2004831731  0.6144545674   \n",
              "3  2.5838351250 -1.2322738171 -2.7884037495  1.4736993313 -3.1015565395   \n",
              "4  4.4928522110 -0.8764061332 -2.3473026752  0.0668368563 -1.4170516729   \n",
              "\n",
              "     txt_vec124    txt_vec125    txt_vec126    txt_vec127      img_vec0  \\\n",
              "0  2.0227699280 -1.5996438265  3.2231538296 -1.4574943781 -2.8722801208   \n",
              "1  0.3650854230 -1.1901761293  1.6859598160  0.8126941919 -0.0705208853   \n",
              "2 -0.2370703667 -5.3172769547  4.8742480278  0.5578527451 -5.1803641319   \n",
              "3 -0.9659563899 -3.5598251820  4.0261893272  1.3633310795 -1.0772739649   \n",
              "4 -0.0014237612 -3.9701452255  4.4187226295  0.2834067345 -3.2601945400   \n",
              "\n",
              "       img_vec1      img_vec2      img_vec3      img_vec4      img_vec5  \\\n",
              "0  1.4587551355  2.5790126324 -1.6097468138  1.4378223419  1.3874959946   \n",
              "1 -1.4393335581  0.7728728056 -2.3489952087 -0.2355124950 -0.8700022697   \n",
              "2 -0.3882471323 -0.0362354293 -1.8510223627  1.2238538265  1.9967815876   \n",
              "3  2.8394529819  1.1834309101 -1.0987117290  0.9005973339  1.4222483635   \n",
              "4  0.4988903403  2.5831427574 -2.5513806343  1.4665173292 -0.1956336200   \n",
              "\n",
              "       img_vec6      img_vec7      img_vec8      img_vec9     img_vec10  \\\n",
              "0  0.7249992490  0.0203323103  0.3120986819 -1.9997732639 -1.8057322502   \n",
              "1 -0.5425865054  1.5831973553  1.7427791357 -2.9939756393 -0.8622460961   \n",
              "2  0.7940438390 -0.2907482982  0.3932960033 -1.1030144691 -2.6933064461   \n",
              "3  0.1098280475 -3.7701313496  0.1382257044 -3.4304034710 -1.1713567972   \n",
              "4  1.2730638981  0.4443459213  1.9116442204 -1.8641946316  0.4185179174   \n",
              "\n",
              "      img_vec11     img_vec12     img_vec13     img_vec14     img_vec15  \\\n",
              "0 -0.1739237309 -2.1751496792 -0.4395467937 -1.8935351372 -0.7034621835   \n",
              "1 -1.2157950401 -2.3686754704  2.3326988220  1.9421590567  1.1301317215   \n",
              "2  1.2588562965 -1.9516181946 -1.6696166992 -1.3041158915 -0.7412303686   \n",
              "3 -1.2840040922 -0.0544508547 -2.2876307964 -0.5878560543 -3.7379798889   \n",
              "4 -2.4434888363 -1.9919613600 -0.6361541748 -1.0268591642 -0.8774957061   \n",
              "\n",
              "      img_vec16     img_vec17     img_vec18     img_vec19     img_vec20  \\\n",
              "0 -1.9535105228  0.6914859414  0.6445956826  2.0112810135 -0.4342123568   \n",
              "1 -2.5715732574  2.0020222664  3.8542828560 -0.4467480779  0.3667028844   \n",
              "2 -1.9874830246  1.1826648712  0.1876281202  2.8795382977 -1.4945707321   \n",
              "3 -0.7720518112  0.6717689037  1.4492791891 -0.1424507499 -0.6465058327   \n",
              "4  0.7087628841  1.8621208668  0.8565728068  1.7871872187 -0.2045107186   \n",
              "\n",
              "      img_vec21     img_vec22     img_vec23     img_vec24     img_vec25  \\\n",
              "0  2.6146309376  2.1234035492 -2.8775033951  1.0714125633  0.4730164111   \n",
              "1  0.3724231422 -1.9866981506 -0.1244335026 -2.7045094967 -2.9197115898   \n",
              "2  4.8454046249  1.6018526554 -2.2582504749  0.6056196094  1.3605409861   \n",
              "3  2.2852480412 -1.3476312160 -0.3918263912  0.2032637298 -0.4844906628   \n",
              "4  1.8074589968 -1.2486822605 -2.0458302498 -0.6823843718 -1.0407505035   \n",
              "\n",
              "      img_vec26     img_vec27     img_vec28     img_vec29     img_vec30  \\\n",
              "0  2.4707813263 -1.6296484470 -2.5948154926  2.1294517517 -1.0729905367   \n",
              "1 -3.0368967056 -1.1918561459 -2.3457062244  1.7503809929 -0.7577392459   \n",
              "2  2.2704613209 -2.3936748505 -2.5237107277  2.3623688221 -3.7879507542   \n",
              "3 -2.1060159206 -3.5996644497 -4.4429578781  1.7781949043 -4.1688241959   \n",
              "4 -0.1911843121 -1.1757192612 -3.0022175312  1.3092085123  0.7799966335   \n",
              "\n",
              "      img_vec31     img_vec32     img_vec33     img_vec34     img_vec35  \\\n",
              "0  2.4951767921 -0.6153161526 -0.3726658523  1.4416368008 -0.3869579732   \n",
              "1  0.7082000375 -2.0362606049 -1.2478457689  1.3371763229  0.3810861111   \n",
              "2  4.1489663124  0.5273576379 -0.4623291790  1.9587676525 -0.5154456496   \n",
              "3  2.1066026688 -2.6107659340 -4.6652832031  4.2292447090  1.1606259346   \n",
              "4  1.5844647884 -0.2545006573 -1.9702123404  2.6014389992  0.7656390667   \n",
              "\n",
              "      img_vec36     img_vec37     img_vec38     img_vec39     img_vec40  \\\n",
              "0  0.5742669106  0.2901403606  2.1439840794 -2.1797549725  1.0018137693   \n",
              "1 -2.1957163811  2.3492677212  3.2342376709 -1.0737447739  2.7275660038   \n",
              "2  0.6768915653 -0.3047086000  0.1290760487 -1.6329034567 -0.4164456129   \n",
              "3  1.1377283335  0.3503388762  3.7622182369 -1.5629478693  3.2892580032   \n",
              "4 -0.3065223992  1.4117398262  2.0450096130 -1.4351650476  0.6078616381   \n",
              "\n",
              "      img_vec41     img_vec42     img_vec43     img_vec44     img_vec45  \\\n",
              "0  1.7092645168  1.7659958601 -0.9781475067  2.3762657642  1.2863856554   \n",
              "1  2.1341414452  1.3165485859  1.4014288187  0.3226478398  1.5204454660   \n",
              "2  0.2012564689  1.5046161413 -1.8403992653  0.7415528893  1.1971130371   \n",
              "3  0.6765853763 -1.1160399914 -2.3792004585  0.3785956204  0.5143413544   \n",
              "4  1.8148971796  1.9150559902  1.3558405638  0.3710158169  1.5915417671   \n",
              "\n",
              "      img_vec46     img_vec47     img_vec48     img_vec49     img_vec50  \\\n",
              "0 -1.4987120628 -2.1206870079 -1.6261025667 -1.7383675575 -0.2232712805   \n",
              "1 -1.5553992987 -1.7593723536 -0.5223306417 -2.0628519058  1.2358421087   \n",
              "2  0.4738982022 -0.9263385534  0.7251952887 -2.4600844383  0.6102679968   \n",
              "3  3.4223504066  1.5008887053 -2.3732028008  1.3730483055 -1.8183721304   \n",
              "4 -1.3562458754 -2.0786681175 -1.4965167046 -1.5357089043  0.5223278999   \n",
              "\n",
              "      img_vec51     img_vec52     img_vec53     img_vec54     img_vec55  \\\n",
              "0  1.2644373178 -0.9871305823 -1.9093743563  2.2314555645 -2.6836464405   \n",
              "1  0.1661762446 -3.3796861172 -2.2228477001  1.6136515141  0.7360733747   \n",
              "2  2.4189102650 -0.8073080182 -2.4715397358  2.5514853001 -1.8118276596   \n",
              "3  0.2093314379 -4.0995993614 -2.2917511463  1.7036482096 -1.7782133818   \n",
              "4  1.3364672661 -2.0848152637 -2.3919889927  1.2798339128 -0.4796919227   \n",
              "\n",
              "      img_vec56     img_vec57     img_vec58     img_vec59     img_vec60  \\\n",
              "0 -0.6353181005  0.0858888105 -0.8235075474  0.5569828153  2.5153543949   \n",
              "1 -2.1893527508  1.2845479250  2.8726134300  2.6761150360  0.1475290209   \n",
              "2  0.1008770168  0.7436977029 -1.1163951159 -0.3596743941  3.0285360813   \n",
              "3  0.2453990728 -3.7033028603  1.4522143602  2.1704957485  1.1902852058   \n",
              "4  0.8068606853  0.0033650771  0.1334796101  1.9405741692  0.3472729027   \n",
              "\n",
              "      img_vec61     img_vec62     img_vec63     img_vec64     img_vec65  \\\n",
              "0 -3.4205298424  0.0634656399  0.0094741732 -0.0657508075 -1.0753654242   \n",
              "1 -1.3171087503 -2.6440515518 -1.8350887299  0.9574174285 -2.3858914375   \n",
              "2 -2.4324274063  1.5074805021  1.7838965654 -0.2175149024 -2.6842575073   \n",
              "3 -2.3954641819 -0.1170736402  0.6126937270 -4.3434071541 -3.7077896595   \n",
              "4 -3.2160534859 -1.1251442432 -0.4129741192 -0.4549874365 -1.5074959993   \n",
              "\n",
              "      img_vec66     img_vec67     img_vec68     img_vec69     img_vec70  \\\n",
              "0 -2.9713089466  1.0196198225  2.5095589161 -1.5258373022  0.5425801277   \n",
              "1 -0.6619012356  2.6582648754 -0.9451054931 -1.0119893551 -0.6547811627   \n",
              "2 -2.6698846817  1.3063540459  2.1978611946  0.2396692932  0.6746810079   \n",
              "3 -1.9681696892  1.6769342422 -1.6965925694  0.8841276169  1.8131419420   \n",
              "4 -1.0031266212  1.4596577883  0.3572512269 -1.2548041344 -0.3108480573   \n",
              "\n",
              "      img_vec71     img_vec72     img_vec73     img_vec74     img_vec75  \\\n",
              "0 -0.2697300315 -0.0359621942  0.3917995691 -1.2341160774  2.3140294552   \n",
              "1 -0.3363517821 -2.1268010139  1.3375129700 -1.0618399382  0.4118506312   \n",
              "2 -0.1925708055 -0.1629413515  2.5120844841 -1.0960826874  3.5255630016   \n",
              "3  1.8550761938  1.3032124043  2.0474886894  0.6032235622  3.9587745667   \n",
              "4 -1.8746677637 -1.0605058670  0.0878456458 -1.9225060940  1.1394615173   \n",
              "\n",
              "      img_vec76     img_vec77     img_vec78     img_vec79     img_vec80  \\\n",
              "0  1.8986169100 -2.3611283302  0.3124046326  3.4446072578 -0.8862501383   \n",
              "1  0.2462557554 -2.2640297413  2.3994200230  2.0248627663  0.1704825163   \n",
              "2  1.0564339161 -2.1295158863 -0.0054923594  3.8271811008 -0.3581976295   \n",
              "3  3.7462685108 -3.4980876446 -0.7330384254 -0.9137355089 -1.2961897850   \n",
              "4  0.2324949801 -1.6677292585  1.0865254402  3.2355041504 -1.3600406647   \n",
              "\n",
              "      img_vec81     img_vec82     img_vec83     img_vec84     img_vec85  \\\n",
              "0 -1.3436369896  0.9544589520  0.6308349371 -2.3947217464  0.6834869981   \n",
              "1 -0.0392032042 -1.5066767931 -1.9459319115 -0.0202283077 -0.4954991639   \n",
              "2 -2.0093791485 -0.2243905813  0.8038508296 -0.9094979167  0.9628103375   \n",
              "3  4.8217391968  0.6872349381 -1.4064308405  0.6691839695 -1.8475983143   \n",
              "4 -0.5736263990 -0.3438729644 -0.8621111512 -3.0362601280 -1.0166102648   \n",
              "\n",
              "      img_vec86     img_vec87     img_vec88     img_vec89     img_vec90  \\\n",
              "0  1.1490038633 -1.3511732817  2.0239000320  1.5991983414  1.3828682899   \n",
              "1 -0.1410129666 -1.6175206900  2.6246759892 -2.5819215775  0.2208910137   \n",
              "2  2.6015825272  0.0563275069  1.8594735861 -0.3161342740 -1.1312859058   \n",
              "3 -0.8170750737 -1.1811718941  2.5885522366 -1.1231178045  0.2324265391   \n",
              "4 -1.1497695446  0.4641397595  2.4124057293 -0.6541346908  0.4868938923   \n",
              "\n",
              "      img_vec91     img_vec92     img_vec93     img_vec94     img_vec95  \\\n",
              "0  1.6056783199  1.8806668520 -0.5081608891  0.2428404391 -0.2608487904   \n",
              "1  0.3287933767  0.6477577090  0.2319895625  1.1014859676  1.0795272589   \n",
              "2  1.7012784481  2.3054049015 -1.9412707090  1.2480015755  0.2910004854   \n",
              "3  2.1703250408  0.5794144869  2.6014208794 -0.5961964726 -1.7986934185   \n",
              "4  1.1680536270 -0.2714197040  0.6670907736  1.1635572910 -0.1322363019   \n",
              "\n",
              "      img_vec96     img_vec97     img_vec98     img_vec99    img_vec100  \\\n",
              "0  1.8759434223  0.2061345726  0.1869730353  2.0474455357 -0.5754722953   \n",
              "1  2.9531016350 -0.5286824107 -1.1405997276 -0.3732994497  0.1098105833   \n",
              "2  0.7920667529  1.3611664772  1.1290049553  1.9474035501 -0.8594229817   \n",
              "3  0.3123261333  0.3874855340 -2.2073650360 -1.0293287039 -1.2742329836   \n",
              "4  0.6684629917 -0.2281846255  0.1557677239  1.5468212366  0.3076400459   \n",
              "\n",
              "     img_vec101    img_vec102    img_vec103    img_vec104    img_vec105  \\\n",
              "0  3.0164101124  2.7571456432  3.3537209034 -0.4572715461 -0.1253366172   \n",
              "1  2.8135411739  0.5969979167  1.7548358440 -1.3597713709  0.4665011466   \n",
              "2  2.0232229233  2.3486514091  4.5061273575  0.6844365001  2.0649919510   \n",
              "3  2.0472295284  1.9285165071  2.1026327610 -0.5593834519 -0.9514183998   \n",
              "4  2.5429413319  1.2409851551  2.1445691586 -1.0797533989  0.3351914585   \n",
              "\n",
              "     img_vec106    img_vec107    img_vec108    img_vec109    img_vec110  \\\n",
              "0  2.3329634666  3.8589668274 -2.0754899979 -0.7054958344  0.2034520507   \n",
              "1  2.3774173260 -0.1806525588 -3.2593042850  0.1208329052  2.2256433964   \n",
              "2  0.0229008049  3.4642429352 -2.3252725601  0.1313239187 -1.8761780262   \n",
              "3 -2.0217494965  1.3662722111 -1.9472106695 -2.1144192219  1.1403938532   \n",
              "4  0.2451588660  2.1501686573 -1.9914399385 -2.3307268620  0.7368552089   \n",
              "\n",
              "     img_vec111    img_vec112    img_vec113    img_vec114    img_vec115  \\\n",
              "0  1.7197328806  2.9250385761 -0.3886387944  1.2257323265 -1.7731370926   \n",
              "1  2.2205066681 -1.1789444685 -0.8213667870  0.7172386646 -1.4558292627   \n",
              "2  1.7703540325  2.9251759052 -1.8510544300 -0.0925873220 -0.5807421207   \n",
              "3 -0.7960235476  1.9063613415 -0.3575199842  3.3529679775 -3.9963769913   \n",
              "4  2.1269307137  0.5560612679 -1.6114931107  2.7221329212 -1.1859402657   \n",
              "\n",
              "     img_vec116    img_vec117    img_vec118    img_vec119    img_vec120  \\\n",
              "0  0.0526551157  1.2799222469 -3.3747272491 -1.5069689751 -1.8201801777   \n",
              "1 -1.2605844736  2.6234674454 -0.5383300781 -2.6201636791  1.2771952152   \n",
              "2 -0.4220193028  0.9237140417 -4.5827107430 -1.0569097996 -2.5680844784   \n",
              "3  1.5203311443 -0.0007160828 -0.4876829982 -1.8891189098  0.9430151582   \n",
              "4  0.3992010057  1.5986174345 -0.6214751601 -2.0914101601  0.5015996695   \n",
              "\n",
              "     img_vec121    img_vec122    img_vec123    img_vec124    img_vec125  \\\n",
              "0 -3.0246436596  0.4452633858  0.0139333047 -1.3002386093  2.7599484921   \n",
              "1  0.6010145545 -0.3453120291  0.9934566021  1.3516329527  2.1626746655   \n",
              "2 -2.0380613804  2.5087187290 -0.7647889853 -0.6571162343  3.2527816296   \n",
              "3 -2.8344175816  1.6331835985  2.0018005371 -2.3331520557  2.6455948353   \n",
              "4 -3.0838639736 -1.0600911379  2.0536000729 -2.0250082016  2.3992507458   \n",
              "\n",
              "     img_vec126    img_vec127  \n",
              "0  2.0561711788  0.5087034702  \n",
              "1  2.7685971260 -0.9371970296  \n",
              "2  2.6873664856  0.8443320990  \n",
              "3  2.2802333832 -0.6944484115  \n",
              "4  2.5623166561  0.6941336393  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8A1kAyZGp7Yt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_img_vec = df_item[['item_id'] + ['img_vec' + str(i) for i in range(128)]]\n",
        "df_img_vec['item_img_vec'] = df_img_vec.apply(lambda x: np.array(x.values[1:].tolist()), axis=1)\n",
        "items = df_img_vec['item_id'].values.tolist()\n",
        "img_vecs = df_img_vec['item_img_vec'].values.tolist()\n",
        "df_img_vec[['item_id','item_img_vec']].to_pickle('kdd2020_data/my_model/item_img_vec.pkl')\n",
        "\n",
        "item_vec_map = dict(zip(items, img_vecs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCESKo-lqUFY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "583c609b-c6c4-41ae-9197-16391bc675b5"
      },
      "source": [
        "#setup index for item img\n",
        "index_to_item_dict = {}\n",
        "item_to_index_dict = {}\n",
        "\n",
        "item_index = AnnoyIndex(128, 'angular')\n",
        "item_index.set_seed(2020)\n",
        "\n",
        "for i, row in tqdm(df_item.iterrows()):\n",
        "    emb = row[-128:].values\n",
        "\n",
        "    item = row[0]\n",
        "    index_to_item_dict[i] = item\n",
        "    item_to_index_dict[item] = i\n",
        "\n",
        "    item_index.add_item(i, emb)\n",
        "\n",
        "item_index.build(100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "108916it [00:22, 4777.05it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKts2MuFqbDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rec4(df_qtime, user_embs, item_index, index_to_item_dict):\n",
        "    data_list = []\n",
        "    for user_id, query_time, item_id, phase in tqdm(df_qtime.values):\n",
        "        user_emb = user_embs[user_id]\n",
        "        ids, distances = item_index.get_nns_by_vector(user_emb,100,include_distances=True)\n",
        "\n",
        "        item_ids = [index_to_item_dict[id] for id in ids]\n",
        "        \n",
        "        item_sim_scores = [2 - distance for distance in distances]\n",
        "\n",
        "        df_temp = pd.DataFrame()\n",
        "        df_temp['item_id'] = item_ids\n",
        "        df_temp['sim_score'] = item_sim_scores\n",
        "        df_temp['user_id'] = user_id\n",
        "        df_temp['query_time'] = query_time\n",
        "        df_temp['phase'] = phase\n",
        "\n",
        "        if item_id == -1:\n",
        "            df_temp['label'] = np.nan\n",
        "        else:\n",
        "            df_temp['label'] = 0\n",
        "            df_temp.loc[df_temp['item_id'] == item_id, 'label'] = 1\n",
        "\n",
        "        df_temp.sort_values(['sim_score'], inplace=True, ascending=False)\n",
        "\n",
        "        df_temp = df_temp[[\n",
        "            'user_id', 'phase', 'query_time', 'item_id', 'sim_score', 'label'\n",
        "        ]]\n",
        "        df_temp['user_id'] = df_temp['user_id'].astype('int')\n",
        "        df_temp['item_id'] = df_temp['item_id'].astype('int')\n",
        "\n",
        "        data_list.append(df_temp)\n",
        "\n",
        "    df_data = pd.concat(data_list, sort=False)\n",
        "    return df_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjPxwi32qw2k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@multitasking.task\n",
        "def work(phase, force=False):\n",
        "    os.makedirs('kdd2020_data/my_model/recall_4', exist_ok=True)\n",
        "\n",
        "    if force or (not os.path.exists('kdd2020_data/my_model/recall_4/user_img_vec{}.pkl'.format(phase))\n",
        "                 or not os.path.exists('kdd2020_data/my_model/recall_4/recall_{}.pkl'.format(phase))):\n",
        "        # 获取当前阶段的click\n",
        "        df_click_phase = df_click[df_click['phase'] == phase]\n",
        "\n",
        "        # 生成用户embedding\n",
        "        tmp = df_click_phase.groupby('user_id', as_index=False)['item_id'].agg(\n",
        "            {'list': list})\n",
        "        sentences = tmp['list'].values.tolist()\n",
        "        del tmp['list']\n",
        "\n",
        "        emb_matrix = []\n",
        "        for seq in sentences:\n",
        "            seq = seq[::-1]\n",
        "\n",
        "            vec = []\n",
        "            for pos, w in enumerate(seq):\n",
        "                if w in item_vec_map.keys():\n",
        "                    vec.append(np.asarray(item_vec_map[w]) * (0.7**pos))\n",
        "            if len(vec) > 0:\n",
        "                emb_matrix.append(np.mean(vec, axis=0))\n",
        "            else:\n",
        "                emb_matrix.append([0] * 128)\n",
        "\n",
        "        df_user_img_vec = tmp\n",
        "        df_user_img_vec['user_img_vec'] = emb_matrix\n",
        "        # df_user_img_vec.to_pickle('kdd2020_data/my_model/user_img_vec.pkl')\n",
        "        df_user_img_vec['phase'] = phase\n",
        "        df_user_img_vec.to_pickle('kdd2020_data/my_model/recall_4/user_img_vec{}.pkl'.format(phase))\n",
        "\n",
        "        users = tmp['user_id'].values.tolist()\n",
        "        user_embs = dict(zip(users, emb_matrix))\n",
        "\n",
        "        df_qtime_phase = df_qtime[df_qtime['phase'] == phase]\n",
        "        df_data = rec4(df_qtime_phase, user_embs, item_index,index_to_item_dict)\n",
        "\n",
        "        df_data.to_pickle('kdd2020_data/my_model/recall_4/recall_{}.pkl'.format(phase))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL7rbV8urrnP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "01eb430e-3d1e-4cd3-dd42-00b5da21133a"
      },
      "source": [
        "force = False\n",
        "for phase in phases:\n",
        "    work(phase, force)\n",
        "\n",
        "multitasking.wait_for_tasks()\n",
        "print('over')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18505/18505 [07:52<00:00, 39.14it/s]\n",
            "100%|██████████| 18398/18398 [08:01<00:00, 38.24it/s]\n",
            "100%|██████████| 18672/18672 [08:03<00:00, 38.66it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "over\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxoJwSbpr8y5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(df, median_item_degree, item_degree_map, num_cases_full, num_cases_half):\n",
        "    gg = df.groupby(['user_id'])\n",
        "\n",
        "    ndcg_50_full = 0.0\n",
        "    hitrate_50_full = 0.0\n",
        "\n",
        "    ndcg_50_half = 0.0\n",
        "    hitrate_50_half = 0.0\n",
        "\n",
        "    for _, g in tqdm(gg):\n",
        "        try:\n",
        "            item_id = g[g['label'] == 1]['item_id'].values[0]\n",
        "            item_degree = item_degree_map[item_id]\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "        predictions = g['item_id'].values.tolist()\n",
        "\n",
        "        rank = 0\n",
        "        while rank < 50 and predictions[rank] != item_id:\n",
        "            rank += 1\n",
        "\n",
        "        if rank < 50:\n",
        "            ndcg_50_full += 1.0 / np.log2(rank + 2.0)\n",
        "            hitrate_50_full += 1.0\n",
        "\n",
        "        if item_degree <= median_item_degree:\n",
        "            if rank < 50:\n",
        "                ndcg_50_half += 1.0 / np.log2(rank + 2.0)\n",
        "                hitrate_50_half += 1.0\n",
        "\n",
        "    ndcg_50_full /= num_cases_full\n",
        "    hitrate_50_full /= num_cases_full\n",
        "\n",
        "    ndcg_50_half /= num_cases_half\n",
        "    hitrate_50_half /= num_cases_half\n",
        "\n",
        "    return ndcg_50_full, hitrate_50_full, ndcg_50_half, hitrate_50_half"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Op2q7qMwsBaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_scores(df, phase):\n",
        "    df_qtime = pd.read_pickle('kdd2020_data/recall/qtime.pkl')\n",
        "    df_click = pd.read_pickle('kdd2020_data/recall/click.pkl')\n",
        "    \n",
        "    df_qtime = df_qtime[df_qtime['phase']==phase]\n",
        "    df_click = df_click[df_click['phase']==phase]\n",
        "\n",
        "    oof_answer = df_qtime[df_qtime['item_id'] != -1]\n",
        "    num_cases_full = oof_answer.shape[0]\n",
        "\n",
        "    answer_items = oof_answer['item_id'].values\n",
        "    item_degree = df_click['item_id'].value_counts().reset_index()\n",
        "    item_degree.columns = ['item_id', 'degree']\n",
        "\n",
        "    answer_item_degree = item_degree[item_degree['item_id'].isin(answer_items)]\n",
        "    list_item_degress = answer_item_degree['degree'].values.tolist()\n",
        "    median_item_degree = list_item_degress[len(list_item_degress) // 2]\n",
        "    item_degree_map = dict(zip(item_degree['item_id'], item_degree['degree']))\n",
        "    num_cases_half = answer_item_degree[answer_item_degree['degree']\n",
        "                                        <= median_item_degree].shape[0]\n",
        "\n",
        "    ndcg_50_full, hitrate_50_full, ndcg_50_half, hitrate_50_half = evaluate(\n",
        "        df, median_item_degree, item_degree_map, num_cases_full, num_cases_half)\n",
        "    return ndcg_50_full, hitrate_50_full, ndcg_50_half, hitrate_50_half"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxiCDOSrrt-3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "a178c1a8-5909-4d7f-dffc-de5b022a4308"
      },
      "source": [
        "df_user_img_vec_phase = pd.DataFrame()\n",
        "df_recall = pd.DataFrame()\n",
        "val_score = np.array([0.0, 0.0, 0.0, 0.0])\n",
        "df_user_txt_vec_phase = pd.DataFrame()\n",
        "for phase in phases:\n",
        "    df_user_img_vec = pd.read_pickle('kdd2020_data/my_model/recall_4/user_img_vec{}.pkl'.format(phase))\n",
        "    df_data = pd.read_pickle('kdd2020_data/my_model/recall_4/recall_{}.pkl'.format(phase))\n",
        "\n",
        "    df_user_img_vec_phase = df_user_img_vec_phase.append(df_user_img_vec)\n",
        "    df_recall = df_recall.append(df_data)\n",
        "\n",
        "    score = evaluate_scores(df_data, phase)\n",
        "    val_score += score\n",
        "\n",
        "    print('phase', phase, score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18505/18505 [00:18<00:00, 989.55it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "phase 0 (0.0064046248809043185, 0.020484503028143926, 0.007743461517184497, 0.02421897391802809)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18672/18672 [00:19<00:00, 980.96it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "phase 1 (0.0068464595884933175, 0.021893072111412722, 0.008489119674941013, 0.025880661394680086)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18398/18398 [00:19<00:00, 956.49it/s] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "phase 2 (0.0069302797515830026, 0.023042853722767535, 0.007733284420870578, 0.02529585798816568)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lfoj5fE2sOT7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "98829646-a497-43d1-9f7a-920cc3bb7923"
      },
      "source": [
        "df_user_img_vec_phase.to_pickle('kdd2020_data/my_model/user_img_vec.pkl')\n",
        "val_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.02018136, 0.06542043, 0.02396587, 0.07539549])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8C_qmu8sToX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1c8854dd-1b7e-471c-e4b7-ab001128230e"
      },
      "source": [
        "df_recall.sort_values(['user_id', 'phase', 'query_time'], inplace=True)\n",
        "df_recall.to_pickle('kdd2020_data/my_model/recall_4.pkl')\n",
        "df_recall.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>phase</th>\n",
              "      <th>query_time</th>\n",
              "      <th>item_id</th>\n",
              "      <th>sim_score</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>17887</td>\n",
              "      <td>1.5567105114</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>17559</td>\n",
              "      <td>1.5547946692</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>37316</td>\n",
              "      <td>1.5266568065</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>31443</td>\n",
              "      <td>1.5244504213</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>35217</td>\n",
              "      <td>1.5183159113</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  phase    query_time  item_id     sim_score  label\n",
              "0        1    0.0  0.9839419315    17887  1.5567105114    0.0\n",
              "1        1    0.0  0.9839419315    17559  1.5547946692    0.0\n",
              "2        1    0.0  0.9839419315    37316  1.5266568065    0.0\n",
              "3        1    0.0  0.9839419315    31443  1.5244504213    0.0\n",
              "4        1    0.0  0.9839419315    35217  1.5183159113    0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4jNIBgdstbn",
        "colab_type": "text"
      },
      "source": [
        "# Recall_5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU2owP7bs7Ad",
        "colab_type": "text"
      },
      "source": [
        "**item cf**\n",
        "\n",
        "$w_{ij}=\\frac{\\sum_(a*b*c*d)}{(N(i)*N(j))^{0.5}}$\n",
        "\n",
        "* a: a penalty function for rank distance\n",
        "* b: a penalty function for time\n",
        "* c: a penalty function for item txt\n",
        "* d: a penalty function for item img"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr5AaT1nsq8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from annoy import AnnoyIndex\n",
        "import os\n",
        "import warnings\n",
        "from collections import defaultdict\n",
        "import math\n",
        "import pickle\n",
        "import gc\n",
        "import multitasking\n",
        "import signal\n",
        "\n",
        "multitasking.set_max_threads(10)\n",
        "multitasking.set_engine('process')\n",
        "signal.signal(signal.SIGINT, multitasking.killall)\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('precision', 10)\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXXTOPmMtMyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_qtime = pd.read_pickle('kdd2020_data/recall/qtime.pkl')\n",
        "df_click = pd.read_pickle('kdd2020_data/recall/click.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4aZOdTmtRis",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1ceb3e2c-54af-499a-c5df-8e9e01e22893"
      },
      "source": [
        "phases = sorted(list(df_qtime['phase'].unique()))\n",
        "phases"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4eroCNitW2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def euc(v, w):\n",
        "    if np.max(v) == 0 and np.min(v) == 0 and np.max(w) == 0 and np.min(w) == 0:\n",
        "        return 10\n",
        "    return np.sqrt(np.sum(np.square(v - w)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjJ6vfidtZwy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def item2item(user_item_set_dict, item_user_set_dict, rank_dict, time_dict,\n",
        "              txt_vec_dict, img_vec_dict, sim_topN):\n",
        "    item2item_sim_dict = {}\n",
        "    for user in tqdm(user_item_set_dict.keys()):\n",
        "        for item1 in user_item_set_dict[user]:\n",
        "            if item1 not in item2item_sim_dict.keys():\n",
        "                item2item_sim_dict[item1] = {}\n",
        "            for item2 in user_item_set_dict[user]:\n",
        "                if item1 == item2:\n",
        "                    continue\n",
        "                if item2 not in item2item_sim_dict[item1].keys():\n",
        "                    item2item_sim_dict[item1][item2] = 0\n",
        "                heat_factor = 1 / (np.log2(1 + len(user_item_set_dict[user])) + \n",
        "                                np.sqrt(abs(rank_dict[user][item1] - rank_dict[user][item2])))\n",
        "                time_factor = 1 / \\\n",
        "                    np.sqrt(1 + 20000 * abs(time_dict[user][item1] - time_dict[user][item2]))\n",
        "                txt_euc_factor = 1 / \\\n",
        "                    np.sqrt(1 + euc(txt_vec_dict[item1], txt_vec_dict[item2]))\n",
        "                img_euc_factor = 1 / \\\n",
        "                    np.sqrt(1 + euc(img_vec_dict[item1], img_vec_dict[item2]) / 10)\n",
        "                score = heat_factor * time_factor * txt_euc_factor * img_euc_factor\n",
        "                item2item_sim_dict[item1][item2] += score / np.sqrt(\n",
        "                    len(item_user_set_dict[item1]) *\n",
        "                    len(item_user_set_dict[item2]))\n",
        "    \n",
        "    new_dic={}\n",
        "    items = item2item_sim_dict.keys()\n",
        "    for item in tqdm(items):\n",
        "      if len(item2item_sim_dict[item]) == 0:\n",
        "          # del item2item_sim_dict[item]\n",
        "          continue\n",
        "      elif len(item2item_sim_dict[item]) > sim_topN:\n",
        "        new=dict(sorted(item2item_sim_dict[item].items(),key=lambda x: x[1],\n",
        "                       reverse=True)[:sim_topN])\n",
        "        new_dic[item] =new\n",
        "      else:\n",
        "        new=dict(sorted(item2item_sim_dict[item].items(),\n",
        "                       key=lambda x: x[1],\n",
        "                       reverse=True))\n",
        "        new_dic[item] =new\n",
        "\n",
        "    # return item2item_sim_dict\n",
        "    return new_dic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SlyyKWqt7iv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rec5(df_qtime, item2item_sim_dict, user_item_set_dict, rank_dict,\n",
        "           time_dict, txt_vec_dict, recall_topN):\n",
        "    data_list = []\n",
        "\n",
        "    qtime_dict = dict(zip(df_qtime['user_id'], df_qtime['query_time']))\n",
        "\n",
        "    for user_id, query_time, item_id, phase in tqdm(df_qtime.values):\n",
        "        rank = {}\n",
        "        for item in user_item_set_dict[user_id]:\n",
        "            if item not in item2item_sim_dict.keys():\n",
        "              continue\n",
        "            for i in item2item_sim_dict[item].keys():\n",
        "                if i in user_item_set_dict[user_id]:\n",
        "                    continue\n",
        "                if i not in rank.keys():\n",
        "                    rank[i] = 0\n",
        "                rank_factor = 1 / np.sqrt(rank_dict[user_id][item])\n",
        "                time_factor = 1 - 1000 * \\\n",
        "                    (qtime_dict[user_id] - time_dict[user_id][item])\n",
        "                txt_euc_factor = 1 / \\\n",
        "                    (1 + euc(txt_vec_dict[i], txt_vec_dict[item]) / 100)\n",
        "                rank[i] += item2item_sim_dict[item][i] * \\\n",
        "                    rank_factor * time_factor * txt_euc_factor\n",
        "\n",
        "        sim_items = sorted(rank.items(), key=lambda d: d[1],\n",
        "                           reverse=True)[:recall_topN]\n",
        "        item_ids = [item[0] for item in sim_items]\n",
        "        item_sim_scores = [item[1] for item in sim_items]\n",
        "\n",
        "        df_temp = pd.DataFrame()\n",
        "        df_temp['item_id'] = item_ids\n",
        "        df_temp['sim_score'] = item_sim_scores\n",
        "        df_temp['user_id'] = user_id\n",
        "        df_temp['query_time'] = query_time\n",
        "        df_temp['phase'] = phase\n",
        "\n",
        "        if item_id == -1:\n",
        "            df_temp['label'] = np.nan\n",
        "        else:\n",
        "            df_temp['label'] = 0\n",
        "            df_temp.loc[df_temp['item_id'] == item_id, 'label'] = 1\n",
        "\n",
        "        df_temp.sort_values(['sim_score'], inplace=True, ascending=False)\n",
        "        df_temp = df_temp[[\n",
        "            'user_id', 'phase', 'query_time', 'item_id', 'sim_score', 'label'\n",
        "        ]]\n",
        "        df_temp['user_id'] = df_temp['user_id'].astype('int')\n",
        "        df_temp['item_id'] = df_temp['item_id'].astype('int')\n",
        "\n",
        "        data_list.append(df_temp)\n",
        "\n",
        "    df_data = pd.concat(data_list, sort=False)\n",
        "    return df_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfgJvSi_t_aK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "txt_vec_cols = ['txt_vec_{}'.format(i) for i in range(128)]\n",
        "img_vec_cols = ['img_vec_{}'.format(i) for i in range(128)]\n",
        "vec_df = pd.read_csv('kdd2020_data/underexpose_train/underexpose_item_feat.csv',\n",
        "                     names=['item_id'] + txt_vec_cols + img_vec_cols)\n",
        "vec_df['txt_vec_0'] = vec_df['txt_vec_0'].apply(lambda x: x.strip()[1:])\n",
        "vec_df['txt_vec_127'] = vec_df['txt_vec_127'].apply(lambda x: x.strip()[:-1])\n",
        "vec_df['img_vec_0'] = vec_df['img_vec_0'].apply(lambda x: x.strip()[1:])\n",
        "vec_df['img_vec_127'] = vec_df['img_vec_127'].apply(lambda x: x.strip()[:-1])\n",
        "vec_df[txt_vec_cols + img_vec_cols] = vec_df[txt_vec_cols +img_vec_cols].astype('float')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nknzvqa3uE4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@multitasking.task\n",
        "def work(phase, force=False):\n",
        "    os.makedirs('kdd2020_data/my_model/recall_5', exist_ok=True)\n",
        "\n",
        "    if force or (not os.path.exists('kdd2020_data/my_model/recall_5/sim_{}.pkl'.format(phase))\n",
        "                 or not os.path.exists('kdd2020_data/my_model/recall_5/recall_{}.pkl'.format(phase))):\n",
        "        \n",
        "        df_click_phase = df_click[df_click['phase'] == phase]\n",
        "\n",
        "        df_click_phase = df_click_phase.merge(vec_df, on='item_id', how='left')\n",
        "        for f in tqdm(txt_vec_cols + img_vec_cols):\n",
        "            df_click_phase[f] = df_click_phase[f].fillna(0)\n",
        "\n",
        "        txt_vec_dict = dict(\n",
        "            zip(df_click_phase['item_id'],\n",
        "                df_click_phase[txt_vec_cols].values))\n",
        "        img_vec_dict = dict(\n",
        "            zip(df_click_phase['item_id'],\n",
        "                df_click_phase[img_vec_cols].values))\n",
        "\n",
        "        df_click_phase['rank'] = df_click_phase.groupby('user_id')['time'].rank(method='first', ascending=False)\n",
        "        rank_df = df_click_phase.groupby('user_id')['item_id', 'rank'].apply(\n",
        "            lambda x: dict(zip(x['item_id'], x['rank']))).reset_index()\n",
        "        rank_dict = dict(zip(rank_df['user_id'], rank_df[0]))\n",
        "\n",
        "        time_df = df_click_phase.groupby('user_id')['item_id', 'time'].apply(\n",
        "            lambda x: dict(zip(x['item_id'], x['time']))).reset_index()\n",
        "        time_dict = dict(zip(time_df['user_id'], time_df[0]))\n",
        "\n",
        "        item_user_set_df = df_click_phase.groupby(\n",
        "            'item_id', as_index=False)['user_id'].agg({'item_user_set': set})\n",
        "        item_user_set_dict = dict(\n",
        "            zip(item_user_set_df['item_id'],\n",
        "                item_user_set_df['item_user_set']))\n",
        "\n",
        "        user_item_set_df = df_click_phase.groupby(\n",
        "            'user_id', as_index=False)['item_id'].agg({'user_item_set': set})\n",
        "        user_item_set_dict = dict(\n",
        "            zip(user_item_set_df['user_id'],\n",
        "                user_item_set_df['user_item_set']))\n",
        "\n",
        "        del rank_df, time_df, item_user_set_df, user_item_set_df\n",
        "        gc.collect()\n",
        "\n",
        "        item2item_sim_dict = item2item(user_item_set_dict, item_user_set_dict,\n",
        "                                       rank_dict, time_dict, txt_vec_dict,\n",
        "                                       img_vec_dict, sim_topN)\n",
        "\n",
        "        f = open('kdd2020_data/my_model/recall_5/sim_{}.pkl'.format(phase), 'wb')\n",
        "        pickle.dump(item2item_sim_dict, f)\n",
        "        f.close()\n",
        "\n",
        "        df_qtime_phase = df_qtime[df_qtime['phase'] == phase]\n",
        "        df_data = rec5(df_qtime_phase, item2item_sim_dict,\n",
        "                         user_item_set_dict, rank_dict, time_dict,\n",
        "                         txt_vec_dict, recall_topN)\n",
        "        df_data.to_pickle('kdd2020_data/my_model/recall_5/recall_{}.pkl'.format(phase))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoDbe9_q-5Fd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "1b1c0871-5ce6-46f0-dfd2-49fe42b4237e"
      },
      "source": [
        "sim_topN = 500\n",
        "recall_topN = 100\n",
        "item_sim_phase = {}\n",
        "df_recall = pd.DataFrame()\n",
        "val_score = np.array([0.0, 0.0, 0.0, 0.0])\n",
        "force = False\n",
        "for phase in phases:\n",
        "    work(phase, force)\n",
        "multitasking.wait_for_tasks()\n",
        "print('over')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [00:01<00:00, 237.71it/s]\n",
            "100%|██████████| 256/256 [00:01<00:00, 174.92it/s]\n",
            "100%|██████████| 256/256 [00:01<00:00, 199.60it/s]\n",
            "100%|██████████| 18505/18505 [15:01<00:00, 20.52it/s]\n",
            "100%|██████████| 40768/40768 [00:07<00:00, 5505.81it/s]\n",
            "100%|██████████| 18672/18672 [15:21<00:00, 20.26it/s]\n",
            "100%|██████████| 41400/41400 [00:08<00:00, 4820.72it/s]\n",
            "100%|██████████| 18398/18398 [15:43<00:00, 19.51it/s]\n",
            "100%|██████████| 41024/41024 [00:08<00:00, 4715.55it/s]\n",
            "100%|██████████| 18505/18505 [1:01:48<00:00,  4.99it/s]\n",
            "100%|██████████| 18672/18672 [1:03:07<00:00,  4.93it/s]\n",
            "100%|██████████| 18398/18398 [1:03:38<00:00,  4.82it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "over\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV8R_sYrAM12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(df, median_item_degree, item_degree_map, num_cases_full, num_cases_half):\n",
        "    gg = df.groupby(['user_id'])\n",
        "\n",
        "    ndcg_50_full = 0.0\n",
        "    hitrate_50_full = 0.0\n",
        "\n",
        "    ndcg_50_half = 0.0\n",
        "    hitrate_50_half = 0.0\n",
        "\n",
        "    for _, g in tqdm(gg):\n",
        "        try:\n",
        "            item_id = g[g['label'] == 1]['item_id'].values[0]\n",
        "            item_degree = item_degree_map[item_id]\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "        predictions = g['item_id'].values.tolist()\n",
        "\n",
        "        rank = 0\n",
        "        while rank < 50 and predictions[rank] != item_id:\n",
        "            rank += 1\n",
        "\n",
        "        if rank < 50:\n",
        "            ndcg_50_full += 1.0 / np.log2(rank + 2.0)\n",
        "            hitrate_50_full += 1.0\n",
        "\n",
        "        if item_degree <= median_item_degree:\n",
        "            if rank < 50:\n",
        "                ndcg_50_half += 1.0 / np.log2(rank + 2.0)\n",
        "                hitrate_50_half += 1.0\n",
        "\n",
        "    ndcg_50_full /= num_cases_full\n",
        "    hitrate_50_full /= num_cases_full\n",
        "\n",
        "    ndcg_50_half /= num_cases_half\n",
        "    hitrate_50_half /= num_cases_half\n",
        "\n",
        "    return ndcg_50_full, hitrate_50_full, ndcg_50_half, hitrate_50_half"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfWulREgARww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_scores(df, phase):\n",
        "    df_qtime = pd.read_pickle('kdd2020_data/recall/qtime.pkl')\n",
        "    df_click = pd.read_pickle('kdd2020_data/recall/click.pkl')\n",
        "    \n",
        "    df_qtime = df_qtime[df_qtime['phase']==phase]\n",
        "    df_click = df_click[df_click['phase']==phase]\n",
        "\n",
        "    oof_answer = df_qtime[df_qtime['item_id'] != -1]\n",
        "    num_cases_full = oof_answer.shape[0]\n",
        "\n",
        "    answer_items = oof_answer['item_id'].values\n",
        "    item_degree = df_click['item_id'].value_counts().reset_index()\n",
        "    item_degree.columns = ['item_id', 'degree']\n",
        "\n",
        "    answer_item_degree = item_degree[item_degree['item_id'].isin(answer_items)]\n",
        "    list_item_degress = answer_item_degree['degree'].values.tolist()\n",
        "    median_item_degree = list_item_degress[len(list_item_degress) // 2]\n",
        "    item_degree_map = dict(zip(item_degree['item_id'], item_degree['degree']))\n",
        "    num_cases_half = answer_item_degree[answer_item_degree['degree']\n",
        "                                        <= median_item_degree].shape[0]\n",
        "\n",
        "    ndcg_50_full, hitrate_50_full, ndcg_50_half, hitrate_50_half = evaluate(\n",
        "        df, median_item_degree, item_degree_map, num_cases_full, num_cases_half)\n",
        "    return ndcg_50_full, hitrate_50_full, ndcg_50_half, hitrate_50_half"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8phAq-_ADkl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "9f54b642-a9be-46c6-d110-0ce9ef195bde"
      },
      "source": [
        "for phase in phases:\n",
        "    f = open('kdd2020_data/my_model/recall_5/sim_{}.pkl'.format(phase), 'rb')\n",
        "    item_sim = pickle.load(f)\n",
        "    f.close()\n",
        "    df_data = pd.read_pickle('kdd2020_data/my_model/recall_5/recall_{}.pkl'.format(phase))\n",
        "    item_sim_phase[phase] = item_sim\n",
        "    df_recall = df_recall.append(df_data)\n",
        "    score = evaluate_scores(df_data, phase)\n",
        "    val_score += score\n",
        "    print('phase', phase, score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18505/18505 [00:19<00:00, 947.86it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "phase 0 (0.05837995479642042, 0.13341645885286782, 0.052475814576360795, 0.10920034393809114)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18672/18672 [00:19<00:00, 959.86it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "phase 1 (0.06114354105667278, 0.13619733270388293, 0.0529964213171576, 0.11056793673616104)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18398/18398 [00:19<00:00, 965.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "phase 2 (0.061077995778497894, 0.14047163035671534, 0.05125148364574258, 0.1113905325443787)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8s9yXkr_39M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ab915fd-e65f-4ff3-eb7b-c64febf39c71"
      },
      "source": [
        "f = open('kdd2020_data/my_model/sim5.pkl', 'wb')\n",
        "pickle.dump(item_sim_phase, f)\n",
        "f.close()\n",
        "val_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.18060149, 0.41008542, 0.15672372, 0.33115881])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY6wRZW1A6bR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9e2fb560-09f4-403a-bfbf-f408f993f731"
      },
      "source": [
        "df_recall.sort_values(['user_id', 'phase', 'query_time'], inplace=True)\n",
        "df_recall.to_pickle('kdd2020_data/my_model/recall_5.pkl')\n",
        "df_recall.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>phase</th>\n",
              "      <th>query_time</th>\n",
              "      <th>item_id</th>\n",
              "      <th>sim_score</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>103421</td>\n",
              "      <td>0.0050941158</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>91290</td>\n",
              "      <td>0.0045766652</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>35217</td>\n",
              "      <td>0.0045467833</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>95676</td>\n",
              "      <td>0.0040608463</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>109853</td>\n",
              "      <td>0.0040455135</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  phase    query_time  item_id     sim_score  label\n",
              "0        1    0.0  0.9839419315   103421  0.0050941158    0.0\n",
              "1        1    0.0  0.9839419315    91290  0.0045766652    0.0\n",
              "2        1    0.0  0.9839419315    35217  0.0045467833    0.0\n",
              "3        1    0.0  0.9839419315    95676  0.0040608463    0.0\n",
              "4        1    0.0  0.9839419315   109853  0.0040455135    0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhlNALL8Bb9W",
        "colab_type": "text"
      },
      "source": [
        "# Recall_6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9AjeGfkBlMq",
        "colab_type": "text"
      },
      "source": [
        "* use word2vec embedding item id \n",
        "* calculate sim by model.wv.most_similar\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7vhaakoBkDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import warnings\n",
        "from collections import defaultdict\n",
        "import math\n",
        "import pickle\n",
        "import multitasking\n",
        "import signal\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "multitasking.set_max_threads(10)\n",
        "multitasking.set_engine('process')\n",
        "signal.signal(signal.SIGINT, multitasking.killall)\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('precision', 10)\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "seed=2020"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzfgqw7yBROi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_qtime = pd.read_pickle('kdd2020_data/recall/qtime.pkl')\n",
        "df_click = pd.read_pickle('kdd2020_data/recall/click.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aklejmfmCdj0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d7b2916b-cd8b-4927-fce4-e5bf83a64077"
      },
      "source": [
        "phases = sorted(list(df_qtime['phase'].unique()))\n",
        "phases"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0EsC41LCf2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def item2vec(df_, f1, f2):\n",
        "    df = df_.copy()\n",
        "    tmp = df.groupby(f1, as_index=False)[f2].agg({'{}_{}_list'.format(f1, f2): list})\n",
        "    sentences = tmp['{}_{}_list'.format(f1, f2)].values.tolist()\n",
        "    del tmp['{}_{}_list'.format(f1, f2)]\n",
        "    for i in range(len(sentences)):\n",
        "        x = [str(x) for x in sentences[i]]\n",
        "        sentences[i] = x\n",
        "\n",
        "    model = Word2Vec(sentences, size=256, window=5, min_count=1,\n",
        "                         sg=1, hs=0, seed=seed, iter=300, negative=5, workers=6)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXntMOofCvfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rec6(df_qtime, model, user_item):\n",
        "    data_list = []\n",
        "\n",
        "    for user_id, query_time, item_id, phase in tqdm(df_qtime.values):\n",
        "        rank = {}\n",
        "        interacted_items = user_item[user_id]\n",
        "        sim_items = model.wv.most_similar(positive=[str(x) for x in interacted_items[-2:]], topn=100)\n",
        "        item_ids = [int(item[0]) for item in sim_items]\n",
        "        item_sim_scores = [item[1] for item in sim_items]\n",
        "\n",
        "        df_temp = pd.DataFrame()\n",
        "        df_temp['item_id'] = item_ids\n",
        "        df_temp['sim_score'] = item_sim_scores\n",
        "        df_temp['user_id'] = user_id\n",
        "        df_temp['query_time'] = query_time\n",
        "        df_temp['phase'] = phase\n",
        "\n",
        "        if item_id == -1:\n",
        "            df_temp['label'] = np.nan\n",
        "        else:\n",
        "            df_temp['label'] = 0\n",
        "            df_temp.loc[df_temp['item_id'] == item_id, 'label'] = 1\n",
        "\n",
        "        df_temp.sort_values(['sim_score'], inplace=True, ascending=False)\n",
        "        df_temp = df_temp[['user_id', 'phase', 'query_time',\n",
        "                           'item_id', 'sim_score', 'label']]\n",
        "        df_temp['user_id'] = df_temp['user_id'].astype('int')\n",
        "        df_temp['item_id'] = df_temp['item_id'].astype('int')\n",
        "\n",
        "        data_list.append(df_temp)\n",
        "\n",
        "    df_data = pd.concat(data_list, sort=False)\n",
        "    return df_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bgey60K8EMLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@multitasking.task\n",
        "def work(phase, force=False):\n",
        "    os.makedirs('kdd2020_data/my_model/recall_6', exist_ok=True)\n",
        "\n",
        "    if force or (not os.path.exists('kdd2020_data/my_model/recall_6/w2v_{}.m'.format(phase))):\n",
        " \n",
        "        df_click_phase = df_click[df_click['phase'] == phase]\n",
        "        model = item2vec(df_click_phase, 'user_id', 'item_id')\n",
        "        \n",
        "        model.save('kdd2020_data/my_model/recall_6/w2v_{}.m'.format(phase))\n",
        "\n",
        "        user_item_ = df_click_phase.groupby('user_id')['item_id'].agg(list).reset_index()\n",
        "        user_item_dict = dict(zip(user_item_['user_id'], user_item_['item_id']))\n",
        "\n",
        "        df_qtime_phase = df_qtime[df_qtime['phase'] == phase]\n",
        "        df_data = rec6(df_qtime_phase, model, user_item_dict)\n",
        "        df_data.to_pickle('kdd2020_data/my_model/recall_6/recall_{}.pkl'.format(phase))\n",
        "\n",
        "        print('phase {} finish'.format(phase))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyGXsM1pEjtS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "9e57c075-8fab-41ac-e2bf-2a41f0c5ed99"
      },
      "source": [
        "item_sim_phase = {}\n",
        "df_recall = pd.DataFrame()\n",
        "val_score = np.array([0.0, 0.0, 0.0, 0.0])\n",
        "force = False\n",
        "\n",
        "for phase in phases:\n",
        "    work(phase, force)\n",
        "    \n",
        "multitasking.wait_for_tasks()\n",
        "print('over')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18398/18398 [16:14<00:00, 18.89it/s]\n",
            "100%|██████████| 18672/18672 [16:29<00:00, 18.87it/s]\n",
            "100%|██████████| 18505/18505 [17:20<00:00, 17.79it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "phase 2 finish\n",
            "phase 1 finish\n",
            "phase 0 finish\n",
            "over\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdILrqRyFScC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(df, median_item_degree, item_degree_map, num_cases_full, num_cases_half):\n",
        "    gg = df.groupby(['user_id'])\n",
        "\n",
        "    ndcg_50_full = 0.0\n",
        "    hitrate_50_full = 0.0\n",
        "\n",
        "    ndcg_50_half = 0.0\n",
        "    hitrate_50_half = 0.0\n",
        "\n",
        "    for _, g in tqdm(gg):\n",
        "        try:\n",
        "            item_id = g[g['label'] == 1]['item_id'].values[0]\n",
        "            item_degree = item_degree_map[item_id]\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "        predictions = g['item_id'].values.tolist()\n",
        "\n",
        "        rank = 0\n",
        "        while rank < 50 and predictions[rank] != item_id:\n",
        "            rank += 1\n",
        "\n",
        "        if rank < 50:\n",
        "            ndcg_50_full += 1.0 / np.log2(rank + 2.0)\n",
        "            hitrate_50_full += 1.0\n",
        "\n",
        "        if item_degree <= median_item_degree:\n",
        "            if rank < 50:\n",
        "                ndcg_50_half += 1.0 / np.log2(rank + 2.0)\n",
        "                hitrate_50_half += 1.0\n",
        "\n",
        "    ndcg_50_full /= num_cases_full\n",
        "    hitrate_50_full /= num_cases_full\n",
        "\n",
        "    ndcg_50_half /= num_cases_half\n",
        "    hitrate_50_half /= num_cases_half\n",
        "\n",
        "    return ndcg_50_full, hitrate_50_full, ndcg_50_half, hitrate_50_half"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVzcDP47FZrx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_scores(df, phase):\n",
        "    df_qtime = pd.read_pickle('kdd2020_data/recall/qtime.pkl')\n",
        "    df_click = pd.read_pickle('kdd2020_data/recall/click.pkl')\n",
        "    \n",
        "    df_qtime = df_qtime[df_qtime['phase']==phase]\n",
        "    df_click = df_click[df_click['phase']==phase]\n",
        "\n",
        "    oof_answer = df_qtime[df_qtime['item_id'] != -1]\n",
        "    num_cases_full = oof_answer.shape[0]\n",
        "\n",
        "    answer_items = oof_answer['item_id'].values\n",
        "    item_degree = df_click['item_id'].value_counts().reset_index()\n",
        "    item_degree.columns = ['item_id', 'degree']\n",
        "\n",
        "    answer_item_degree = item_degree[item_degree['item_id'].isin(answer_items)]\n",
        "    list_item_degress = answer_item_degree['degree'].values.tolist()\n",
        "    median_item_degree = list_item_degress[len(list_item_degress) // 2]\n",
        "    item_degree_map = dict(zip(item_degree['item_id'], item_degree['degree']))\n",
        "    num_cases_half = answer_item_degree[answer_item_degree['degree']\n",
        "                                        <= median_item_degree].shape[0]\n",
        "\n",
        "    ndcg_50_full, hitrate_50_full, ndcg_50_half, hitrate_50_half = evaluate(\n",
        "        df, median_item_degree, item_degree_map, num_cases_full, num_cases_half)\n",
        "    return ndcg_50_full, hitrate_50_full, ndcg_50_half, hitrate_50_half"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de2k0DLoEy_z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "3dd82baa-8ca5-47fa-a460-bb030c078d57"
      },
      "source": [
        "for phase in phases:\n",
        "    df_data = pd.read_pickle('kdd2020_data/my_model/recall_6/recall_{}.pkl'.format(phase))\n",
        "    df_recall = df_recall.append(df_data)\n",
        "\n",
        "    score = evaluate_scores(df_data, phase)\n",
        "    val_score += score\n",
        "\n",
        "    print('phase', phase, score)\n",
        "val_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18505/18505 [00:17<00:00, 1037.25it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "phase 0 (0.03323028536511711, 0.09678185488659304, 0.042128717529749206, 0.117798796216681)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18672/18672 [00:18<00:00, 1015.91it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "phase 1 (0.0347391304179518, 0.09483063849876076, 0.04457930251176991, 0.11488138030194105)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18398/18398 [00:17<00:00, 1043.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "phase 2 (0.03469133843335808, 0.09360785252573617, 0.04551946155369641, 0.11597633136094675)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.10266075, 0.28522035, 0.13222748, 0.34865651])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrgkujOeFJEa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7f131457-0799-4a21-f64f-2299f90ebf1d"
      },
      "source": [
        "df_recall.sort_values(['user_id', 'phase', 'query_time'], inplace=True)\n",
        "df_recall.to_pickle('kdd2020_data/my_model/recall_6.pkl')\n",
        "df_recall.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>phase</th>\n",
              "      <th>query_time</th>\n",
              "      <th>item_id</th>\n",
              "      <th>sim_score</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>18522</td>\n",
              "      <td>0.7354431152</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>47611</td>\n",
              "      <td>0.6580811739</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>5509</td>\n",
              "      <td>0.5552558899</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>85492</td>\n",
              "      <td>0.5425689220</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>91290</td>\n",
              "      <td>0.5115175247</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  phase    query_time  item_id     sim_score  label\n",
              "0        1    0.0  0.9839419315    18522  0.7354431152    0.0\n",
              "1        1    0.0  0.9839419315    47611  0.6580811739    0.0\n",
              "2        1    0.0  0.9839419315     5509  0.5552558899    0.0\n",
              "3        1    0.0  0.9839419315    85492  0.5425689220    0.0\n",
              "4        1    0.0  0.9839419315    91290  0.5115175247    0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f5PGjkjJxjm",
        "colab_type": "text"
      },
      "source": [
        "# Recall_7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APXZGCZ7Ns_S",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Graph embedding**\n",
        "\n",
        "first, get users' behavior seq\n",
        "\n",
        "second, generated item graph structure\n",
        "\n",
        "third, random walk\n",
        "\n",
        "forth, generated item embedding by word2vec\n",
        "\n",
        "![替代文字](https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcTYz8t-cBFdznpB5xSBX279HBDnCXj2u4yX-w&usqp=CAU)\n",
        "\n",
        "**random walk**\n",
        "\n",
        "![替代文字](https://www.mit.edu/~kardar/teaching/projects/chemotaxis(AndreaSchmidt)/biased_2D.gif)\n",
        "\n",
        "[know more about random walk](https://www.mit.edu/~kardar/teaching/projects/chemotaxis(AndreaSchmidt)/random.htm)\n",
        "\n",
        "[know more about deep walk](http://www.perozzi.net/publications/14_kdd_deepwalk.pdf)\n",
        "\n",
        "\n",
        "**ps**\n",
        "\n",
        "if we consider of the weight of edge, we call it node2vec,\n",
        "otherwise we call it deepwalk.\n",
        "\n",
        "we do deepwalk in this stage and will do node2vec in next stage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8Hhz0UeXdwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/shenweichen/GraphEmbedding.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PPA_Y72J1Rt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import warnings\n",
        "from collections import defaultdict\n",
        "import math\n",
        "import pickle\n",
        "import multitasking\n",
        "import signal\n",
        "from gensim.models import Word2Vec\n",
        "import networkx as nx\n",
        "\n",
        "multitasking.set_max_threads(10)\n",
        "multitasking.set_engine('process')\n",
        "signal.signal(signal.SIGINT, multitasking.killall)\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('precision', 10)\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "seed=2020"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rekHpoPOeEUy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f5489a1-2dbb-4b86-d96e-44b575b60388"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "module_path = '/content/drive/My Drive/Colab Notebooks/kdd2020_data/'\n",
        "print(module_path)\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "from GraphEmbedding.ge.models import DeepWalk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/kdd2020_data/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN5gUAG6eOP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_qtime = pd.read_pickle('drive/My Drive/Colab Notebooks/kdd2020_data/recall/qtime.pkl')\n",
        "df_click = pd.read_pickle('drive/My Drive/Colab Notebooks/kdd2020_data/recall/click.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0j5JSCtUhNw3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8da239cf-f027-4f86-a80c-576a51132b9c"
      },
      "source": [
        "phases = sorted(list(df_qtime['phase'].unique()))\n",
        "phases"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjJDWwFU_EEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def deepwalk(df, user_col, item_col):\n",
        "\n",
        "    user_item_ = df.groupby(user_col)[item_col].agg(list).reset_index()\n",
        "    user_item_dict = dict(zip(user_item_[user_col], user_item_[item_col]))\n",
        "    \n",
        "    edgelist=[]\n",
        "\n",
        "    for user, items in user_item_dict.items():\n",
        "        for i in range(len(items) - 1):\n",
        "            edgelist.append([items[i], items[i + 1], 1])\n",
        "    \n",
        "    G = nx.Graph()\n",
        "    for edge in edgelist:\n",
        "        G.add_edge(str(edge[0]), str(edge[1]), weight=edge[2])\n",
        "\n",
        "    model = DeepWalk(G, walk_length=10, num_walks=5, workers=10)\n",
        "    deepwalk_model=model.train(window_size=4, iter=20)\n",
        "    return deepwalk_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IW5HauKwip87",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rec7(df_qtime, model, user_item):\n",
        "    data_list = []\n",
        "\n",
        "    for user_id, query_time, item_id, phase in tqdm(df_qtime.values):\n",
        "        rank = {}\n",
        "        interacted_items = user_item[user_id]\n",
        "        sim_items = model.wv.most_similar(positive=[str(x) for x in interacted_items[-2:]], topn=100)\n",
        "        item_ids = [int(item[0]) for item in sim_items]\n",
        "        item_sim_scores = [item[1] for item in sim_items]\n",
        "\n",
        "        df_temp = pd.DataFrame()\n",
        "        df_temp['item_id'] = item_ids\n",
        "        df_temp['sim_score'] = item_sim_scores\n",
        "        df_temp['user_id'] = user_id\n",
        "        df_temp['query_time'] = query_time\n",
        "        df_temp['phase'] = phase\n",
        "\n",
        "        if item_id == -1:\n",
        "            df_temp['label'] = np.nan\n",
        "        else:\n",
        "            df_temp['label'] = 0\n",
        "            df_temp.loc[df_temp['item_id'] == item_id, 'label'] = 1\n",
        "\n",
        "        df_temp.sort_values(['sim_score'], inplace=True, ascending=False)\n",
        "        df_temp = df_temp[['user_id', 'phase', 'query_time',\n",
        "                           'item_id', 'sim_score', 'label']]\n",
        "        df_temp['user_id'] = df_temp['user_id'].astype('int')\n",
        "        df_temp['item_id'] = df_temp['item_id'].astype('int')\n",
        "\n",
        "        data_list.append(df_temp)\n",
        "\n",
        "    df_data = pd.concat(data_list, sort=False)\n",
        "    return df_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "690ubJBli6kr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@multitasking.task\n",
        "def work(phase, force=False):\n",
        "    os.makedirs('drive/My Drive/Colab Notebooks/kdd2020_data/my_model/recall_7', exist_ok=True)\n",
        "\n",
        "    if force or (not os.path.exists('drive/My Drive/Colab Notebooks/kdd2020_data/my_model/recall_7/w2v_{}.m'.format(phase))):\n",
        " \n",
        "        df_click_phase = df_click[df_click['phase'] == phase]\n",
        "        model = deepwalk(df_click_phase, 'user_id', 'item_id')\n",
        "        \n",
        "        model.save('drive/My Drive/Colab Notebooks/kdd2020_data/my_model/recall_7/w2v_{}.m'.format(phase))\n",
        "\n",
        "        user_item_ = df_click_phase.groupby('user_id')['item_id'].agg(list).reset_index()\n",
        "        user_item_dict = dict(zip(user_item_['user_id'], user_item_['item_id']))\n",
        "\n",
        "        df_qtime_phase = df_qtime[df_qtime['phase'] == phase]\n",
        "        df_data = rec7(df_qtime_phase, model, user_item_dict)\n",
        "        df_data.to_pickle('drive/My Drive/Colab Notebooks/kdd2020_data/my_model/recall_7/recall_{}.pkl'.format(phase))\n",
        "\n",
        "        print('phase {} finish'.format(phase))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7n9V9UicjJUe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "07328a7b-0158-4515-b09c-ead9d43d60ae"
      },
      "source": [
        "item_sim_phase = {}\n",
        "df_recall = pd.DataFrame()\n",
        "val_score = np.array([0.0, 0.0, 0.0, 0.0])\n",
        "force = False\n",
        "\n",
        "for phase in phases:\n",
        "    work(phase, force)\n",
        "    \n",
        "multitasking.wait_for_tasks()\n",
        "print('over')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
            "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
            "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
            "[Parallel(n_jobs=10)]: Done   4 out of  11 | elapsed:   43.1s remaining:  1.3min\n",
            "[Parallel(n_jobs=10)]: Done   4 out of  11 | elapsed:   45.4s remaining:  1.3min\n",
            "[Parallel(n_jobs=10)]: Done   4 out of  11 | elapsed:   47.6s remaining:  1.4min\n",
            "[Parallel(n_jobs=10)]: Done  11 out of  11 | elapsed:  2.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Learning embedding vectors...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=10)]: Done  11 out of  11 | elapsed:  2.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Learning embedding vectors...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=10)]: Done  11 out of  11 | elapsed:  2.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Learning embedding vectors...\n",
            "Learning embedding vectors done!\n",
            "Learning embedding vectors done!\n",
            "Learning embedding vectors done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 18437/18505 [17:33<00:03, 21.78it/s]\n",
            "100%|██████████| 18505/18505 [17:35<00:00, 17.54it/s]\n",
            "100%|██████████| 18672/18672 [18:08<00:00, 17.15it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "phase 2 finish\n",
            "phase 0 finish\n",
            "phase 1 finish\n",
            "over\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14NhhM_1j44w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(df, median_item_degree, item_degree_map, num_cases_full, num_cases_half):\n",
        "    gg = df.groupby(['user_id'])\n",
        "\n",
        "    ndcg_50_full = 0.0\n",
        "    hitrate_50_full = 0.0\n",
        "\n",
        "    ndcg_50_half = 0.0\n",
        "    hitrate_50_half = 0.0\n",
        "\n",
        "    for _, g in tqdm(gg):\n",
        "        try:\n",
        "            item_id = g[g['label'] == 1]['item_id'].values[0]\n",
        "            item_degree = item_degree_map[item_id]\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "        predictions = g['item_id'].values.tolist()\n",
        "\n",
        "        rank = 0\n",
        "        while rank < 50 and predictions[rank] != item_id:\n",
        "            rank += 1\n",
        "\n",
        "        if rank < 50:\n",
        "            ndcg_50_full += 1.0 / np.log2(rank + 2.0)\n",
        "            hitrate_50_full += 1.0\n",
        "\n",
        "        if item_degree <= median_item_degree:\n",
        "            if rank < 50:\n",
        "                ndcg_50_half += 1.0 / np.log2(rank + 2.0)\n",
        "                hitrate_50_half += 1.0\n",
        "\n",
        "    ndcg_50_full /= num_cases_full\n",
        "    hitrate_50_full /= num_cases_full\n",
        "\n",
        "    ndcg_50_half /= num_cases_half\n",
        "    hitrate_50_half /= num_cases_half\n",
        "\n",
        "    return ndcg_50_full, hitrate_50_full, ndcg_50_half, hitrate_50_half"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhQnBXntkWnd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_scores(df, phase):\n",
        "    df_qtime = pd.read_pickle('drive/My Drive/Colab Notebooks/kdd2020_data/recall/qtime.pkl')\n",
        "    df_click = pd.read_pickle('drive/My Drive/Colab Notebooks/kdd2020_data/recall/click.pkl')\n",
        "    \n",
        "    df_qtime = df_qtime[df_qtime['phase']==phase]\n",
        "    df_click = df_click[df_click['phase']==phase]\n",
        "\n",
        "    oof_answer = df_qtime[df_qtime['item_id'] != -1]\n",
        "    num_cases_full = oof_answer.shape[0]\n",
        "\n",
        "    answer_items = oof_answer['item_id'].values\n",
        "    item_degree = df_click['item_id'].value_counts().reset_index()\n",
        "    item_degree.columns = ['item_id', 'degree']\n",
        "\n",
        "    answer_item_degree = item_degree[item_degree['item_id'].isin(answer_items)]\n",
        "    list_item_degress = answer_item_degree['degree'].values.tolist()\n",
        "    median_item_degree = list_item_degress[len(list_item_degress) // 2]\n",
        "    item_degree_map = dict(zip(item_degree['item_id'], item_degree['degree']))\n",
        "    num_cases_half = answer_item_degree[answer_item_degree['degree']\n",
        "                                        <= median_item_degree].shape[0]\n",
        "\n",
        "    ndcg_50_full, hitrate_50_full, ndcg_50_half, hitrate_50_half = evaluate(\n",
        "        df, median_item_degree, item_degree_map, num_cases_full, num_cases_half)\n",
        "    return ndcg_50_full, hitrate_50_full, ndcg_50_half, hitrate_50_half"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tho2R5RNkdFk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "c4f5666f-18ef-4169-8a4a-0da1bbd370fe"
      },
      "source": [
        "for phase in phases:\n",
        "    df_data = pd.read_pickle('drive/My Drive/Colab Notebooks/kdd2020_data/my_model/recall_7/recall_{}.pkl'.format(phase))\n",
        "    df_recall = df_recall.append(df_data)\n",
        "\n",
        "    score = evaluate_scores(df_data, phase)\n",
        "    val_score += score\n",
        "\n",
        "    print('phase', phase, score)\n",
        "val_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18505/18505 [00:18<00:00, 1013.20it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "phase 0 (0.03666895348362071, 0.09986937418358864, 0.030675673064774908, 0.07351676698194325)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18672/18672 [00:18<00:00, 1014.63it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "phase 1 (0.03821268365999283, 0.10167591171957985, 0.030600356583550255, 0.07117181883537024)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18398/18398 [00:18<00:00, 1012.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "phase 2 (0.03657832982296708, 0.09857553267895619, 0.029896798800727275, 0.07248520710059171)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.11145997, 0.30012082, 0.09117283, 0.21717379])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owZ9AMg0k2Uw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "609fa2f8-613e-4db1-d837-58c38479b1b1"
      },
      "source": [
        "df_recall.sort_values(['user_id', 'phase', 'query_time'], inplace=True)\n",
        "df_recall.to_pickle('drive/My Drive/Colab Notebooks/kdd2020_data/my_model/recall_7.pkl')\n",
        "df_recall.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>phase</th>\n",
              "      <th>query_time</th>\n",
              "      <th>item_id</th>\n",
              "      <th>sim_score</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>103015</td>\n",
              "      <td>0.6282564998</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>5509</td>\n",
              "      <td>0.6168600321</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>42845</td>\n",
              "      <td>0.6069713235</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>95676</td>\n",
              "      <td>0.5800161362</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>103421</td>\n",
              "      <td>0.5346841812</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  phase    query_time  item_id     sim_score  label\n",
              "0        1    0.0  0.9839419315   103015  0.6282564998    0.0\n",
              "1        1    0.0  0.9839419315     5509  0.6168600321    0.0\n",
              "2        1    0.0  0.9839419315    42845  0.6069713235    0.0\n",
              "3        1    0.0  0.9839419315    95676  0.5800161362    0.0\n",
              "4        1    0.0  0.9839419315   103421  0.5346841812    0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csVjzqXdcXkC",
        "colab_type": "text"
      },
      "source": [
        "# Recall_8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtJFJXEYtDC6",
        "colab_type": "text"
      },
      "source": [
        "[know more about node2vec](https://www.kdd.org/kdd2016/papers/files/rfp0218-groverA.pdf)\n",
        "\n",
        "in node2vec, we import p and q two parameters.\n",
        "\n",
        "p: the probability of go back\n",
        "\n",
        "q: the probability of go front\n",
        "\n",
        "p is bigger than q means we prefect deepth-first searches\n",
        "\n",
        "q is bigger than p means we prefect breadth-first searches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBizNaL4dR0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install node2vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k6P3mD6vI7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import warnings\n",
        "from collections import defaultdict\n",
        "import math\n",
        "import pickle\n",
        "import multitasking\n",
        "import signal\n",
        "from gensim.models import Word2Vec\n",
        "import networkx as nx\n",
        "from node2vec import Node2Vec\n",
        "multitasking.set_max_threads(10)\n",
        "multitasking.set_engine('process')\n",
        "signal.signal(signal.SIGINT, multitasking.killall)\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('precision', 10)\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "seed=2020"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3bfrXCbyqHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_qtime = pd.read_pickle('kdd2020_data/recall/qtime.pkl')\n",
        "df_click = pd.read_pickle('kdd2020_data/recall/click.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TcsXRV-yq7H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c16fd0c-64e8-4a8c-a871-6b40ef5d2cb2"
      },
      "source": [
        "phases = sorted(list(df_qtime['phase'].unique()))\n",
        "phases"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sZMX8RNvVtx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def n2v(df, user_col, item_col):\n",
        "    user_item_ = df.groupby(user_col)[item_col].agg(list).reset_index()\n",
        "    user_item_dict = dict(zip(user_item_[user_col], user_item_[item_col]))\n",
        "    edgelist = []\n",
        "    user_time_ = df.groupby(user_col)['time'].agg(list).reset_index() \n",
        "    user_time_dict = dict(zip(user_time_[user_col], user_time_['time']))\n",
        "\n",
        "    item_cnt=df[item_col].value_counts().to_dict()\n",
        "\n",
        "    for user, items in user_item_dict.items():\n",
        "        for i in range(len(items) - 1):\n",
        "            t1 = user_time_dict[user][i] \n",
        "            t2 = user_time_dict[user][i+1]\n",
        "            delta_t=abs(t1-t2)*50000   \n",
        "            ai, aj = item_cnt[items[i]], item_cnt[items[i+1]]\n",
        "            edgelist.append([items[i], items[i + 1], max(3, np.log(1+ai/aj)) * 1/(1+delta_t)])\n",
        "            edgelist.append([items[i+1], items[i], max(3, np.log(1+aj/ai)) * 0.8 * 1/(1+delta_t)])\n",
        "            \n",
        "    G = nx.Graph()\n",
        "    for edge in edgelist:\n",
        "        G.add_edge(str(edge[0]), str(edge[1]), weight=edge[2])\n",
        "    for u,v,d in G.edges(data=True):\n",
        "        deg = G.degree(u)/G.degree(v)\n",
        "        if deg < 1:\n",
        "            deg = max(0.1, deg)\n",
        "        else:\n",
        "            deg = min(3, deg)\n",
        "            new_weight = d[\"weight\"] * deg\n",
        "            G[u][v].update({\"weight\":new_weight})\n",
        "    \n",
        "    model = Node2Vec(G, walk_length=10, num_walks=5, workers=10, p=2, q=0.5)\n",
        "    node2vec_model=model.fit(window=4, iter=20)\n",
        "    return node2vec_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWnXRzI2xgfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rec8(df_qtime, model, user_item):\n",
        "    data_list = []\n",
        "\n",
        "    for user_id, query_time, item_id, phase in tqdm(df_qtime.values):\n",
        "        rank = {}\n",
        "        interacted_items = user_item[user_id]\n",
        "        sim_items = model.wv.most_similar(positive=[str(x) for x in interacted_items[-2:]], topn=100)\n",
        "        item_ids = [int(item[0]) for item in sim_items]\n",
        "        item_sim_scores = [item[1] for item in sim_items]\n",
        "\n",
        "        df_temp = pd.DataFrame()\n",
        "        df_temp['item_id'] = item_ids\n",
        "        df_temp['sim_score'] = item_sim_scores\n",
        "        df_temp['user_id'] = user_id\n",
        "        df_temp['query_time'] = query_time\n",
        "        df_temp['phase'] = phase\n",
        "\n",
        "        if item_id == -1:\n",
        "            df_temp['label'] = np.nan\n",
        "        else:\n",
        "            df_temp['label'] = 0\n",
        "            df_temp.loc[df_temp['item_id'] == item_id, 'label'] = 1\n",
        "\n",
        "        df_temp.sort_values(['sim_score'], inplace=True, ascending=False)\n",
        "        df_temp = df_temp[['user_id', 'phase', 'query_time',\n",
        "                           'item_id', 'sim_score', 'label']]\n",
        "        df_temp['user_id'] = df_temp['user_id'].astype('int')\n",
        "        df_temp['item_id'] = df_temp['item_id'].astype('int')\n",
        "\n",
        "        data_list.append(df_temp)\n",
        "\n",
        "    df_data = pd.concat(data_list, sort=False)\n",
        "    return df_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT-E6ngFxq5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@multitasking.task\n",
        "def work(phase, force=False):\n",
        "    os.makedirs('kdd2020_data/my_model/recall_8', exist_ok=True)\n",
        "\n",
        "    if force or (not os.path.exists('kdd2020_data/my_model/recall_8/w2v_{}.m'.format(phase))):\n",
        " \n",
        "        df_click_phase = df_click[df_click['phase'] == phase]\n",
        "        model = n2v(df_click_phase, 'user_id', 'item_id')\n",
        "        \n",
        "        model.save('kdd2020_data/my_model/recall_8/w2v_{}.m'.format(phase))\n",
        "\n",
        "        user_item_ = df_click_phase.groupby('user_id')['item_id'].agg(list).reset_index()\n",
        "        user_item_dict = dict(zip(user_item_['user_id'], user_item_['item_id']))\n",
        "\n",
        "        df_qtime_phase = df_qtime[df_qtime['phase'] == phase]\n",
        "        df_data = rec8(df_qtime_phase, model, user_item_dict)\n",
        "        df_data.to_pickle('kdd2020_data/my_model/recall_8/recall_{}.pkl'.format(phase))\n",
        "\n",
        "        print('phase {} finish'.format(phase))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSfogu1Gx71Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "a10bbad1-2c63-477e-e746-8e2f6b4717f4"
      },
      "source": [
        "item_sim_phase = {}\n",
        "df_recall = pd.DataFrame()\n",
        "val_score = np.array([0.0, 0.0, 0.0, 0.0])\n",
        "force = False\n",
        "\n",
        "for phase in phases:\n",
        "    work(phase, force)\n",
        "    \n",
        "multitasking.wait_for_tasks()\n",
        "print('over')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computing transition probabilities: 100%|██████████| 41400/41400 [00:57<00:00, 718.11it/s] \n",
            "Computing transition probabilities: 100%|██████████| 40768/40768 [00:57<00:00, 709.11it/s] \n",
            "Computing transition probabilities: 100%|██████████| 41024/41024 [01:03<00:00, 647.10it/s]\n",
            "100%|██████████| 18672/18672 [16:56<00:00, 18.36it/s]\n",
            "100%|██████████| 18398/18398 [16:49<00:00, 18.23it/s]\n",
            "100%|██████████| 18505/18505 [16:55<00:00, 18.21it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "phase 2 finish\n",
            "phase 1 finish\n",
            "phase 0 finish\n",
            "over\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo6jbiLIyDVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(df, median_item_degree, item_degree_map, num_cases_full, num_cases_half):\n",
        "    gg = df.groupby(['user_id'])\n",
        "\n",
        "    ndcg_50_full = 0.0\n",
        "    hitrate_50_full = 0.0\n",
        "\n",
        "    ndcg_50_half = 0.0\n",
        "    hitrate_50_half = 0.0\n",
        "\n",
        "    for _, g in tqdm(gg):\n",
        "        try:\n",
        "            item_id = g[g['label'] == 1]['item_id'].values[0]\n",
        "            item_degree = item_degree_map[item_id]\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "        predictions = g['item_id'].values.tolist()\n",
        "\n",
        "        rank = 0\n",
        "        while rank < 50 and predictions[rank] != item_id:\n",
        "            rank += 1\n",
        "\n",
        "        if rank < 50:\n",
        "            ndcg_50_full += 1.0 / np.log2(rank + 2.0)\n",
        "            hitrate_50_full += 1.0\n",
        "\n",
        "        if item_degree <= median_item_degree:\n",
        "            if rank < 50:\n",
        "                ndcg_50_half += 1.0 / np.log2(rank + 2.0)\n",
        "                hitrate_50_half += 1.0\n",
        "\n",
        "    ndcg_50_full /= num_cases_full\n",
        "    hitrate_50_full /= num_cases_full\n",
        "\n",
        "    ndcg_50_half /= num_cases_half\n",
        "    hitrate_50_half /= num_cases_half\n",
        "\n",
        "    return ndcg_50_full, hitrate_50_full, ndcg_50_half, hitrate_50_half"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkhGetrbyMEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_scores(df, phase):\n",
        "    df_qtime = pd.read_pickle('kdd2020_data/recall/qtime.pkl')\n",
        "    df_click = pd.read_pickle('kdd2020_data/recall/click.pkl')\n",
        "    \n",
        "    df_qtime = df_qtime[df_qtime['phase']==phase]\n",
        "    df_click = df_click[df_click['phase']==phase]\n",
        "\n",
        "    oof_answer = df_qtime[df_qtime['item_id'] != -1]\n",
        "    num_cases_full = oof_answer.shape[0]\n",
        "\n",
        "    answer_items = oof_answer['item_id'].values\n",
        "    item_degree = df_click['item_id'].value_counts().reset_index()\n",
        "    item_degree.columns = ['item_id', 'degree']\n",
        "\n",
        "    answer_item_degree = item_degree[item_degree['item_id'].isin(answer_items)]\n",
        "    list_item_degress = answer_item_degree['degree'].values.tolist()\n",
        "    median_item_degree = list_item_degress[len(list_item_degress) // 2]\n",
        "    item_degree_map = dict(zip(item_degree['item_id'], item_degree['degree']))\n",
        "    num_cases_half = answer_item_degree[answer_item_degree['degree']\n",
        "                                        <= median_item_degree].shape[0]\n",
        "\n",
        "    ndcg_50_full, hitrate_50_full, ndcg_50_half, hitrate_50_half = evaluate(\n",
        "        df, median_item_degree, item_degree_map, num_cases_full, num_cases_half)\n",
        "    return ndcg_50_full, hitrate_50_full, ndcg_50_half, hitrate_50_half"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGbrMRfuyP7S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "e45bd3b3-94cf-4952-98fd-62ae0ee73918"
      },
      "source": [
        "for phase in phases:\n",
        "    df_data = pd.read_pickle('kdd2020_data/my_model/recall_8/recall_{}.pkl'.format(phase))\n",
        "    df_recall = df_recall.append(df_data)\n",
        "\n",
        "    score = evaluate_scores(df_data, phase)\n",
        "    val_score += score\n",
        "\n",
        "    print('phase', phase, score)\n",
        "val_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18505/18505 [00:18<00:00, 1005.76it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "phase 0 (0.02704913215190689, 0.07659422871392946, 0.02919069589602102, 0.07194038406420178)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18672/18672 [00:18<00:00, 1004.20it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "phase 1 (0.028960658826503262, 0.0762421810456745, 0.03273351602313089, 0.07591660675772825)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18398/18398 [00:18<00:00, 1011.49it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "phase 2 (0.026348841109454287, 0.07367728034474504, 0.0301069659338838, 0.07337278106508875)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.08235863, 0.22651369, 0.09203118, 0.22122977])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u87alwNAyWW_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f57455b2-1022-456e-fc19-2d16c4a34c9f"
      },
      "source": [
        "df_recall.sort_values(['user_id', 'phase', 'query_time'], inplace=True)\n",
        "df_recall.to_pickle('kdd2020_data/my_model/recall_8.pkl')\n",
        "df_recall.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>phase</th>\n",
              "      <th>query_time</th>\n",
              "      <th>item_id</th>\n",
              "      <th>sim_score</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>87837</td>\n",
              "      <td>0.7194173336</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>89478</td>\n",
              "      <td>0.7190618515</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>5007</td>\n",
              "      <td>0.6620476246</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>47611</td>\n",
              "      <td>0.6592251062</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>68074</td>\n",
              "      <td>0.6245218515</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  phase    query_time  item_id     sim_score  label\n",
              "0        1    0.0  0.9839419315    87837  0.7194173336    0.0\n",
              "1        1    0.0  0.9839419315    89478  0.7190618515    0.0\n",
              "2        1    0.0  0.9839419315     5007  0.6620476246    0.0\n",
              "3        1    0.0  0.9839419315    47611  0.6592251062    0.0\n",
              "4        1    0.0  0.9839419315    68074  0.6245218515    0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNDL6qkYcjb_",
        "colab_type": "text"
      },
      "source": [
        "# Recall_9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blick2dRhJj9",
        "colab_type": "text"
      },
      "source": [
        "**GCN**\n",
        "\n",
        "![替代文字](data:image/png;base64,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)\n",
        "\n",
        "first, get users' behavior seq\n",
        "\n",
        "second, generated item graph structure and get the adjacency matrix (A)\n",
        "\n",
        "third, get the degree matrix (D)\n",
        "\n",
        "forth, generated Laplacian matrix\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "[know more about GCN](https://arxiv.org/pdf/1609.02907.pdf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncS6HeinrTFn",
        "colab_type": "text"
      },
      "source": [
        "three ways to generated Laplacian matrix:\n",
        "* combinatorial Laplacian\n",
        "\n",
        "$L=D-A$\n",
        "\n",
        "* symmetric normalized Laplacian\n",
        "\n",
        "$L=D^{-0.5}*A*D^{-0.5}$\n",
        "\n",
        "* randomwalk normalized Laplacian\n",
        "\n",
        "$L=D^{-1}*A$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHQdslxClRpY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install annoy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD-XcTTjafnh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import warnings\n",
        "from collections import defaultdict\n",
        "import math\n",
        "import pickle\n",
        "import multitasking\n",
        "import signal\n",
        "from gensim.models import Word2Vec\n",
        "import networkx as nx\n",
        "from annoy import AnnoyIndex\n",
        "\n",
        "multitasking.set_max_threads(10)\n",
        "multitasking.set_engine('process')\n",
        "signal.signal(signal.SIGINT, multitasking.killall)\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('precision', 10)\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "seed=2020"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZuJCgvbajKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_qtime = pd.read_pickle('kdd2020_data/recall/qtime.pkl')\n",
        "df_click = pd.read_pickle('kdd2020_data/recall/click.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k60GlDIlaozy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc098ea2-c135-4095-9ff6-100446cc3659"
      },
      "source": [
        "phases = sorted(list(df_qtime['phase'].unique()))\n",
        "phases"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBvVOgvka4R_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from networkx import to_numpy_matrix\n",
        "def gcn_layer(G):\n",
        "  order = sorted(list(G.nodes()))\n",
        "  #get A\n",
        "  A = to_numpy_matrix(G, nodelist=order)\n",
        "  #get A_hat\n",
        "  I = np.eye(G.number_of_nodes())\n",
        "  A_hat = A + I\n",
        "  #get D_hat\n",
        "  D_hat = np.array(np.sum(A_hat, axis=0))[0]\n",
        "  D_hat = np.matrix(np.diag(D_hat))\n",
        "  \n",
        "  W_1 = np.random.normal(loc=0, scale=1, size=(G.number_of_nodes(), 64))\n",
        "  W_2 = np.random.normal(loc=0, size=(W_1.shape[1], 32))\n",
        "\n",
        "  def relu(x):\n",
        "    return(abs(x)+x)/2\n",
        "\n",
        "  def gcn_layer(A_hat, D_hat, X, W):\n",
        "\t  return relu(D_hat**-1 * A_hat * X * W)\n",
        "   \n",
        "  H_1 = gcn_layer(A_hat, D_hat, I, W_1)\n",
        "  H_2 = gcn_layer(A_hat, D_hat, H_1, W_2)\n",
        "  output = H_2\n",
        "  feature_representations = {}\n",
        "  nodes = list(G.nodes())\n",
        "  for i in range(len(nodes)):\n",
        "    feature_representations[nodes[i]] = np.array(output)[i]\n",
        "  return feature_representations\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMfV9FmZi1UW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gcn(df, user_col, item_col):\n",
        "    user_item_ = df.groupby(user_col)[item_col].agg(list).reset_index()\n",
        "    user_item_dict = dict(zip(user_item_[user_col], user_item_[item_col]))\n",
        "    edgelist = []\n",
        "    user_time_ = df.groupby(user_col)['time'].agg(list).reset_index() \n",
        "    user_time_dict = dict(zip(user_time_[user_col], user_time_['time']))\n",
        "\n",
        "    item_cnt=df[item_col].value_counts().to_dict()\n",
        "\n",
        "    for user, items in user_item_dict.items():\n",
        "        for i in range(len(items) - 1):\n",
        "            t1 = user_time_dict[user][i] \n",
        "            t2 = user_time_dict[user][i+1]\n",
        "            delta_t=abs(t1-t2)*50000   \n",
        "            ai, aj = item_cnt[items[i]], item_cnt[items[i+1]]\n",
        "            edgelist.append([items[i], items[i + 1], max(3, np.log(1+ai/aj)) * 1/(1+delta_t)])\n",
        "            edgelist.append([items[i+1], items[i], max(3, np.log(1+aj/ai)) * 0.8 * 1/(1+delta_t)])\n",
        "            \n",
        "    G = nx.Graph()\n",
        "    for edge in edgelist:\n",
        "        G.add_edge(str(edge[0]), str(edge[1]), weight=edge[2])\n",
        "    for u,v,d in G.edges(data=True):\n",
        "        deg = G.degree(u)/G.degree(v)\n",
        "        if deg < 1:\n",
        "            deg = max(0.1, deg)\n",
        "        else:\n",
        "            deg = min(3, deg)\n",
        "            new_weight = d[\"weight\"] * deg\n",
        "            G[u][v].update({\"weight\":new_weight})\n",
        "    \n",
        "    feature_representations= gcn_layer(G)\n",
        "    return feature_representations\n",
        "feature_representations=gcn(df_click, 'user_id', 'item_id')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2Jldt6Yie7c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setup index for feature_representations\n",
        "index_to_item_dict = {}\n",
        "item_to_index_dict = {}\n",
        "\n",
        "item_index = AnnoyIndex(128, 'angular')\n",
        "item_index.set_seed(2020)\n",
        "\n",
        "for i, key in enumerate(feature_representations.keys()):\n",
        "    emb = feature_representations[key]\n",
        "\n",
        "    index_to_item_dict[i] = key\n",
        "    item_to_index_dict[key] = i\n",
        "\n",
        "    item_index.add_item(i, emb)\n",
        "\n",
        "item_index.build(100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJuwbyMNg3ru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rec9(df_qtime, user_embs, item_index, index_to_item_dict):\n",
        "    data_list = []\n",
        "    for user_id, query_time, item_id, phase in tqdm(df_qtime.values):\n",
        "        user_emb = user_embs[user_id]\n",
        "        ids, distances = item_index.get_nns_by_vector(user_emb,100,include_distances=True)\n",
        "        item_ids = [index_to_item_dict[id] for id in ids]\n",
        "        # the smaller distance, the higher score\n",
        "        item_sim_scores = [2 - distance for distance in distances]\n",
        "\n",
        "        df_temp = pd.DataFrame()\n",
        "        df_temp['item_id'] = item_ids\n",
        "        df_temp['sim_score'] = item_sim_scores\n",
        "        df_temp['user_id'] = user_id\n",
        "        df_temp['query_time'] = query_time\n",
        "        df_temp['phase'] = phase\n",
        "\n",
        "        if item_id == -1:\n",
        "            df_temp['label'] = np.nan\n",
        "        else:\n",
        "            df_temp['label'] = 0\n",
        "            df_temp.loc[df_temp['item_id'] == item_id, 'label'] = 1\n",
        "\n",
        "        df_temp.sort_values(['sim_score'], inplace=True, ascending=False)\n",
        "\n",
        "        df_temp = df_temp[['user_id', 'phase', 'query_time', 'item_id', 'sim_score', 'label']]\n",
        "        df_temp['user_id'] = df_temp['user_id'].astype('int')\n",
        "        df_temp['item_id'] = df_temp['item_id'].astype('int')\n",
        "\n",
        "        data_list.append(df_temp)\n",
        "\n",
        "    df_data = pd.concat(data_list, sort=False)\n",
        "    return df_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwLh6FaghDQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@multitasking.task\n",
        "def work(phase, force=False):\n",
        "    os.makedirs('kdd2020_data/my_model/recall_9', exist_ok=True)\n",
        "\n",
        "    if force or (not os.path.exists('kdd2020_data/my_model/recall_9/user_item_vec_{}.pkl'.format(phase))\n",
        "                 or not os.path.exists('kdd2020_data/my_model/recall_9/recall_{}.pkl'.format(phase))):\n",
        "      \n",
        "        df_click_phase = df_click[df_click['phase'] == phase]\n",
        "\n",
        "        tmp = df_click_phase.groupby('user_id', as_index=False)['item_id'].agg({'list': list})\n",
        "        sentences = tmp['list'].values.tolist()\n",
        "        del tmp['list']\n",
        "\n",
        "        emb_matrix = []\n",
        "        for seq in sentences:\n",
        "            seq = seq[::-1]\n",
        "\n",
        "            vec = []\n",
        "            for pos, w in enumerate(seq):\n",
        "                if w in item_vec_map.keys():\n",
        "                    vec.append(np.asarray(item_vec_map[w]) * (0.7**pos))\n",
        "            if len(vec) > 0:\n",
        "            #we get the seq vec by average all the item's vec in the seq\n",
        "                emb_matrix.append(np.mean(vec, axis=0))\n",
        "            else:\n",
        "                emb_matrix.append([0] * 128)\n",
        "\n",
        "        df_user_txt_vec = tmp\n",
        "        df_user_txt_vec['user_txt_vec'] = emb_matrix\n",
        "        df_user_txt_vec['phase'] = phase\n",
        "        df_user_txt_vec.to_pickle('kdd2020_data/my_model/recall_9/user_item_vec_{}.pkl'.format(phase))\n",
        "\n",
        "        users = tmp['user_id'].values.tolist()\n",
        "        user_embs = dict(zip(users, emb_matrix))\n",
        "\n",
        "        df_qtime_phase = df_qtime[df_qtime['phase'] == phase]\n",
        "        df_data = rec3(df_qtime_phase, user_embs, item_index,index_to_item_dict)\n",
        "        df_data.to_pickle('kdd2020_data/my_model/recall_9/recall_{}.pkl'.format(phase))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWV3neebhKf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "item_sim_phase = {}\n",
        "df_recall = pd.DataFrame()\n",
        "val_score = np.array([0.0, 0.0, 0.0, 0.0])\n",
        "force = False\n",
        "\n",
        "for phase in phases:\n",
        "    work(phase, force)\n",
        "    \n",
        "multitasking.wait_for_tasks()\n",
        "print('over')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL84G-ZMdl3N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(df, median_item_degree, item_degree_map, num_cases_full, num_cases_half):\n",
        "    gg = df.groupby(['user_id'])\n",
        "\n",
        "    ndcg_50_full = 0.0\n",
        "    hitrate_50_full = 0.0\n",
        "\n",
        "    ndcg_50_half = 0.0\n",
        "    hitrate_50_half = 0.0\n",
        "\n",
        "    for _, g in tqdm(gg):\n",
        "        try:\n",
        "            item_id = g[g['label'] == 1]['item_id'].values[0]\n",
        "            item_degree = item_degree_map[item_id]\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "        predictions = g['item_id'].values.tolist()\n",
        "\n",
        "        rank = 0\n",
        "        while rank < 50 and predictions[rank] != item_id:\n",
        "            rank += 1\n",
        "\n",
        "        if rank < 50:\n",
        "            ndcg_50_full += 1.0 / np.log2(rank + 2.0)\n",
        "            hitrate_50_full += 1.0\n",
        "\n",
        "        if item_degree <= median_item_degree:\n",
        "            if rank < 50:\n",
        "                ndcg_50_half += 1.0 / np.log2(rank + 2.0)\n",
        "                hitrate_50_half += 1.0\n",
        "\n",
        "    ndcg_50_full /= num_cases_full\n",
        "    hitrate_50_full /= num_cases_full\n",
        "\n",
        "    ndcg_50_half /= num_cases_half\n",
        "    hitrate_50_half /= num_cases_half\n",
        "\n",
        "    return ndcg_50_full, hitrate_50_full, ndcg_50_half, hitrate_50_half"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2UJwKv8uwel",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_scores(df, phase):\n",
        "    df_qtime = pd.read_pickle('kdd2020_data/recall/qtime.pkl')\n",
        "    df_click = pd.read_pickle('kdd2020_data/recall/click.pkl')\n",
        "    \n",
        "    df_qtime = df_qtime[df_qtime['phase']==phase]\n",
        "    df_click = df_click[df_click['phase']==phase]\n",
        "\n",
        "    oof_answer = df_qtime[df_qtime['item_id'] != -1]\n",
        "    num_cases_full = oof_answer.shape[0]\n",
        "\n",
        "    answer_items = oof_answer['item_id'].values\n",
        "    item_degree = df_click['item_id'].value_counts().reset_index()\n",
        "    item_degree.columns = ['item_id', 'degree']\n",
        "\n",
        "    answer_item_degree = item_degree[item_degree['item_id'].isin(answer_items)]\n",
        "    list_item_degress = answer_item_degree['degree'].values.tolist()\n",
        "    median_item_degree = list_item_degress[len(list_item_degress) // 2]\n",
        "    item_degree_map = dict(zip(item_degree['item_id'], item_degree['degree']))\n",
        "    num_cases_half = answer_item_degree[answer_item_degree['degree']\n",
        "                                        <= median_item_degree].shape[0]\n",
        "\n",
        "    ndcg_50_full, hitrate_50_full, ndcg_50_half, hitrate_50_half = evaluate(\n",
        "        df, median_item_degree, item_degree_map, num_cases_full, num_cases_half)\n",
        "    return ndcg_50_full, hitrate_50_full, ndcg_50_half, hitrate_50_half"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpdWD61-u10F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for phase in phases:\n",
        "    df_data = pd.read_pickle('kdd2020_data/my_model/recall_9/recall_{}.pkl'.format(phase))\n",
        "    df_recall = df_recall.append(df_data)\n",
        "\n",
        "    score = evaluate_scores(df_data, phase)\n",
        "    val_score += score\n",
        "\n",
        "    print('phase', phase, score)\n",
        "val_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBPFqv1Su_UL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_recall.sort_values(['user_id', 'phase', 'query_time'], inplace=True)\n",
        "df_recall.to_pickle('kdd2020_data/my_model/recall_9.pkl')\n",
        "df_recall.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylfPX5KvcpkF",
        "colab_type": "text"
      },
      "source": [
        "# Recall_10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGcRvAVsxkol",
        "colab_type": "text"
      },
      "source": [
        "**The Common Neighbors algorithm**\n",
        "\n",
        "![替代文字](data:image/png;base64,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)\n",
        "\n",
        "we don't calculate the sim of white circles directly, we caculate the sim of while and black circles instead."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp_3rQFdzqK1",
        "colab_type": "text"
      },
      "source": [
        "[know about common neighbors algorithm](https://www.nature.com/articles/srep12261)\n",
        "\n",
        "Adamic-Adar (AA)\n",
        "\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAegAAAB+CAYAAADvGILmAAAgAElEQVR4Ae3dd7BtSVUGcKr0L0uCCUosxCpTDWlgGAYYBgSGKA4DQxzCOERRMSEimBMiioIoQUGygjkh5oBZjJgx55xz3tZvw/dY02+f8244995z7ltdtU/37t1xdff61lrde5/rTe2aAk2BpkBToCnQFNg6Clxv61rUDWoKNAWaAk2BpkBTYGqA7knQFGgKNAWaAk2BLaRAA/QWDko3qSnQFGgKNAWaAg3QPQeaAk2BpkBToCmwhRRogN7CQekmNQWaAk2BpkBToAG650BToCnQFGgKNAW2kAIN0Fs4KN2kpkBToCnQFGgKNED3HGgKNAWaAk2BpsAWUqABegsHpZvUFGgKNAWaAk2BBuieA02BpkBToCnQFNhCCjRAb+GgdJOaAk2BpkBToCnQAN1zoCnQFGgKNAWaAltIgQboLRyUblJToCnQFGgKNAUaoHsONAWaAk2BpkBTYAsp0AC9hYPSTWoKNAWaAk2BpkADdM+BpkBTYOsp8H//939n2vi///u/czj+//zP/5x5JiBtngnnPnE18VK5KaOmO+lwbed+21LzLtFgL+XVfCkvdHefOGUJS1/z7KWOTnM2BRqgz6ZJxzQFmgJbQoGAQJrj/r/+67+uAwieAYOAxF6BIelTdr2v4Tw/CV87/vM//3P667/+6/kS3o+Tv/alhpXz3//939cB0vq8hlMn2o5jkmftb54CDdCbp2mX2BRoCmyYAsCiAkbCAIaroJzwmCfpkndVE/M8/qp0xxGvDX/7t387/fRP//R8Ce+nXaFFbav8+ykjacd8ia9ld3izFGiA3iw9u7SmQFNggxQIACsygPAf//Ef0x//8R9Pf/mXfzn98z//81m10bBpmv/+7/8+a4jyASpl/dM//dP0D//wD/P1L//yL3PcWEDqiT8+P+773//9359e9apXzZfwflz6wK/hlCEOvQD/X/3VX810QTf0Crh7juaJl1c+9BRnDP7mb/5m+ru/+7uZ7nme+lJX+/unQAP0/mnWOZoCTYFjosDI5N0Dkh/6oR+afvAHf3A2+2pK0gGVf/3Xf53BG4D/27/925mWApM//MM/nH7zN39z+vVf//XpD/7gD2ZwSd4kDDCN8Xl+3P6v/uqvTp/zOZ8zX8IHcfo09if9BM6/8Au/MGvoaINuAJkpWxo0FPfnf/7nZ+gJnAE3gQdN3/KWt0y/+Iu/OIP0QdrXeZYp0AC9TJeObQo0BbaIAsCFpvbbv/3b0/d8z/dMn//5nz8997nPnYFFPI0ZoPAByY//+I9PP/VTP3UGwHXFPu6P/MiPTF//9V8/ve51r5vLkTbAFT/AlfuTJgPg+/iP//jpEz7hE+b+HqQ9SwBNkPmzP/uzmVYvetGLphe+8IXTd3zHd0y/8iu/MgNv6kG3N7/5zTPtCEdcgJuQ8wM/8APT85///OllL3vZ9Fu/9Vvz822hXfqwq34D9K6OXLe7KXAeUCAHkgDC7/3e702veMUrpic/+cnTJZdcMj3oQQ+aXv/618/xzNUBnB/90R+dvviLv3j6iq/4ihnQkUl+4PFVX/VV0yd90idNT3nKU6Yv+qIvmp8HTFJX7reFvLTbj/3Yj50+7uM+7joAvZd2Jo3+c7kXphUD5C/8wi+crrjiipmen/u5nzt913d91wzc6f9b3/rWSbx00eCVQ/NmyUBr+Z/0pCfNQpG6Ul/KaP9gFGiAPhjdOldToClwTBQAnMzTzNJf/uVfPj3kIQ+Z3u/93m+66KKL5nugQYum6f3cz/3cDMKPeMQjZlD7+Z//+TOgJD8wecxjHjM97GEPmz77sz97BpyAVva7c39M3VtbDaCLBv2Jn/iJczjti7+ugABl0tZ72u8b3vCG6VM+5VOmiy++eLrjHe84PfWpT52+9mu/dvrd3/3d2SJhX/lNb3rT9OAHP3hC0+/93u+dtWsmcNYH1oxP//RPn/NL8xM/8RNzc1LPurb1s3NToAH63DTqFE2BpsAJUQCw2AMFvr/xG78x73Uyp97mNreZARrgAjDaHFChIT/ucY+bLrjgglkjZJqNk/8FL3jBbC5+5jOfOb3mNa+Zte+AFz9adACmPlNO7gPmKXvJlzbp49cyluJqOWmD/gHOj/mYjzmjQaedtTzh5Knl1HrynI9mtgGYtgk997znPec6HEhDS+bsn/zJn5yFmjvc4Q7TpZdeOpux7VM7aEcD//7v//7pec973vToRz96IkDQtmt9Y/tqu/JMW9IueZM/fvqa+5Qx3if+NPkN0KdpNLsvTYFTSAHaMW3NYSQ+s+y97nWvCWh82Zd92ay1/c7v/M58yOkLvuALpiuvvHJ63/d93+nDPuzD5n3THGj6pV/6penZz3729PSnP302lQMnp4+BgzpcAQNx8rmnLTKh8/MeMnBw/4//+I9nNEp5xMtH48+++DgkI7BIByxptKwBAJlZW3tZAGi5tH6XsGcsBZ797M/+7PTLv/zL88G3P/mTP5mFGeWnLequ9YlPnP6i6Xd+53fO5nNWBXvd9pLf9ra3TWhqr555/Za3vOV05zvfefqSL/mS6Wd+5mfm9jpJ/43f+I0zQH/e533e9PKXv3wWeEIzNAjtHCgTn7ahZw7widcWWxRV8NFWtEm8sDjpzxfXAH2+jHT3symwgxTA0DF3zBlDx/Bpxcyt973vfWcTt0NKwBbQfMZnfMa8H3qTm9xkutvd7janlR+Q/tiP/dj0tKc9bdb0fviHf3jWypXpAo5eYQIc0nOAwP1f/MVfTH/0R380CwdAJ06ZtEl723//93+f6Dm/PH/6p386A3UeBBxzz9c/mqr3nGmuTms7DEZj5tt3pp3e+ta3nq0Gj3rUo84cGEu6Zz3rWdNznvOc6Zu/+ZsnIJ1yU08F6BrWT/0D9A7dfdRHfdQsvLz4xS+ehQTxLBSA+0M/9EOne9zjHvO9E9sEGxYJB/WYuF/96lefAW4gq/+hKTpU4EVvh9P0Gz21AX0JC8BYG13yOCXOepJX44wJOi7RMv09TX4D9Gkaze5LU+AUUyCMG0A88YlPnK666qrpJS95yfTt3/7t88lsB8i+8iu/cgawD/zAD5xNtvZIaae/9mu/Nn3rt37rDCYOO9EQgT6gybNv+7Zvm7VGcUADsABOe7D2Xpl7PaPtObBGKPi6r/u66Ru+4Rtm8KfJumi4wE0dgCVuFagAoArQTMWA2WG2ADST/oUXXjhdffXVcxxwdtF4mev16Zu+6ZvOAHTq5FdQXgrTlJm5CS/K+tIv/dJZ2Pnu7/7umZ4f/dEfPd3pTneaHvCAB8yntbVV/9HjMz/zM2ehgtCEXoDZs+/7vu+bvuVbvmWmOdqhCXoAdZcwMzqhiMVA2wkYTumjvbFBO2OjHlq7sGfpU+1L7e9pCjdAn6bR7L40BU4hBTDiqjUx/QKmhz/84bM5FkgyddP8nOBmlmX+vuyyy2aQYDZmimW6fe1rXzuDLe3NAShliWc+vvbaa+cDUgETZQE+Jl6gCcQACG1PHbR1J5ef8IQnzODm3mlnB9kATkzBAZL4GaLcAyNCBLDS1gB8TN36FxO3A1zAP2mYuu37Aj0ASTsdXeoRL1zvxQHUr/7qr57B+dM+7dPO9IFWDKQJPrT4hz70oTN4E1i8rkb4QXd51Q9Qgb08tPrHPvax0zXXXDPThgkc8NO4mcLRRh7AbtykRUdCEvqyTuQQmzqcyCdgxUIw9vG03jdAn9aR7X41BU4BBcb9RvdACUAzvTIJO/iF8QNNzB3Tt/98+9vffvqar/maGUikAbBAF+MHAHkHmBn3wz/8w6f73//+Mzh5T9o+t/1e5dNknXQGEt4RdikPaMcMrT00TSDzqZ/6qbNmTdMHWqs05wqUNWzY3CcfQFY+bVrfR1fz1vCYLuXWNMKEDkLKM57xjLkefQKwL33pS2cBBhgzuTtIBmjRFMgSFtDIB2MIBzHVGwc0ILygySd/8ifPQo5y0Qzg6gctmuAkrQNoTOjGiPBBYAH23s/2XL0EFcLE+eQaoM+n0e6+NgV2lAIVVGi9AMMeNK0OeDq9DZiBhP1lzP4Wt7jFrBUCGie/7fHS2phJ7W/aN/ZBk1e+8pVzGRVQAJQDUbREAMl0Tbu158zEC1iYZAG+i5kdmGQ/WLk0dHvmo6t9ybOlOM/EAywArc/awgW8E879WM54P2d+x0+eAT0ATRB55CMfOZvRmbpp0PbXmfJZEQgxfHvOBBc0RwtmbfvZDvC98Y1vnEGbWdsBNm0X5/CePOoB+DRhe87oxurwwAc+cL68m+5kuDJZFIyd58knnkvba39OY7gB+jSOavepKXBKKIAR50qXmH4BhdeC7n3ve8/gReOlPTtUBKjvd7/7zQebmE6BA40P4wfgcTnk5ZAZsGHedfiMZk7zY9oFEhwAdIAJqDAp0wDtiQJ52qMDaLRJgAK4aefcCCTKGa0Cc8LhJ33mA7nsN+t7LXcsvz4TDnDPmYaf5AXQ9vJp6EDY3r5Xp2jGXqViMSAE2YNGn8c//vGzIOIjMWiectAWjX28RP+Z7uVnSUAXpmzgHBN29t7VTThixndYDf2koUHLw8LhACDhyP4/lzqHLp262wboUzek51+HwoRy+hYFEhdquK+LuoalcT+mSd6k5SecPEnT/tFRIGOZ8QGQNMrLL7983oe2T0yztP9qDjhU5LSzg1W+NmZvOKe26ynsvCblsBLgsEd617vedTaPxwxLC45TNlAnBDgs5hlTLM3aPiyQp20CF20JENc5k7L4q+JrGmGaKO1Zn6uJe6/5x/LqvTIAIWHEe9Z3v/vdZ9o55AVk0QswOiUOuJ2Mt/fPjM2qgB5x6EnDBdTAWRjIM4Xbk2dVQGsWDLR0AXBaOGsF8zchieZOEGLtICjQoIE8cNaeTfQ7bd52vwF620eo27eWAuNidZ+rZhzjwuxrmlXhWkcNr0rf8ZulQAA6gMfETaOjzWHoNFeabl7lAdZeGbrPfe4zHz6ihdnvTDnx00r7xJ4D2XxRS5hmSUM25skTHwAx6dJumcGZYJm9AcvSHNlrXNoUXz5AyHTO7JwPgaQdSXcYH+30l5b+kR/5kbMpmtARZ8/e3rBnBB6CAoEH3cZDadoLRIG0ttrPp2ln759wMzoCgvrtNTOf07ZZCoyjeo2fffJKQ+FN0mBs07bcN0Bvy0h0Ow5MAYs1zLkWYgHXRTwucGnF1avmXxWfNLXsxLV/dBTI+AFo+5kAxStOACymT7UHwAEKZk+rpenGjXOFRgckmMFvd7vbzSfAAQbNkVmbS92EBJofcGL6ZZ5VBxM3U/eq14Ayl9KG/fjRYFkKaJXcpuae/gQgmZf1h8CRvV7Pab0EEODp86j27AEmOqQdtX8sC2jOVO1rbfagpQfmaF9pqS+eKZOlw+W8gDawahC+hOvWxH5ot+tpG6B3fQS7/TNTtB/o1Q2SOunePqTvAjMJYtgkcmFSubBLPA1IHN8lPnHSYzTKsa8mTNvAnEcm38NwfBQAGLQyZlkgCRAqUGD4AIX2ZQyBDeCMBl7TipPfHHDIi4nX5ZQ20ytgkIZWCJBozszb0tv39kpVAEs6z6UjMEgnHEA6KIUcqGIidhECNu1YAuzxEnb02RzX/tBLnUCWqZpvfVgDoWPag0YEIZqzd6CZwZUrPRqjDV8adIlTn/HMiXmaNKHHa1XWM+sGU3rac1h6pt5d8Bugd2GUuo0rKWDRAmd7ZN7VZNb0ig0m61CL117s39nfcgjGxUSXixY2Xp5J5yCSvUyHhpwYdpCFRE+jqXtvKxvXDzZCgQBBGDOwZXZlggYU5oBnuTx3+phmCGABR5j7UoMABPABDF4lcpLZwTIADNztreaLVkCXxm6/2eElQASQzIfsaSuP4ABYAF3an7rTztyv8+WleQJpl/B+8q8rO8+AJRC2dw48qzAjDWD1XL/4I8CmnBz6YuontBAorE2grI6AN8AWjpOPtkzY8U9l1jFt3al7pnbbDNqg39WN9/XZaQk3QJ+WkTyP+wEwvSfpVO/7vM/7TO/yLu8yXe9615ve+73fez70k1O5gBcY84F2Dt4ErOMHnB2aAdDej/WpQ8DvIBFNHVMZGe95PARH2vVK58qUxedZjdeYxI8Nkw4A2SsGtOYOawvTLvMtkM4XvJiUnfBmVgaONHMHtoA54c1Jb0BEywMk/i2LZg1sWF1YYwD32BZtGOPGdtZ76cf+eb4UV/PtJbyuHcpfEmzEyxcfeBIc0NPWgP1yF1M12hJU0M5BLx8i8aGTnHKPVo2uxsBrc4RhZwuYyH3vu7ZBna7zxTVAny8jfUr7afHSajBFWo9DPu/+7u8+veu7vut0s5vdbAZY2rX/uMUEmLVj8o4fszY/VzVz0wgwbf8hzGyqLgDd7mQoEAYdXyvWAc34jPbti2Lmi31Xh5BowjTm7IV6L9eBKJ+/pMkxlTP/AiDAzEJzl7vcZf5jDoKe08bM4j59SbMGTEA9e9hjG8c2raNkwHBdmsM8C+ipZ2xXnvHHZ6lTH9GUSZqQS1D2xxpO2ROIrT+ntAG29RNTfcaPFcTJeyfn5WEF88lW63O0VJ1vW0sN0Jll7e8sBZgwSeQ+juCvBm91q1tNN7zhDSd/mPARH/ERM8Ok2VjsAH2J4YVZVCIkjukPSPuSlK8oeQXFvl2e1zwdPhoK1DGr4YxBGHfu42tNwvFpzQADsPp6FmAFEDQ9PpDOdonT4DQ7AA0wAAcLiwNoLDNM4tdcc82Zr40R5AANKwtNnYYYN2qCiT+Xn3afK91Bn9fyE46/qkx9kcZlXTFl03gJKLYIrrjiilnAQRvbS74mRiAi4HhXmtk7gM/c7RUsZwAIRmif7QVrWx1JG19cxnxVG09D/JEDdAYxxHKfwU1c9Q86iWsZHT6/KGDO2P/DeL3WwfzozxLe7d3ebbrpTW86f3yBFuS5/azRZY7y4xLm5wMVmLeDLzG9JU3ytL+dFBjHyf40QQtImy8O/9lbNTdocywtQBbY0LRpzvaiacQ0YwelWFGYvwlu9qNp4kzizN/Kk/Z8ABAjDmyZ99FJ360T3+P2aU5CLTq70BJtcy4gswVtbRMAb3vPNG2WLGv6fHdHDtAITOqpwDsSvS6gVeExT983BVCgzi0HcjAKzNcBMf8JDKQ/+IM/eDZLYhiYs4VvPkYaHylpDuZZ5iPffpj9M9I9BtxuNyiQMUxrAYST/rY97Jvmq1fhUawjTu0ba4e9fEzDIacIavavzTUasoNq9pudgGYmp2UrP4e5Uudp9h2gY2Vy0aZZDQg7TtujMzo6zZ2zGxkPAoy89qcJvQDaa1k+bgK0203TsQD0EqENUpggP4NW0+Z5jetwU2CJAuYPBotBMGf7pq/PFgLp61//+rPZ2ylskr3Fj4lkzsVfVa54c5F2RQDAtNWzLt9SWR13MhQY+QiwBcKA2ThGU8t4mhueSWPM3QMT5lb3QMVccwFpZyCAE6ENMAFndZwvDn3QhNASq0HAl3CDlujDlF3pIr29a4Bsn9oBTBYK61P+cdzOF3rWfh45QEcqVakF4D4LIQ1xP8YlfdK03xRYokAWceaP+eUAF8n92c9+9vxpwvd6r/ea96QdIPPZQHtgTJqYRfLVsmuZwtLwMWjMA+OOFl7zdXg7KVDHM+Odcc3YanmeCQMI9zVu7N1YRtLyK98b853mezSp19hXtEFb1ggaNiuGPX5bBLahWLjizlcapv/8IwfoWlkmcI3rcFPgMBSw2EcHeEntgNirUv520OtX9qP9ucJnfdZnzYdSSP2kf25ktuLM1zpnhTEWkr/07XaDAhkr45fwfls+5q3zQlmZP/std9fTp9/okav2KeszdJeGhcHWAGuWT7a67N2zTLFQxI00Tvz55B85QNdBIxEZHGalnHDMwCF6TXs+DUL3dTMUMH8idfOZ1Sx8J3EvuOCC6UY3utEM0vanvVqziiGMjMEcrfN0M63tUo6LAnU8a9iYuk9cwvylMc9z7c58SBniks/cE253XQqwOjFz05JpzvkwiYNhDpYRmFmpuKbf22l35ACdIUJwoOygjUMB9mvc00jipOmBCTXa3wsFwiiTts4fmi4zGpC+8sorp5vf/ObzfrSPjlx99dXzKzOYxViG+zDeWl6tY8yTZ+1vHwWWxlAr18V7litC3357dj7MkdAo9NRn9Mr6qTRzeM7rag7U2X7yMRPmbf8J7eAdbfugtK71nKbwkQM0otOYaTM+/uDD515NcKrPB+aZNDKR62BnwE8TsbsvR0MB8yYucyn3fAKhL40xbzs0duMb33i65S1vOf+vrVdmmMPrwZ5aXsoRV8teSpO07W8fBep4LY2j5zVN7UHSe56w58JjnqW4WtZpDJ+LdgFdvN7rU15te+5znztr0A6IOShWFbXQOObx00izvfZpIwCdSRrC5t7+Hi3GS+xecfG1He8W+rqMD0jYewDaccm/dJ8y6wJYNzE8iySnvOSPn9OEtYw8kz5tyfNVftqqrpqm1pk07R8/BYyjU7ZMaE6JXnLJJfOrV/ak73CHO8x/4QeknTaNy9jnvv3DUaCuq1pS1kviarqEk6b9d2r0u0SLOrZM3N6ZjhXVGxEOdDJthx9Ln/7VcOJGP2lSz2nzNwLQIQricfENhvcMvePm5XMnaP2dmK/K+AIPoLYPOLrkF18BOenynD8y0zxL2vhJF2ku93nOJ1Awuzupa/Lks4/rfK/0eE7Q0Bf5mGtIhEt11Po6fDwUMCfsfXm31acIb3vb257Zj/bdX/+i40tGTHB55UbLevw2Mz6r1qT4+izhMX4zrehSToICGdNVdUexWfV8L/F1vtT6angv5Wxjmo0CdDoYwvj3E5/N846bvw/zgQdfkrEP4aPpTtkyLy45zPEwDFIbqokkbUpduZcm9QBV5hafjPQerU/67eXC9KVjEdBXHywgJbY7eQoY31hSnHugLRsnJm5/psHkDaTthfnIBKEyLvMi9+0fjAJZa2PuVfHSrXs2ltP3u0OB8PWl8RWX5/vp0VJZ8q+K30/ZJ5320AAdIsTXIUR2z7Tt/TYfl+fbewaA9qQxSxpL3XuQNxJVmGMtN2F+0qW+SsikSzvc13BNW8P2IQPQ9kho+Oe6gHPSPPOZz5z3VgC0ctKOWkeHT44COTTmY/0OiX3Ih3zIdIMb3GAGa/9k5HODrCftNkuBug5qmPDk1C6hiNXJWQGH+lzC/i6yr92mQcYx4xrfa1au3Btn4cTH38v4Z95QCM0jZvNqCdvsbD7e0g4N0GluANW9RejyF2z+NuzBD37wdNVVV837ffYC7QliltFepU1+wLvkapo8F8dVX1i5Sy4gXfOIi4ZlULUrJm4aFdP1uos1wHOmbuZ8Jm4H4vK6wFI7Ou74KJB5pUbzwhaGrQgf5vdXkv7x6sILL5wPkfmOcP6lquY7vtaezpqyPvUudBVnvdn7t0VEqH35y18+X694xSvmz7XG9+nWvnaTBi972cvmMc34GWNxPuvpG+bCuU8496yuybfOl165PnRC+PZN8KzjXV9RGwNoCy4LMWESkY+lP/axj50P59zvfvebX21BQF9jCogBSAcFxOUvAfM9W1qtz+f5T1aACQRJVzRveWiqBAF/hECCkl55mLHFL73n0qd9lVHUAazPVwkKNX0NJy8/TKg+7/D2UID1xqsd/vv3bne72/yvOxiAV64IaJzxz5huT8t3uyV1bVgj1j9h1v4/+ttWskUUP2H3fe0+DVglc/lLTpc/0eAnnp9n/L2Mu3kinz84MY+cDF+1dbprK2hjAK3jYWjxSTHA2OlZf3bvYxFObzssRpN27B6gkqSBK6bJZOwQmdexMFIgS0tFfPH2D0lfzBoGwcfVvVPnEmbisPiZ0dXhJXj1AeoKumljHbAKrDVtTTOGlZMrz5bKzrP2j58CGdeMKaHOdotXr/w9ICZgnpoz+bLYOKbH3+rTWWPWBh9AW98sGta792NdXsN5/etfP73hDW+Yw+772k0a1DE1nnu9jHfmwrqxTxrr2f9ROz9EkWOlzVzb5ZW0EYAOIcIIQxBaK63YYTD70Jdeeul0m9vcZtZYfDzC/gKmCKiZiX3dyR8cAHFhp279Uwzgdvrb3wg6jOV1LeZI71Fjrv6b9RGPeMScJkBM6zZYTos//OEPn8tJu6qv7Wk/rVubY+LO6ex1Jm7Pkk7dNH1agXJGetR6O3x8FMg4AF+gYAET8swdhxjNk5jEVm2PHF9rT1dNWVtLvSKYs4IRxK0d/3ZEULK2+baNxPV1OmlQxzpjnLjMgcSv8llc5XFJgxcTwGMJW5p3uxS3EYDW4TDBdN7CpLHk4JU/ufeH3fe4xz3mD0Z4tSV/fI85kqB9+s1nGR/3uMfN+9UYKDOHP0m3t+D/V50E95ETe1akMf/B6g/B73//+8/gTdvWFozWf7YC5wrQqxiG+LQVw2Z6IRDkANgqn8afi8lUe7S1T3FnJhytv2o8a63RnO0/O7joDQLf42YaczCMFlffw0z6lB1fmTVc6+jwwShAaCLMEtK9CudyaMwlTNAWxiNse9GM8ix+8p2Erz2pN2FtdqWt/IS1ud4nb/tvH/uRDqFj4s0D9Mu8SHzoS+Ezn6znrOODzcztyLUxgMa4wrxoKQhnMmKKgM+/B9GEr7322llLfvrTnz6brWibiEtiYsoAyk972tOma665Zt67Zta2r0BTlQ7wYbLAl0mDKcwJXMD/6Ec/ejZrA2cDJY0/SwDg8i+5tJmvnUztPuIOoGnrAd9VPuDOs5zi1i7tTNlL9XbcZimA1gSz0Dy+WsSTqJ1TINg5F0FYNK+cZ4hZOy1aEjZreUm3FJdn7e+PAiMt3dfxHEurz4VP6hrnivu0O8/S1vQhadyfVLt3qd7QMfSLP8br02lzhwboOtlCHEAKEJkdHBQLUDNjAT6ARjOmCQNopi6SEfOEvQTazeWXXz5f9nhYnnAAACAASURBVI9ptPaWpQOipCf7z8p2apq58rLLLpscQvM3g8xmmHGA1gk/adc5gxuNn6TuwJD2nOvST5d09tIID0wspLjTIMGto9m2PAuzWdUeY2GemQ+EqGc84xmzMGg+xhRWyxgX/qpyO37zFBiZbB2Xzde2uRLNGeu91/zmaJqSMgfiJ/5c/jiXzpV+G58fGqB1qjI0RIm27Pg7jcWpure+9a3znvELX/jC+UCXT386xAW844C0fQSHynyG8U53utOs7cgrXa1HHmYMDJbJEkA7kQugAax9bxq5Z8qk0cctDVwdfGF10cQTv86X1nOuhlNf+ydDAcySdky4I+R5tQo4ExLtb9ZDYdJmfmUs44+tXxU/puv7c1Ngv7Q0RnWc5D/Jq86bsbdj39LOyiMS1/7yOFZaVfqGXqG/++ryvMbtYvjQAI0QdcEgmMNfzIj2k+3/PvGJT5xN1/aSfbCEb3Ofpk0rDpFpOpjpa1/72vlAmf/x9a4cbZipfHTyAWlg7JQ4gGbWVgYBwHtxGDHgH82Yykrbx8Ed69nPfS2rhvdTRqc9OAXQ3Lzg22oBws4lMGl7A8CWiHuHF82dpTESl0tLwiTEJSx+Ke/BW35+5lxFw0rrjOc2Umip/XWObGObu027Q4FDA7TJ6IoTtv8KZO0fA2h7w/aJaTDM0f4L1Enpmk9+AO2dZS+oA1xaMS1cXEyRtNq6YJXhoA/z9j3vec95Xxoo+8iB166Ym6VZWkg1LgxhVdr0b/STbym+lj8+7/vNUCA0zlzKvdJtdZgLQNkBPtslBENzCThzNX1aNMZlTph7yjRPxzTJ2/7+KICO41VLiBBex2BprGue4w6n/anXvblijlVe5bln7fZHgUrPzIOlEjIOp4nGhwboSqgQj1ZMi7UH7UQzbdYpbQfBvIbEBB7zcfKbyPaVmaS9UgVwr7jiinmvmoa87hOMTNiPfOQjp/vc5z6zedyfc7zuda87IwikDn4Wt7CBTJtrmv2GMyGUpR9crWe/5XX6vVMgdA7dk9McdO6AtYZwSOhj5iaweWbMMgczB/gpL+XwM7608fwhCqButzkKoHEuY2BsWL1sbaF1xiVp6rhsrhUHK6m2SQnml7liWy1z7GAldy60NQ/Q07VOsD6N1NoIQCNinIWUCUtTcSqaidppWWZFxA4zNXm94iJeOtqOA10A2rvNXrei+dCigTCQtmCVIW8crYgZ3atWTlXT1O19x7yddPzULVzbLZy21/TnCq/KE4Zyrvz9/HAUyBhWemOQhD3v0fsYiY/V5KAh7XevLnMiZbMMeRPBq34E0HabowBaW9PA2HvRrGbWvDHMOs5Yp9bxPvHH7WsH4MCb8DkHV23z4Wvm4iqek3l13O3dtfq8gkexcxgXXQk+MIBbNQfEr3q2S/3fCECv6zCG6LLwYvLJhLUHbRECU9erX/3q+d1m5mkHeRzoAdTeR37BC14wn/qmwQDqSFLqtqf4lKc8ZT71/bCHPeyMKVP5FoHrNAzWOjqfz8/q+AoT+oAordknAG23YJrOMWTejPPBfS0HPcUlHR9oEB59X95pfenbbYYC6IsRv+1tb5u3qfxv/JOe9KTpyU9+8mxFw5hHV8dnfJZ7acZxzTO+59Utpa9plsYcP/NmiQ/gOHvjq4cEQm2m9cWlHSkvfn2e8Pgs8fv1azm17TW83zJreuXXOoTRo8bV9OH94lalqemlYfXyYSvfyWCRZYkdLarpT2hcy9jl8JEDNAIjWgamDopXX4CyAzxOdzvU5WMkvhDmFSzmSfvX9rEtWGZr0rTBiSZEknLK2343k7gFbZGQuLgMWK13lwes276aAsDXgcC3vOUts0DnYzgWtrcFxGcOriqhzhFhGh0NiGbk07JeAfR+PmFQHecqb1U9HX82BazTaErW+eMf//jprne963yuxGuZtCfjYVxyyeOKy319nmeJ40vHry7Pl+LGtEmTsoAwHkTJsJ3is8O29ABLzs7IY34CchaCWBbz5UEHGqtbVWdNs5fwqnJWxe+lzDENeq5bC7WuVeGxzHqPjr4t4e0eH4KCEwRkSl8sqSl39Gs5uxg+coAeiZIFxSctex/a95BJnUCZOZxpyMS1l+xjIbRoGrX3WA0WppmBUT6tmin8CU94wnzqm4SFIXMGLIM2tqXvd58C0Yj1hMXEHy/YJvG+s8XsU7E06jD39LjOw6X5geGYZ85LOEvBquODN845+GwtwGh3eAoYh9AfzQEaixjLB2HoXve61/zdBN8ZiNvPmpa21qGMxInPlTakjqSr96vChDdzzpfpWPpsg4iL1TBlEfQAOeuOj+TgeeYoIZJpfKkNq+rca7wyc+01zybSqRNtuZH+KT/Pc7/KZ/myZeVwMazwkas3velNs6ATAWik3Xi/quxtjz9ygB4JFUmLT4r0GhXwZbqwCO0vYLqkaZOZNgzESadMSJ4r00V79s7zm9/85vnjJjQmYXGjRLrtA9HtOzgFgK8P2JgfrC62RPzFqXMJLDTewzcv7Gfy3Qt7Jc9783zxudx77lO0PsZv/gELbwnQ6jCJBuiDj9eqnNa0sQRu+IKvALKKhd4jL6nlhCfgK+vS1TxLYaARHlWfi0vZ0rjwHwBBKHzWs541W/FYWSgZwLk6bcKXvHFi68X2nTllS47WTckY3VI7xjR7uVcOiyOemD7Idxg6pd7aRuXV8pNG/FJdS3HJs+Sjqy9NEpQJQhQ2yhynrAr4+y17qb5tiDs2gEawSjTENLlJjrRlZh+gbNIbZNoLMHYS18Dkk6Di40iktBtM9PnPf/6ZvUaTsWrYSd/+6aOAeYQZsqxgjv7a9La3ve1005vedPqAD/iA+YM3gPXud7/7mcv78j4NK87rfHkmnHs+MPaxHH/w8v7v//7zdfHFF8+AwcTd7vAUqDwhpTmAx2LBevaABzzgzDf2kza+9MKVMScuvmc1ferI83pfw/LkWpXWvGNq9UEk33wAHIQ8ZuzKp5IfP2Pd86ops/2VV145949GGAvBqrbWtu03THjFZ60R2mjqiL/f8lal33R5qUe5xjEfwGKpcBiYzwqbMa7113DK2UX/yAE6RAmRcz8uqsSv85MHiANnpjAHgJza9ioXphnTtnKqdLeu3H622xQw5jQTe393uctdppvc5CbTjW50o+k93/M9Z1/4Bje4wRy+4Q1vOIff4z3eYxKu1/Wvf/35mbjkESfsuvnNb37m87O09XabpwA+QSgHYjRo/2wH+Cq9wwdSO4sbQAQ+QLC+jpM0S34YO80SqMoLdPGXkcGnzsS7BxjMriwsDrTRhB1GXOWUna07GjSAvve97z099alPnd/Ply/1rCrjIPG2eOyJu2ic6cNByhrzKCvl4beEAfQ3FuhY+1PTjuWsuk9+edGPsobnO5vkLIgtLPFVIUt74q8qexfijxWgK8ES5rsyEIhW75dA1iRz8MdAeYWGidxA2YM0QdqdXxRwWpbZ0IKlLfsC3UUXXTRrvrRpGvCFF144+zWcOGkSzvN6nzj7oZipeUcjabdZClj31jsTN4BGa38/S5N2OHTkFeEZwABP8P18QM6vp6fTSumVMTqWO3lsqQFQZWWLTB5X+FDNr514j/bhQw4vZS85ba115ZAYxcL+s4NweTU0GnRNn/7VuP2GtYOWqZ0uAMfVfuy3zKX0yjMOXkVEFxZR9znMmzoPWi/6ox8wtv3k74UJOP7RkECXvejUU/2l9u5K3LEA9KqJVgerhkfiZXEYcNIgMMaQnewmtTqgkfdSU9e68sby+353KWCcbX8wiTqDwFyIsTMhYpy5aGH2psXb08xfiXqevxJNHr5LOZ5J495cw4TrIcTdpdx2tNz4jWsVyPn2Abo/8IEPnGkfgNZqazxgB3yAsm8hePvDvqSzA6xp9nXxBRaWAK78+AlGj5cALGVj+g4eyS9MAVAG4GTGVo48UQCU4ZkDg94yAX7ONtCqR1f7J+zsDZ5lDjLhm5vawIV/jWUc9F55zkugpfmcsxObqofmShiyBpVNS7fV5MCv8SD8pK5xrCtdVvVvTKM+Ao79e3PDXrSxN5ZxqS/3u+wfC0AflkABaJPfInLy0QDZ96HNWIgmQgYzA5T7w9bf+Y+PAgcZM4wTg8BIMU2MIpf7w17KAgLKx1xZapjv2u2dAsbVuuSvG2PPAtABMOASAPMckyasi3vJS14yf9/fqWifdHWYFPh5X92/4r3yla+cBSrm69QLUACuVzqdXbGXaR9ZfoeQCHlM1i5mdv8f4Jl5hM9weJLDYQ6xOavgcKJ5YuuNS1/nm/Iz9o8JX/+UvUmXvioTnQgBhE3gtuSkr3mkyX38ka9aAzRX68IW4/Oe97xZaVKPfvn2PZpw8ib/Uv1j3FLaxOmPvyS+6qqr5sN5tGjrPy7pcr/L/k4AdAiMOXofzoIyQL4SZcJZfCTquAB6Jlbi298+ClhMLmO16fFKmYfxt49iR9eiJTodXW3LJWtDBWiMnvUijN5zIIhJe18aiNMMadxvfOMbZwHeN/gBNIAFTEBYfoIc3kDQp2UDVSDCPO3VJ9qfOHnsDV9yySVnDnEBIEKauqM1UhaceXCQkGWFqZXgwGnnklvq32EAutaTMD9hbdB3ddR6xjRpc803tj/P4qOFv2z1Oiwa+9Y9uvsmxUMe8pBZILBtMDpjEB6dtc8Xl/vUkXZVn0DAWnbttdfOFowXv/jFs1m95hnr3NX7rQfoDBgCA2KTjQmKmZt5yiQxMNK5uPi7Oijd7rdTYC8LrqYRztU0PH4KhPZ1TPbbCnkrQNNQATQNM+Xb46Q5A1IfJqLh4gdeY3LhC8DTB5AA7YMe9KD5dTvxQBqoEO4xeD4rnGeA2140MLa/eemll86KAMAHNCwn9lRpjU5Ei3feAUgz6YoP8Kyiwdi/w2rQ6+oJ7QkzaAigI+jk2ZK/qsykzXMKEwsFhcmWIyGHuZnS5D8V/IeC/XxOnpFHp5yUu8pPuvjOnDBtE8wcFjP+vvLnedKsKmvX4rceoBE0RGdSsZ9kvyF7StGcI33t2gB0e4+GAkexWJWJyWQ+Hk3Ld7fUJbqEXnsdD+kqQAfAaK/Kor36PLC93xwgAxK019RPiwWggJf52SE/n2cF2jlg6s91Lr/88vmDKPZKga+yOeU/5jGPmV+/o6k5qV33OJ34tq3m64f+t95repSG1J8RHO/Fr+rfYUzcTrDji8z2QBMtCDGAzAUsCSMuYXHSuAgk8vg6I+EFP63tTji+PmRMabLA0Vjw7T2juy0Eh8SWvkchb3XKrWXX+8RXX37zg0DAlO6wmI9UEbq4CEhjPbXOXQrvBECH8IjvkIbLAGRBrSJ4BnbV844/eQpkQRpPV+732rKkT9695ttrugh+58tcCj35aLpJV8teVa40FaDzHjSABkT2gAGt0893vOMd54N7NDUAKi+HLwBpJmsHiS644IL5/XimUGUDZF+EY5r2xTLfUgDQaR+AZjpXB83T/jPgSfksebRSn5683e1uN/8PvQ/ecEkzhueHRwTQwDn/HMjUbg+eyd++POHF4UZvIOgzgUO8Q5U+BiOtPVwCBitCPcuTNvPrXAidaK0EHx8Fsh/s630O16Ela4JxkM8aCl3ii69lpq48r3XWOGVlfrAIqBtQmx+c59Wfb3b4Z2cAug7Suegtba5zpe3np4MCxtuCz7jHP6repb6jKv+4ytWP43br6vQsDLgeEmOaxfRpiUzLwNmrcACWWZVWm3L5LqftHSYFooDeWx9AxZfimL69igewfFyk/vmC8miF/vLWHnU0wwAKQATiDpTRzn3URhlc6l5FU89r/2IhOIwG7TOYTpADXq9voQmzs/Z5R5uQcec733m67LLL5nDipZGW4EKzBnL1MF3tQ+1XwjRwX3r0cSD79ehlD5+wkFfVACbByvg4yIW2xkUa9dHgo817Lt06xSv0I1gwcRtX84TAFPpXv/ZhF8M7A9CIG6nLoDPF5D4Lx+AJ89ttNwWyyNeN1bpn6Z25sJQu5SfdYf2Ut1TXYcs+bfnRyDo0Nq79rEl5K4BlDxoDpt0xq/owEXC+9a1vPQMRhl+BJWMkj3fj7SV7P97hJUAvPRO2L8oBLxoks6+2cl6v8pzG6eM3/pkKgKdc514ADaDzDr2v0gH98KF14zn277AArTwaK7DTTodoCRROpfvCor5pJ2uACyiLk8Yljf1zmi+gJASln/HTn9zHj+bOkkBIYanQH4fFlGe8bEuyZni/XJuAKa3X3jHNl0DhPAFNXzukSz71pK60ga+d3pNXlvnhLEL21pfS17y7Ft56gK6DVImfxTQSvKYZn/X99lAg42q/ygImZY9jupexTDmkblsf9tGUt04K3w8VUv5+8uxiWv1Ef4Kv8x0OQ6Hjfp1yABX6hzkbl3Fvc1W58leAru9B065omg4I0VwBtFcumayBRVzmEYAGwPaIA9AOe/naF23a/iXtz8ljGijGT8N2Gtwf7/g/eqACNLKtpm/mmDJongAa0DOno1kFaX0Z3di/wwK08oEqEzza0Oxpp65oq067X3311fMlLE20WOmAG02WEKKfaffo176pV39pyrYYWBwIQsbFoTx/AELoMYfsRzs1b9zQ1PNHPepRcx7gygTvPXJbCQQw/TFfuLEN7rUVqKvTt8x9Bz0mbm2UJvnmQnb4Z+sBeodpu6emr5pI4scFsZcC103OPBvrTLzyx2fakHZ4VoEPI6zpazhMssal/SnDQrQgsyilTb6kXeenbO2jQTmF63AMUxngX3LJs5dn0iZ9aCBfwp4lLD7pk6emXaqv5l33fF15eVb9pXLzfKlNeUZIwlAxXQDEnIwJ57lyEx7bmzo9x1yNrXKAm69LjeMh3dJYKwdQ2kNlwgTQNCWHgGhWmL79U6enb3GLW8z7nvnThNoGYWBsn5LmqBzvRZtr5gltk3bsGe0Pk/eqkP8cBhbSAmCgp97aVv2jRdP4nOBmbqeNxqy7RONKL2DKHJ0/A9FGJ59r+6VfRetalnZpj3FCY+2iUVsPuQgw/jjGa2dM8Z4njfT6Z9yNv7W5VG/alrozfgBdfwCwU/OsCbYPbB2IY35Pf9GXKd1nefU3r8xKSxAyXoQEbViqT53ifZyGVcAJfjRUrnnG1XFKW3fZb4DekdEzOevCyWQ1YWv82J0x3/jcfc2fMN/ioy1kkWGcGKRTnxYdTSeXZ4DRgs9CT10pM/c0NMwDCDhck8+0ep4FJk8N66f79DdluregaVfapDwMQFjbPZMv6fkJpz3rfOVz8qQuzFB9GD0Q03d00H/34tGhgpv8aX/qq2WvalONl9+YKJtWknr5CRsfQoor40S7pM2ucmiEyTt1SxNhnoxWBWhrGyotxI/PPNdOtNcWgODSFiCgHTXfUn5p8y3u7DFql3mDgQNDGvGtbnWr+WNF/rEM/ZWFpup3+ZCIz2kCYADl5C/tCyDRIpnKAbQDVL6NDZgxe8KBOsxL81SZYzvFKf++973vfNjMnmhe4xrpXPNqF7roHw1Q/5h6D7MHXeurdSXeWBJ21BNTsGeh1VL/lFPLqvdZv+ahMTUnzXl/s+mkuNP1PvYCdM1TY0Ojzr38hBnauzFh3haub+fU+mo7tBvfYPWghTvB7bS+OcMlbc0/P9jRnwboLRu4TKwl/1xNlcdiW1pwS3ml5+LXsDIsQGZCp2YtIowrJ0RH3zMfLMBoMHogHZfy45Pe7fORoC1cGhAhoNafvHv1AQxQol1Z9EAaYGIeY7n6NsalbXzPMVLAFScOuNBSgL/206C0H7N1IhaNMAuMinkR0wBwyjqXS/2r0nmuL5gYTcOYqNup3ZzG5WuLsRB2mMqXtTA/NB/rSF+jgdFS0c7rQ8AJ0zWO+h6a1DJqWLulQTPx2mo8gCdzJJAmvABurtJE+pTFRzfzi+ZM82UGNQ/lwdyNrf+IdzAJGDCRMk1z8hsn9Xg9yvvMDkhJwwxNm0cLJm37n7RK4EyjBt7A0yVdFWzSPn1MmJnYXqq9apq3ewKENNXVe3kBFg1a/wC0/o0atHSpp5Y1hveSBigz9de9WuWcK6/n2l7bLx/6KdO8IhgGqM0fQo66HE6zPgC0saDhxlJmXdpGsF7sgdu/NzeMbepL2/h1rnhubRE4nBz3epexG/lH8o/02rX7BugTHjET7qQnU12AaYs4WiLGSJuwZ+cb1nwHTZzWBAQYDa0Dk2My9PlEzI1kzSkvZWLeGD5NA3jIZ9+JxmaRr3MpJ2UtpQWcylMuoAlD1pdK57G/9X4sF3hhMMDKu6/223zIAuj4tCHG70tUXjFhJkUfpj7mURoDMAGomBJ6Vk12Xb1jO9xH8zAmOfxDK8IQ9Rk4AzbgrG2YJN/4oU1omHpDS+2ioRKwnOo1tu4JI/qf9GObUt4Y714ezDnjoU2ECoxYPvMg9accdakTAzbHfOOa9mvf0kcwomEBUPuZNCgnh2lt/k+eQGCczD9lENbsM0tHcKJ5GUvtQhPjxEzq8BjTK5AEPIQvYenVZW7WcUu7pTXvgTSTOIEzQFFpkvT67Dkrj3kDYOzbyo/2gJt2b5yTp5azFA7t6jNx6B9gM1+Y0V3C1SV//Pos4Tr+0kVbtv4JgIQdc5wpnXCHD1gj1jUwN674AeFF/1kvrH8AzQphbbA2xaXduU/9fLQB6E7nE96sM4KBMUq65DsNfgP0Fo5iFgvfZDXxXO4Tji9uyXkOEJMv6fgJJ580cUnvHlMy8YGM101oLfaLaG4WGYZCggaEnmN09p0sxCy4WhetinaNQWGOmJRFLa7WKxxNLO1a5aMPBsABGpoU5ktbAJwYAKanL0lX+zvSo7ZXHoCBUdOKHUjC7GlMNDPAQGhRj4tZD1iik4Mw0lTmbe+smoxrXav6J01tL7oCGIIQDRCTd6CJtgJMjAlmSXsE1r6UBaiAV9xYL41VGoBO4zU+GCl6GYfq0NuVMvi1jZ7FoZ3xIKj4NC+zpPEWD6yqU0Y0LQeZnKJmwr7ZzW42H/IyXzBmplH5gSiBxCEvJ3nRntBkLpqDNFpjwgTqVSDAJJ/2oZH+0mC9euRjI8bM2GmnuSNMOwOchBVzK31Ou9ENSOXzlkzm1oN0oUPNQ3CgORLi7NN+0Ad90HTjG994PpFuHgE1ggHaj/RJnQfxA9C0TkIFV9u1rkzpMv/SL/MMTf0XAiHK9oE9YYIdmvEJSMAZHcwhc8m8BdrWkjVqrMxLc9rzdW3SBunwCvkJXtaYeY5HjfN0XZ926VkD9I6M1rrJ61musTtL+ZI2z7IA5RVX78VhhvlrPNIxLRKjjCPB0iBokBYgEAoYJo0ymQwBO7MspmZRA63UF6aWPKv8sf1JB1AxeSCAedC8aFaYJuEg9SR/8lVfGu3QBwxVewkk+m3P0DeGvSaCKflIA5AEhC5Mi4kPHYC3E6aYiHYQbAAP+tBmq4Wh1i9c21fDeYbx+bAEbZewYGy0M/0DRKwUmJc0QASdRyc9ugAFfQFOgB6A6X+cNpzLJU1tL6ZpPJi3jYd2Ajz9V+/oCFLMoMaMZvrQhz50Bl9maICrz5i88ZHWdgrLAXDT/voKkXGRB+gxPaMZp8/RAPWXhu40OJDH9AlUvjLm3slnFgraP+tJAD59tD+tbGBvbhh3a0XfzMXRmU/GxLw3P5i3ATUhy3qg5cuvffvRotWTNmUcUjdaMd0THsxPYTSwPjNfknbJl6amE9YPbSWQA2g0I2yrg9CkjzH1Sw9YIzwbW+vAWBprNDVP+Ma01qU9lSegN/rQms0lQpQ5UNOkD6FH7nfVb4A+4ZEbF5TmiDNRx4mXSbcqz7m6knLrIlgleaYOPsDzOghtgwmLFE5qTRpmS6DrAoba7Vmep08kbwvYYqatWawYblzalXzr2pbyk0cZwhgjDdK7mDQhWhXNKww6bUmd471yMUdtpYkBChoqBkwbZdJnqsWYCSYYHkCjTQnba6M1AkymP6Y8GhOmDwAACbMgsx6HVrUPaVdokPukEY/ehAZaIxADUPqcPFXzlw6dgSKXcoQBCUZKq8PwvDPMWkJ4UEbKi5+28MUZn3GO1jQZDxooAcV4ADt1VKtJyg+jNifksQ9u7mHKBAxtDbBLi2GLJ/QQGpnB+cabBmcM0Qo4RGDUXvfmsLEELgQp88VccQF3486Mav+a1cReqTFO/fqpTG2gCeaUNFrGFB9ap3/mFcFWm82PHGjURwKA8oFUNf9Xeh40rM00VfMTWFanjS5tzFWf13DSaR+62oM2twhBaGBNmP8EDOOTfhPMWbJozXiErQBtCThrk/VQBdfUlXFzLw9BmDBDUze3M6+1UxoXl7pr+3cx3AC9JaNmQoWxmuAWFEaPyZBYMTQgY7IDR4t9dCanxSidiUuLwuhcGBJTFx8zMNkxhFpOJrdyMTKLzOIBSBiVQzkWWGVU0mFSmAxGKVzLqQsFiJC6aVMWGukXs+SSjq9NmIC+aieGTRNTlwWLiVnQ+odWykg/5Nd3+1u0egsZSBIcUk9tX+Lio5+yaQEAmQkVg2YuZaqNJoU2KUe74mo/tEsb5QOitG9aGQEl+7H6I3/ypZz4ia9p0IS2wkQLRPQTY0za+OiHaeY0sjK1m9N2dDQmaKUcGqX5MTppzU3zynxEy5gVladtnhknIKrf0sfJQ8sE0mjKjJ7xkCZ0FE7bk3dVXJ5Ln7ZZM+a6MSJkKNdzV/otLXAhfBEWzA/WEZYD6wPoAE6gQwDynrP3qAE3jS9aXsrlW6fG1Hg4+wCMKkjV+bHU18QpK/1N+ennKn9dupQnb2hRy6nPa7xwLbemSzniWFnwAnOckEr4QN/0F83NBYIswZ5wapsIDzHvzBW8TX4Ci7GTfnTKDI8h7NpOo4Wbq+LjtCm0TNyu+w3QWzCCWQAkSozWHgvTpMlowTMLMhNa+E4sBghr001MYArImSyBEi3VHpzDIUx18WkHzIHKKEuLEAAAFhRJREFUxazi0o74QNFzmoZ9OgdaaAhArAIGcLSwXHXvTDn1AuJMvk7eAihMPemTTlssfPXqM43bgga6wEzdGCKGz4RJG9VfbU0ZFj4Tmi8cYZoYgzxxYda5l49TvjFQr8NDOUHMpEbrA9wYNIbBrWMGaYvyMDFjh8nTopk0Ab6DXhi5clJW/LmCFT/6AlTs09Ls7fkB7bjaHzR2GaO0KekwR3PA/i7tlnleOckvnbA2hdESDNRHuEIL8wCT1D9aFA3WM3XG6SNrgvGiaZrXwG5TThv0zxzQJuBsLGs/pHHph7E0L5iZCSfmD4AJrWjAxto6RGOCFaEC3eXnatkEE28iMCETctBTmXWuyFPHeVN9P+lyrFVXrC7oHhd+RtNl6bGdgJ4ENUIrmlm/rBM0cYIk/lUdOhsXgqatGoKu/HggITE0reNR8+96uAF6C0bQJMP0MUySffbVgASJE0gBar5TsSR8IMSZmBYFoMMImfcwE6d3mYIwXodD7NdgSoDaiWMCgEWSclJWJQcGg9FgrMzb9swwtywGvmvVIkk6jNEippUCZ8CnHM6zOGGMFjhbkJgnbZtA4R59SM1MZQQMWgtJGjhY2AFedTnYhTHQftGRdhSXdrmv9WMowAWts/9pLLQVk0i++ClvyZcm6QL8GBBTKiZl7w5I65d6047kqX4Nq0tfaHf2wglgaABQ4pLeuHApuz73LJq4vVOarXKATfIlr3lA40FP+8HmE0HNYaZYHDBYdMNECZH1jEIYtX1L48GUbl5twqWvyhLOXOTXZ54bB2vEvPdPVv7pKtaVavo1j9ybVwDButFfNCYEVPoISwvgCSjmpTWbg3bok3bwE95E37ehjPQnfav31iQgJdA5h2G+Ooxn7qKTtYUPEYABNQ3aXIsLnc0lfBH/I3SbpywwnrtSd/KdJr8B+oRH0+TCOExMExQoWeCkcVoiQKZ50X4Ba0yjFn6csMVA88NoLQCaDu2I1mo/TtnAh4/Z0tQx48qY6kQ38ZWJ2VpMgJXGoazqsiDHuMQrB2BibtpjL9Z+p31FLun4+mExYt7SAjAfgqB1AmVAiT4WKZMZzZppUr9I03EYrHttJ1TQWDGK1JV01fcMk1UmgQCIkNQxaeAM5AJ0YQw1/7qw8ZWXMMSESuDRLtYEwpQ9STRS7jqX50DdWPjIBgZHa2XO5vRj7Ge9r2GmxZhmzRdWhwgiNR0gZ0UBzICNmd7cRHfzloXAuJgnBENjZ26lDOMB2GhMhDPjga7H4bQB7dFOG5jBba9cfPHF859osBqYb6wA0rqkM1+1l7ZvPZqv1oq+pF9pv/LNXQKkecZaQIhi2qdZZt7UfKkrZZw2H73Nd2uQYEZLxsuAtW0FigLrD3O1rQZ8hXVipK9yWDTMFyAtHWsaQZ477XRsgD7hlWGC0Z5NQkwA4wPIgBjgYnYYOk3YxMYAMBAacxY+5iwvcKFR0Zy910mLxPjjwiDWTeqAgLIxKQvLHidgtX9Mg029tVz5xCd/nvGBpX1BYGRPlzavnLRHGmFMzqKW1sLGGB1OA0Q0T4sbIAFnB03QAkiMgobytINwIq93ZQMIqbO2E4Ba8GiIYRAgbA/U06jyYR5x7lNW4lb5qSuCmL4BWH0zpsaaZrdE11qm+qWhnXmFy9e0ACsa0FKX2pN2xk9b3NsbJPTRbmi+hIfs6dWyALS5ZQ6iJ+0fEAN0QhyGac4SaIwRYItlRjnazGfdIXAZD2OzSad8fXPVtqcOcdaCthL2CEe+oQ0oaP7aDFQJruiJxuYY7c4arFtBtczUKy7jS8ik4eWsRqX5mDf3u+rXvqFFaC/eujfOBGvCL3rEwkeYo0xYy+Y/a0xcysx9LDAESgLh+DzpTqPfAL0Fo0rKBob25YAEgMo96RIzBNw0JQwGo65gEQ2HNsAMCdgxiAB5upiJXRdSnsVPGj4NAOMFqA4RAZO6l5vFuKq8PMf0MT8mKibO+j5m6uVLT/CwCAEWiZmJkbbptRfmVZYFwEATAg40PsCOOXJpv3AAgdYXk3qex5eOZqQsZsy8asPkRiOqFoa5gne0M+Fz+eoJfYSNG8EJKLB0+JawU8OYz+hqvtAGyDitbD/PmQCabTQ1aeJqOHHV9xwQaYOTzADa3AtA17TGA5gzLTL3ErJyaA7TNdcwWq8PYbb6UgXDCB7mJaGijket5yjCqVt/ha01fWFetX1ibhEYCKCsVIRCz6w5AiVrhbUYjS1tVF5oHF/55qE5DJzQoK7TpFNGDafM0+JnzqMD5cGFF6EHwQ1YmyPWAd5lrYe+dV2GRmhqXtKws87RqqY9LbQb+9EAPVLkBO4xDZMUINCkTURaIXMOUCPFk+iBcxhfFoHmYjhMccyyAJ02AJBoqcx3GLELSDJxS09TwHjUzWUxxBcnDY2VtudVI4yrAsm5FoiyXMAvfbH/SmvRluSvdc6NecePhUxDlIdJEkg7XZt213wJ1zLRzMf7gZnwKgeACEW0RAeCgGbdI1V2ysVwK5NYVeYYL3/aiB40CwKVvW6mPuPD1bpyn3yYmHnCZOhUvT9qsJ9qzhBSqpOnlpUyahp1AiUma/PMGAGW0QEeNAJWQBhIxzSJwZonvuzlUmaAKXXGNwbGwqloQlZoOta3n3tlp/wx31K8OMye9YWpmwBIaLQ3al7qHyuAeUfYQNuUw6/h1Je4CAPiExe/xo3hlLPLfu1npUPC1k1No6/nGv+smTFf6LQqPs9Pg98AvQWjaCIyc2OyABM4O1Bkf5W2RBMEzp5ViTxNt6fM/GyfmHZDMwAymI9TpZiwa+mQWA7zZLLXRQPMmcy9Jyo/AKOtxSVPvZc/CyvxtFzaGa0RM8wHBpKf70q+xKMDU71DTP7QgKaHFlVjTh3JU++BYP5qECAsOQwE6NGeabKEHJYCgD2WOeYP8xnj6/1SGgBG6wS0PlRhX1Zb1Zf08WtZtBBjTVt1aI+5mJUBPXKyvKav4TquynZPSIp1xNgAYABd+5200tN4WDBo3fbpY14nzIhnbUE3mlMtQzvc+/oZDdplPMY0tb37CStH+3K5r1fi+Zw+6Sftn0Bh+0PfCbQEUHOc4AGcWVBqO1NG4nJf2+vZqvikS/7c76qffsbXjxpe6mfipMPP+ImTXzj38UOfMW3iT6vfAL1FI4ux0Z4xYadivYaDedCsMfUwyzDATF5MhkbDXGd/0J4irQwg2zcE1nzMmJYgrT0ge2yYVHXqSLlAlfasXCBJWACaeS6fcK5aTg1jhhi3g0RMiUAQOKxyWYT2pewD2wOnCTM/swwAoyVBRXnJS5ixJeBLW0yYgD0u7Y+PBsDF3r1+MvcCUK7WI33KT1l78eXhQlv3tDh90y9ChBPA2hztXNrqtIPmDdi8xkMTpe0DlpTNT59q3vpcOO0xJuaCV5+ALdpqV8qIn7JYNJh9nQcA0KwrrDVM17ZWMj+SPvTSF2NGmMh4yHPULu1Pf3PPj0BT6Zz2Jl3al/zukz5+TbOUb4yr6RM+rT66habpY6Vl4vhJm7iRvmM54/PkO21+A/QWjGgmrf0ZL+w7lML8Zh80+4uaCZiZGl1hMOJpNpgmRgt4ATtAohHQgvMRAGFgjjHTFICtMqurC4VWB5z93y1QwMCBRAWtmncprDwaHgsAgcAJXlp0gCUMLDSoZciD8XtNyneZadE0XYdGAmQ1n7Jc2gfcpVUfzZtFIi51Jj360ZoJMg6HsVzUQyvJd1A/9cmfOo2fNtGeHbzyug8ArHvemFAdD6Z99GAtQQt78tUUn/L5IwNLG0Iv90zT5gvriIOITLrGl6v1CrtYGgiO9mkJeiw0zNrM7OabOZUtmNoW408bNZ8JFcbD3GrXFGgKrKdAA/R6+hzLU8wa6GK2gBnTtO/stC8Q9ZxmA7Boexh1TG8Yp9d05HMq0itIGGa+elTBFFOWHvMOUIwgoMPy0OYAlXdFb3/728/twdCXGPC5iKQ8WjQTJ3M5Tdh+pD1V7YkDupg5WrAaECiYgWn/vuhE23RQifkRXfJaRvLz9UvbCSG0PWDAkjACWdLyWSyY8u2zAyptc7BFWZtwtZyE0cSpae1zItthLwfw9D1pat3iCGs0XYKEvWsHtdDIs9Ax/lhG7utzVgJWDZYDe6/299E1Tp7kEwe8acz2zllpbKcQDJ30d67BHDWGyRPfOJk7xs55glXjkXrbbwo0Bd5OgQboE54JGCbwwuAwS9oiJkaT8z6lPWLPaZxMosCDFkyLjPOcluygD20IoNF0ADeGv8qFgXqesPYAYcIAre6iiy6aDyMB66q5ripzKZ4QAIxpjPrGzK0vOYEd0JCGpgWoaHMsAbQuoCSPy0E1cUzCzOQB6ZShfuCKdvZFWRWYyAF2nL6mv+JYGpj/AQ5TN+BE05omeQ/iL5UjjtDA3G9bIu+CVhOzupJX/whdABGoEyZor/VMgPQRyORL3lpO4visBMbV3jvTvvLMmVH7ll/9LDy2XAgxNH+nsQk2xoPQmHwZi9QlH+FM+bR+BxqNcdIpv11ToClwNgUaoM+mybHH0Frs39GAnSYFFN4ptRfKTOuiYdEIAQ+TrANDHCZHawFsmCCtCtMHZEzl9TQ3QAPuAIlGo97RpArQvcJEe2f29f1tB5mAJe2dwLAfoK5MGFP23q1DbMCf9heApTkz8QJm1gCg7FAaULeXnA9qOPSGToQRe5qY/+iU47U0NAQg2VNOWwBHwIOPJgQbwoPDUvV94LHsg9ynrjGvcVAvwE29BIPq5CW4eA+XUCO9d3gJcqwlANOYZMsDQKe++Mqr4ZRvrAkJrBS0WiBtjJI2ftLnsJ9Dat7htv0B3I1RFSwC1Mmv7cYSMBt/faW953nKb78p0BS4LgUaoK9LjxO5AyhACbj6brQDOBim11/sT/pEnj0/TI4mGIDE4FyABxOnxQBwmjjGyXRpv9JeofyYO98pXCZNAM6UHEaJYdtHpFUBQaZoJm77nQ4T2f8ECNkrDeCtI1rKlgZTBpz2s/NBC+BCSAD+9qgBj31KgMwKwJxNq2N+1Qb0oL0RHphbl/aKmayBs/etacT2R2nV1aXtfIICugSgWSuA0aZcpUENB6DVS4MmGBBYuJrOGKEFmtC2HbSyVcDUzUpgzEOHmm9V+5MmhxIJduiuPEJcnlegFQ5Aq9PcdICQkEQ4JCRWmqZuAoM5a7zQ2Hg4IDaOR9K33xRoCryTAg3Q76TFiYQwNQyYmZBWSFMFhADUSWxghCkzbdIu6x5hbTCmSgvFqL3Pqgx/qACMA8zMuMzfBADlA0R1x9HeaOeAj3YGEIG79BisPUTvjwJodYUhJ/+SX5k9MAZ+NDZts89OIABKwJulABNnBqVlEQYwcs9tAbAgoAmzNUavLWH06gEGLAsOIBFMpKV1KrvunWtn2sWvGjSgtF1AI9yUS13KqzSLab0CdNVEU38A2pjRclkRWAbMCQKPbQ+03atLe7RFmIBCmDPW6KU+Al910sVKwzpjbjgrQYBKeaOvfOcBALJ5R2DyBxT1DEWto8NNgabAdSnQAH1dehz7HSYG7JgBaYqYIxAGXLQZWhXAYHoEvtJihGGGNJc4ZUUrUp4yMF9AAIQSdg+I1VOBC8DRopmNPaf5aAPf/ictFyACwVpv6l/ytSlO+YQAGi1rAeBnHgUuQBgAMLmq096qOKZbfQZcTO/aTgAButqSdqiHZUFbCR7KJ1QoS3tzWj10S5v4ygQe0aDRW92bcrXOSg/1EkiqiZuWWtNrg7abF+YA64B8BBbjiybol/5Jr46xDPE1LmFpnTdwsBDwEhJtb6gvZc2BaZrH39aEr2zxCUjGjEt5yePeeJjTGQ+nv9GWxcS41Typo/2mQFPgnRRogH4nLbYmhHExKfIDQJWZCdd7DR/j8jx+mHZNBzDjajpx1bw5pnGf9Hm2zq91Ctv/dgiOGd2HSKJFa2PqrW1L2Z5z/ITdy4NOXgOi/dPQHWRa9Q3lsTyAd1yHxCrdAtDMxSwG46c2pQ090mZ+LWPpvqatYTRL3vieE5q0Bb2AtC0SggCANQ6EOMIZTd3WCcsHSwjBgPDEjeOh3TRl42FrxpaG8sW1awo0BfZGgQbovdGpU22IAhg57ZRmy6zPVM0cT4vjKojstUrgTCtjJVCeA2bM3MDAM2BRAWksFzjZBqBBy7/pU9zqC9AGyLQHDWjQ3gsHerTLHBJLurGtm75XDxrF+mCLxaE6p+RpvywqrDG2N2xLoK0DjSwcaJ5+VfoKy8dioyx71saDAKWedk2BpsDeKNAAvTc6daoDUmAJcMUxT9OcgbN9SSCAsYfR8/cKUgCGGZvZl6lWeQF8ALJUTq3HPioQYYKl0TPnK2+TLm2Ir2wgR9N3aE6bmbA3aVrfa/u1ycVcTTN2at7+P0HFloF9aYfuHGAE1AQaAFxd6InetG5AbHwd7mPiHjXnpK9ldLgp0BS4LgUaoK9Lj747JgrYW8771sC57qFqwl4BWjoArTzgBpjtreeQ0xIQiEs8YNIO2iJgBlIONikvaQ5LkrG+lAfECAeA2b6/e/XGRTvN/VH56Sdg1X/0s7cNpGnA3iP3VoFtCfvO6Cxt8tV2oad4bXduwNjWQ2cRBpby1nI63BRoCkxTA3TPgiOlAEa8dIWRq7wya/GbcvsFuLEd9f4wbVrVp9Clll3rXJWvpt9EuNaDZnnv2mE+Xw1zwtt3t2PpkL6281xhz5UrX61rE23vMpoCp5kCDdCneXS3pG8YdGXitVmV2VcGvip9zbsUrmUsPR/jAh6JD4ActP6UU/2UuRSXZ/HVu8m6a51L4dRbn2W7wGt9tgwc7rI/ThO27zy62l7l1TJp2qtcTbcqTcc3Bc5nCjRAn8+jf0J9ryBUmXttTk1T48cwJl/LEB7j5KlpahniV2naq/LU/HsJK2csawSnVW3YS/mHSVPbkTbaX/aanVPlrvEb7OpborH49DXlpsz6LHFJc5j2d96mwGmmQAP0aR7dLehbZeRh3mOzanwNj+nW3S/lCwAsPRvLShp5ar4x3UHvlR+3FA5Ap+6kPS4//VeffXAg7US5P8gQzp6z9tX2Sz/e1zZ7ljxjuvG+5utwU6Ap0HvQPQeOmAIBnqVqwqAx8ApMiV/KM8ZJu5/0NX+tt5ZRwzX9QcIpq/q1rykzzx1420anfWljbZ+49MdYJ424Gk6epM2zxLffFGgKnE2B1qDPpknHNAWaAk2BpkBT4MQp0AB94kPQDWgKNAWaAk2BpsDZFGiAPpsmHdMUaAo0BZoCTYETp0AD9IkPQTegKdAUaAo0BZoCZ1OgAfpsmnRMU6Ap0BRoCjQFTpwCDdAnPgTdgKZAU6Ap0BRoCpxNgQbos2nSMU2BpkBToCnQFDhxCjRAn/gQdAOaAk2BpkBToClwNgUaoM+mScc0BZoCTYGmQFPgxCnQAH3iQ9ANaAo0BZoCTYGmwNkUaIA+myYd0xRoCjQFmgJNgROnQAP0iQ9BN6Ap0BRoCjQFmgJnU6AB+myadExToCnQFGgKNAVOnAIN0Cc+BN2ApkBToCnQFGgKnE2B/wcGWRwOwrNzSgAAAABJRU5ErkJggg==)\n",
        "\n",
        "z:the common neighbor of x and y\n",
        "\n",
        "w_xz:the sim of x and z\n",
        "\n",
        "w_yz:the sim of y and z\n",
        "\n",
        "s_z:denotes the strength of node z, namely the sum of weights of its associated links"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WRSLluj4bIT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "665cc8a5-fb53-4fe4-d8c9-5a6957f2ec06"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from collections import defaultdict  \n",
        "import math  \n",
        "import json\n",
        "from sys import stdout\n",
        "import pickle\n",
        "import multitasking\n",
        "import signal\n",
        "\n",
        "multitasking.set_max_threads(10)\n",
        "multitasking.set_engine('process')\n",
        "signal.signal(signal.SIGINT, multitasking.killall)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function _signal.default_int_handler>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oDtulxXMuSg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_qtime = pd.read_pickle('kdd2020_data/recall/qtime.pkl')\n",
        "df_click = pd.read_pickle('kdd2020_data/recall/click.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv8WLmfVMz6t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "959495d7-2bae-4fed-a4cd-3d77540a1f51"
      },
      "source": [
        "phases = sorted(list(df_qtime['phase'].unique()))\n",
        "phases"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOh42okdzpR9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "26d02b66-1bc3-47c1-ff1c-18133052ba27"
      },
      "source": [
        "#RA、AA\n",
        "\n",
        "input_path = 'kdd2020_data/my_model/recall_5/'\n",
        "out_path = 'kdd2020_data/my_model/recall_10/'\n",
        "\n",
        "for num in range(len(phases)):\n",
        "    os.makedirs('kdd2020_data/my_model/recall_10/', exist_ok=True)\n",
        "    \n",
        "    # 获取itemCF相似度\n",
        "    with open(input_path+'sim_'+str(num)+'.pkl','rb') as f:\n",
        "        item_sim_dir= pickle.load(f)  \n",
        "    \n",
        "    item_sim = {}\n",
        "    for item in item_sim_dir.keys():\n",
        "        item_sim.setdefault(item, {})\n",
        "        for related_item in item_sim_dir[item].keys():\n",
        "            if item_sim_dir[item][related_item] > 0.005:\n",
        "                item_sim[item][related_item] = item_sim_dir[item][related_item]\n",
        "        \n",
        "    strengh_dict = dict()\n",
        "    print('Counting degree')\n",
        "    for item in tqdm(item_sim):\n",
        "        strengh_dict[item] = sum(item_sim[item].values())       \n",
        "        \n",
        "    strengh_AA_dict = dict()\n",
        "    print('Counting degree')\n",
        "    for item in tqdm(item_sim):\n",
        "        strengh_AA_dict[item] = math.log(1+sum(item_sim[item].values()) )\n",
        "        \n",
        "        \n",
        "    #RA\n",
        "    RA_sim = dict()\n",
        "    for item in tqdm(item_sim):\n",
        "        neighbors = list(set(item_sim[item].keys()))\n",
        "        for item1 in neighbors:\n",
        "            if item in item_sim[item1]:\n",
        "                RA_sim.setdefault(item1, {})\n",
        "                for item2 in neighbors:\n",
        "                    if item1 != item2:\n",
        "                        RA_sim[item1].setdefault(item2, 0)\n",
        "                        RA_sim[item1][item2] += item_sim[item1][item] * item_sim[item][item2]/strengh_dict[item]\n",
        "    \n",
        "    \n",
        "    new_RA = dict()\n",
        "    for item1 in tqdm(RA_sim):\n",
        "        new_RA[item1] = {i: int(x * 1e3) / 1e3 for i, x in RA_sim[item1].items() if x > 1e-3}\n",
        "    \n",
        "  \n",
        "    print('Saving')\n",
        "    write_file = open(out_path+'RA_P'+str(num)+'_new.pkl', 'wb')\n",
        "    pickle.dump(new_RA, write_file)\n",
        "    write_file.close() \n",
        "        \n",
        "    #AA\n",
        "    AA_sim = dict()\n",
        "    for item in tqdm(item_sim):\n",
        "        neighbors = list(set(item_sim[item].keys()))\n",
        "        for item1 in neighbors:\n",
        "            if item in item_sim[item1]:\n",
        "                AA_sim.setdefault(item1, {})\n",
        "                for item2 in neighbors:\n",
        "                    if item1 != item2:\n",
        "                        AA_sim[item1].setdefault(item2, 0)\n",
        "                        AA_sim[item1][item2] += item_sim[item1][item] * item_sim[item][item2]/strengh_AA_dict[item]\n",
        "    \n",
        "    \n",
        "    new_AA = dict()\n",
        "    for item1 in tqdm(AA_sim):\n",
        "        new_AA[item1] = {i: int(x * 1e3) / 1e3 for i, x in AA_sim[item1].items() if x > 1e-3}\n",
        "    \n",
        "   \n",
        "    print('Saving')\n",
        "    write_file = open(out_path+'AA_P'+str(num)+'_new.pkl', 'wb')\n",
        "    pickle.dump(new_AA, write_file)\n",
        "    write_file.close()  \n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40768/40768 [00:00<00:00, 565796.71it/s]\n",
            "100%|██████████| 40768/40768 [00:00<00:00, 447230.95it/s]\n",
            "  0%|          | 0/40768 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Counting degree\n",
            "Counting degree\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40768/40768 [00:01<00:00, 27321.90it/s]\n",
            "100%|██████████| 36487/36487 [00:00<00:00, 114822.13it/s]\n",
            "  8%|▊         | 3119/40768 [00:00<00:01, 31171.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saving\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40768/40768 [00:01<00:00, 26423.94it/s]\n",
            "100%|██████████| 36487/36487 [00:00<00:00, 111489.54it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saving\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 41400/41400 [00:00<00:00, 555179.94it/s]\n",
            "100%|██████████| 41400/41400 [00:00<00:00, 436370.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Counting degree\n",
            "Counting degree\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 41400/41400 [00:01<00:00, 25917.19it/s]\n",
            "100%|██████████| 37026/37026 [00:00<00:00, 115309.62it/s]\n",
            "  0%|          | 0/41400 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saving\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 41400/41400 [00:01<00:00, 25717.34it/s]\n",
            "100%|██████████| 37026/37026 [00:00<00:00, 109411.92it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saving\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 41024/41024 [00:00<00:00, 563186.94it/s]\n",
            "100%|██████████| 41024/41024 [00:00<00:00, 442556.07it/s]\n",
            "  0%|          | 0/41024 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Counting degree\n",
            "Counting degree\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 41024/41024 [00:01<00:00, 26353.37it/s]\n",
            "100%|██████████| 36558/36558 [00:00<00:00, 113070.92it/s]\n",
            "  0%|          | 0/41024 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saving\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 41024/41024 [00:01<00:00, 25420.91it/s]\n",
            "100%|██████████| 36558/36558 [00:00<00:00, 108060.73it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saving\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Wcaa6J3SzpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rec10(df_click_phase,df_qtime, sim_dict):\n",
        "  user_item_ = df_click_phase.groupby('user_id')['item_id'].agg(lambda x: list(x)).reset_index()\n",
        "  user_item_dict = dict(zip(user_item_['user_id'], user_item_['item_id']))\n",
        "  \n",
        "  data_list = []\n",
        "  qtime_dict = dict(zip(df_qtime['user_id'], df_qtime['query_time']))\n",
        "\n",
        "  for user_id, query_time, item_id, phase in tqdm(df_qtime.values):\n",
        "        rank = {}\n",
        "        for item in user_item_dict[user_id]:\n",
        "            if item not in sim_dict.keys():\n",
        "              continue\n",
        "            for i in sim_dict[item].keys():\n",
        "              if i in user_item_dict[user_id]:\n",
        "                    continue\n",
        "              if i not in rank.keys():\n",
        "                    rank[i] = 0\n",
        "              rank[i] += sim_dict[item][i]\n",
        "        sim_items = sorted(rank.items(), key=lambda d: d[1],reverse=True)[:100]\n",
        "        item_ids = [item[0] for item in sim_items]\n",
        "        item_sim_scores = [item[1] for item in sim_items]\n",
        "\n",
        "        df_temp = pd.DataFrame()\n",
        "        df_temp['item_id'] = item_ids\n",
        "        df_temp['sim_score'] = item_sim_scores\n",
        "        df_temp['user_id'] = user_id\n",
        "        df_temp['query_time'] = query_time\n",
        "        df_temp['phase'] = phase\n",
        "\n",
        "        if item_id == -1:\n",
        "            df_temp['label'] = np.nan\n",
        "        else:\n",
        "            df_temp['label'] = 0\n",
        "            df_temp.loc[df_temp['item_id'] == item_id, 'label'] = 1\n",
        "\n",
        "        df_temp.sort_values(['sim_score'], inplace=True, ascending=False)\n",
        "        df_temp = df_temp[[\n",
        "            'user_id', 'phase', 'query_time', 'item_id', 'sim_score', 'label'\n",
        "        ]]\n",
        "        df_temp['user_id'] = df_temp['user_id'].astype('int')\n",
        "        df_temp['item_id'] = df_temp['item_id'].astype('int')\n",
        "\n",
        "        data_list.append(df_temp)\n",
        "\n",
        "  df_data = pd.concat(data_list, sort=False)\n",
        "  return df_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5R_nze0TNl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@multitasking.task\n",
        "#recall depend on phase\n",
        "def work(phase, force=False):\n",
        "    df_click_phase = df_click[df_click['phase'] == phase]\n",
        "    f = open('kdd2020_data/my_model/recall_10/AA_P{}_new.pkl'.format(phase), 'rb')\n",
        "    sim_dir= pickle.load(f)\n",
        "    f.close()\n",
        "    df_qtime_phase = df_qtime[df_qtime['phase'] == phase]\n",
        "    df_data = rec10(df_click_phase,df_qtime_phase, sim_dir)\n",
        "    df_data.to_pickle('kdd2020_data/my_model/recall_10/recall_{}.pkl'.format(phase))\n",
        "    print('phase {} finish'.format(phase))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjZ20sGgYV3I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "896199d0-dd79-4151-fd27-1e04d040ada8"
      },
      "source": [
        "force = False\n",
        "for phase in phases:\n",
        "    work(phase, force)\n",
        "    \n",
        "multitasking.wait_for_tasks()\n",
        "print('over')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18398/18398 [03:05<00:00, 99.07it/s] \n",
            "100%|██████████| 18505/18505 [03:05<00:00, 99.50it/s] \n",
            "100%|██████████| 18672/18672 [03:07<00:00, 99.81it/s] \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "phase 1 finish\n",
            "phase 2 finish\n",
            "phase 0 finish\n",
            "over\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDON00sEYiho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(df, median_item_degree, item_degree_map, num_cases_full, num_cases_half):\n",
        "    gg = df.groupby(['user_id'])\n",
        "\n",
        "    ndcg_50_full = 0.0\n",
        "    hitrate_50_full = 0.0\n",
        "\n",
        "    ndcg_50_half = 0.0\n",
        "    hitrate_50_half = 0.0\n",
        "\n",
        "    for _, g in tqdm(gg):\n",
        "        try:\n",
        "            item_id = g[g['label'] == 1]['item_id'].values[0]\n",
        "            item_degree = item_degree_map[item_id]\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "        predictions = g['item_id'].values.tolist()\n",
        "\n",
        "        rank = 0\n",
        "        while rank < 50 and predictions[rank] != item_id:\n",
        "            rank += 1\n",
        "\n",
        "        if rank < 50:\n",
        "            ndcg_50_full += 1.0 / np.log2(rank + 2.0)\n",
        "            hitrate_50_full += 1.0\n",
        "\n",
        "        if item_degree <= median_item_degree:\n",
        "            if rank < 50:\n",
        "                ndcg_50_half += 1.0 / np.log2(rank + 2.0)\n",
        "                hitrate_50_half += 1.0\n",
        "\n",
        "    ndcg_50_full /= num_cases_full\n",
        "    hitrate_50_full /= num_cases_full\n",
        "\n",
        "    ndcg_50_half /= num_cases_half\n",
        "    hitrate_50_half /= num_cases_half\n",
        "\n",
        "    return ndcg_50_full, hitrate_50_full, ndcg_50_half, hitrate_50_half"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9E6OUw3YrlV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_scores(df, phase):\n",
        "    df_qtime = pd.read_pickle('kdd2020_data/recall/qtime.pkl')\n",
        "    df_click = pd.read_pickle('kdd2020_data/recall/click.pkl')\n",
        "    \n",
        "    df_qtime = df_qtime[df_qtime['phase']==phase]\n",
        "    df_click = df_click[df_click['phase']==phase]\n",
        "    \n",
        "    #filter traindata\n",
        "    oof_answer = df_qtime[df_qtime['item_id'] != -1]\n",
        "    num_cases_full = oof_answer.shape[0]\n",
        "\n",
        "    answer_items = oof_answer['item_id'].values\n",
        "    item_degree = df_click['item_id'].value_counts().reset_index()\n",
        "    item_degree.columns = ['item_id', 'degree']\n",
        "\n",
        "    answer_item_degree = item_degree[item_degree['item_id'].isin(answer_items)]\n",
        "    list_item_degress = answer_item_degree['degree'].values.tolist()\n",
        "    median_item_degree = list_item_degress[len(list_item_degress) // 2]\n",
        "    item_degree_map = dict(zip(item_degree['item_id'], item_degree['degree']))\n",
        "    num_cases_half = answer_item_degree[answer_item_degree['degree']<= median_item_degree].shape[0]\n",
        "\n",
        "    ndcg_50_full, hitrate_50_full, ndcg_50_half, hitrate_50_half = evaluate(\n",
        "        df, median_item_degree, item_degree_map, num_cases_full, num_cases_half)\n",
        "    return ndcg_50_full, hitrate_50_full, ndcg_50_half, hitrate_50_half"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_YOUJXTZQsn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "aa111835-3464-4f0d-f287-ed122cc32746"
      },
      "source": [
        "item_sim_phase = {}\n",
        "df_recall = pd.DataFrame()\n",
        "val_score = np.array([0.0, 0.0, 0.0, 0.0])\n",
        "for phase in phases:\n",
        "    f = open('kdd2020_data/my_model/recall_10/AA_P{}_new.pkl'.format(phase), 'rb')\n",
        "    item_sim = pickle.load(f)\n",
        "    f.close()\n",
        "    df_data = pd.read_pickle('kdd2020_data/my_model/recall_10/recall_{}.pkl'.format(phase))\n",
        "    item_sim_phase[phase] = item_sim\n",
        "    df_recall = df_recall.append(df_data)\n",
        "    score = evaluate_scores(df_data, phase)\n",
        "    val_score += score\n",
        "    print('phase', phase, score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18422/18422 [00:16<00:00, 1115.93it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "phase 0 (0.033125216834393255, 0.08734117088231802, 0.03570359614246794, 0.09271997707079392)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18583/18583 [00:16<00:00, 1098.59it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "phase 1 (0.03440295633171705, 0.08639206892482001, 0.03717244407734193, 0.0901509705248023)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18316/18316 [00:16<00:00, 1094.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "phase 2 (0.03408970818197, 0.08893943021307159, 0.035767263456387095, 0.09156804733727811)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf7bn6N5ZVCQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a86baa21-abb2-41c4-abec-d1169d61dcbd"
      },
      "source": [
        "f = open('kdd2020_data/my_model/sim10.pkl', 'wb')\n",
        "pickle.dump(item_sim_phase, f)\n",
        "f.close()\n",
        "val_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.10161788, 0.26267267, 0.1086433 , 0.27443899])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gQ3Xx6AZj95",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3d54a7b6-a035-4b7f-b007-ac38c7d9826a"
      },
      "source": [
        "df_recall.sort_values(['user_id', 'phase', 'query_time'], inplace=True)\n",
        "df_recall.to_pickle('kdd2020_data/my_model/recall_10.pkl')\n",
        "df_recall.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>phase</th>\n",
              "      <th>query_time</th>\n",
              "      <th>item_id</th>\n",
              "      <th>sim_score</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.983942</td>\n",
              "      <td>95676</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.983942</td>\n",
              "      <td>103421</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.983942</td>\n",
              "      <td>46098</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.983942</td>\n",
              "      <td>68274</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.983942</td>\n",
              "      <td>102093</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  phase  query_time  item_id  sim_score  label\n",
              "0        1    0.0    0.983942    95676      0.004    0.0\n",
              "2        1    0.0    0.983942   103421      0.004    0.0\n",
              "3        1    0.0    0.983942    46098      0.004    0.0\n",
              "1        1    0.0    0.983942    68274      0.004    0.0\n",
              "4        1    0.0    0.983942   102093      0.003    0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oGEfEcrd7nO",
        "colab_type": "text"
      },
      "source": [
        "**more modes of common neighbors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fs6haTWBcWok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # CN、HPI、HDI、LHN1\n",
        "\n",
        "# input_path = 'kdd2020_data/my_model/recall_5/'\n",
        "# out_path = 'kdd2020_data/my_model/recall_10/'\n",
        "\n",
        "# for num in range(now_phase+1):\n",
        "    \n",
        "#     with open(input_path+'sim_'+str(num)+'.pkl','rb') as f:\n",
        "#         item_sim_list_tmp = pickle.load(f)  \n",
        "    \n",
        "#     item_sim = {}\n",
        "#     for item in item_sim_list_tmp:\n",
        "#         item_sim.setdefault(item, {})\n",
        "#         for related_item in item_sim_list_tmp[item]:\n",
        "#             if item_sim_list_tmp[item][related_item] > 0.005:\n",
        "#                 item_sim[item][related_item] = item_sim_list_tmp[item][related_item]\n",
        "    \n",
        "#     item_sim_list_tmp = []\n",
        "    \n",
        "#     #CN\n",
        "#     CN_sim = dict()\n",
        "#     for item in tqdm(item_sim):\n",
        "#         neighbors = list(set(item_sim[item].keys()))\n",
        "#         for item1 in neighbors:\n",
        "#             if item in item_sim[item1]:\n",
        "#                 CN_sim.setdefault(item1, {})\n",
        "#                 for item2 in neighbors:\n",
        "#                     if item1 != item2:\n",
        "#                         CN_sim[item1].setdefault(item2, 0)\n",
        "#                         CN_sim[item1][item2] += item_sim[item1][item] * item_sim[item][item2]\n",
        "    \n",
        "    \n",
        "#     new_CN = dict()\n",
        "#     for item1 in tqdm(CN_sim):\n",
        "#         new_CN[item1] = {i: int(x * 1e3) / 1e3 for i, x in CN_sim[item1].items() if x > 1e-3}\n",
        "    \n",
        "#     CN_sim = []\n",
        "#     print('Saving')\n",
        "#     write_file = open(out_path+'CN_P'+str(num)+'_new.pkl', 'wb')\n",
        "#     pickle.dump(new_CN, write_file)\n",
        "#     write_file.close() \n",
        "    \n",
        "#     strengh_dict = dict()\n",
        "#     print('Counting degree')\n",
        "#     for item in tqdm(item_sim):\n",
        "#         strengh_dict[item] = sum(item_sim[item].values())     \n",
        "    \n",
        "#     #HPI\n",
        "#     HPI_sim = dict()\n",
        "#     for item in tqdm(new_CN):\n",
        "#         HPI_sim.setdefault(item,{})\n",
        "#         for related_item in new_CN[item]:\n",
        "#             HPI_sim[item][related_item] = new_CN[item][related_item]/max(0.005,min(strengh_dict[item],strengh_dict[related_item]))     \n",
        "            \n",
        "#     print('Saving')\n",
        "#     write_file = open(out_path+'HPI_P'+str(num)+'_new.pkl', 'wb')\n",
        "#     pickle.dump(HPI_sim, write_file)\n",
        "#     write_file.close()\n",
        "    \n",
        "#     HPI_sim = []\n",
        "    \n",
        "    \n",
        "#     #HDI\n",
        "#     HDI_sim = dict()\n",
        "#     for item in tqdm(new_CN):\n",
        "#         HDI_sim.setdefault(item,{})\n",
        "#         for related_item in new_CN[item]:\n",
        "#             HDI_sim[item][related_item] = new_CN[item][related_item]/max(strengh_dict[item],strengh_dict[related_item])       \n",
        "            \n",
        "#     print('Saving')\n",
        "#     write_file = open(out_path+'HDI_P'+str(num)+'_new.pkl', 'wb')\n",
        "#     pickle.dump(HDI_sim, write_file)\n",
        "#     write_file.close()    \n",
        "#     HDI_sim = []\n",
        "    \n",
        "    \n",
        "    \n",
        "#     #LHN1\n",
        "#     LHN1_sim = dict()\n",
        "#     for item in tqdm(new_CN):\n",
        "#         LHN1_sim.setdefault(item,{})\n",
        "#         for related_item in new_CN[item]:\n",
        "#             LHN1_sim[item][related_item] = new_CN[item][related_item]/( max(0.005,strengh_dict[item]) * max(0.005,strengh_dict[related_item]))       \n",
        "            \n",
        "#     print('Saving')\n",
        "#     write_file = open(out_path+'LHN1_P'+str(num)+'_new.pkl', 'wb')\n",
        "#     pickle.dump(LHN1_sim, write_file)\n",
        "#     write_file.close()    \n",
        "#     LHN1_sim = []\n",
        "            \n",
        "#     new_CN = []\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IX6duvT5eoC5",
        "colab_type": "text"
      },
      "source": [
        "Above all,we have recalled 1000 items for everyone in every phase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9FXFas46fON",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing for rank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXBY_ZOCeSsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "import os\n",
        "import warnings\n",
        "from collections import defaultdict\n",
        "import math\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('precision', 10)\n",
        "\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OI68PZmfsj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#combine recall\n",
        "recall_1 = pd.read_pickle('kdd2020_data/my_model/recall_1.pkl')\n",
        "recall_2 = pd.read_pickle('kdd2020_data/my_model/recall_2.pkl')\n",
        "recall_3 = pd.read_pickle('kdd2020_data/my_model/recall_3.pkl')\n",
        "recall_4 = pd.read_pickle('kdd2020_data/my_model/recall_4.pkl')\n",
        "recall_5 = pd.read_pickle('kdd2020_data/my_model/recall_5.pkl')\n",
        "recall_6 = pd.read_pickle('kdd2020_data/my_model/recall_6.pkl')\n",
        "recall_7 = pd.read_pickle('kdd2020_data/my_model/recall_7.pkl')\n",
        "recall_8 = pd.read_pickle('kdd2020_data/my_model/recall_8.pkl')\n",
        "# recall_9 = pd.read_pickle('kdd2020_data/my_model/recall_9.pkl')\n",
        "recall_10 = pd.read_pickle('kdd2020_data/my_model/recall_10.pkl')\n",
        "\n",
        "recall_list = [recall_1, recall_2, recall_3, recall_4, recall_5, recall_6, recall_7, recall_8, recall_10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFGKpp3qgiRB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b3b80cce-3b8c-49e3-f231-bdcb38c20832"
      },
      "source": [
        "recall = pd.concat(recall_list, sort=False)\n",
        "recall['phase'] = recall['phase'].astype('int')\n",
        "del recall['sim_score']\n",
        "recall.sort_values(['user_id', 'phase'], inplace=True)\n",
        "print(recall.shape)\n",
        "#drop repeated recall\n",
        "recall.drop_duplicates(subset=['user_id', 'phase', 'item_id'], inplace=True)\n",
        "print(recall.shape)\n",
        "del recall_list,recall_1,recall_2,recall_3,recall_4,recall_5,recall_6,recall_7,recall_8,recall_10\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48702589, 5)\n",
            "(33965132, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "341"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xNb3402hFK_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d5c87dd9-9415-45a4-e871-b037bd87d4a1"
      },
      "source": [
        "phases = sorted(list(recall['phase'].unique()))\n",
        "phases"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns8NU9kphdPa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "281c2659-1d3c-4afb-dedc-514fdce89dc4"
      },
      "source": [
        "recall_hit_total = 0\n",
        "for phase in phases:\n",
        "    recall_phase = recall[recall['phase'] == phase]\n",
        "    recall_hit = recall_phase[recall_phase['label'] == 1]['user_id'].nunique() / \\\n",
        "        recall_phase[recall_phase['label'].notnull()]['user_id'].nunique()\n",
        "    recall_hit_total += recall_hit\n",
        "    print('phase', phase, 'recall hit', recall_hit)\n",
        "recall_hit_total"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "phase 0 recall hit 0.278232988956181\n",
            "phase 1 recall hit 0.2759353239702585\n",
            "phase 2 recall hit 0.285432128321762\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8396004412482014"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1rL2k7ihioM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "92979e13-0834-445a-e01e-982ea5b2e691"
      },
      "source": [
        "for phase in phases:\n",
        "    recall_phase = recall[recall['phase'] == phase]\n",
        "\n",
        "    test_user_num = recall_phase[recall_phase['label'].isnull()]['user_id'].nunique()\n",
        "    train_user_num = recall_phase[recall_phase['label'].notnull()]['user_id'].nunique()\n",
        "\n",
        "    print('phase', phase, 'train_user_num',train_user_num, 'test_user_num', test_user_num)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "phase 0 train_user_num 16842 test_user_num 1663\n",
            "phase 1 train_user_num 16946 test_user_num 1726\n",
            "phase 2 train_user_num 16708 test_user_num 1690\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pP0VN_IlhwjT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3e82d9b8-fae2-44cb-a6fd-b6a74d4d0ba9"
      },
      "source": [
        "recall.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>phase</th>\n",
              "      <th>query_time</th>\n",
              "      <th>item_id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>87837</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>92349</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>91290</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>38168</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.9839419315</td>\n",
              "      <td>13663</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  phase    query_time  item_id  label\n",
              "0        1      0  0.9839419315    87837    0.0\n",
              "1        1      0  0.9839419315    92349    0.0\n",
              "2        1      0  0.9839419315    91290    0.0\n",
              "3        1      0  0.9839419315    38168    0.0\n",
              "4        1      0  0.9839419315    13663    0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeIcQfvwh2oZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1b2f520e-aec3-43b1-c394-9a8ce3439b2a"
      },
      "source": [
        "# if all of the 1000 recall's label are 0,drop them.\n",
        "# this is every important, because we will use NN next.\n",
        "gg = recall.groupby(['user_id', 'phase'])\n",
        "useful_recall = []\n",
        "for (user_id, phase), g in tqdm(gg):\n",
        "    if g['label'].isnull().sum() > 0:\n",
        "        useful_recall.append(g)\n",
        "    else:\n",
        "        label_sum = g['label'].sum()\n",
        "        if label_sum > 1:\n",
        "            print('error', user_id)\n",
        "        elif label_sum == 1:\n",
        "            useful_recall.append(g)\n",
        "\n",
        "df_useful_recall = pd.concat(useful_recall, sort=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 55575/55575 [00:35<00:00, 1584.67it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVBQ3I3YivaB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "af4c2f89-faae-4925-dbce-7bfd9bee8887"
      },
      "source": [
        "for phase in phases:\n",
        "    recall_phase = df_useful_recall[df_useful_recall['phase'] == phase]\n",
        "\n",
        "    test_user_num = recall_phase[recall_phase['label'].isnull()]['user_id'].nunique()\n",
        "    train_user_num = recall_phase[recall_phase['label'].notnull()]['user_id'].nunique()\n",
        "\n",
        "    print('phase', phase, 'train_user_num',train_user_num, 'test_user_num', test_user_num)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "phase 0 train_user_num 4686 test_user_num 1663\n",
            "phase 1 train_user_num 4676 test_user_num 1726\n",
            "phase 2 train_user_num 4769 test_user_num 1690\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05kTSZqpi20g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_useful_recall.to_pickle('kdd2020_data/my_model/recall.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zIx6lkBjCyW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "73493ad6-1d82-44fa-d5ed-642736fb1adf"
      },
      "source": [
        "df_useful_recall.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>phase</th>\n",
              "      <th>query_time</th>\n",
              "      <th>item_id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9839420823</td>\n",
              "      <td>101060</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9839420823</td>\n",
              "      <td>102129</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9839420823</td>\n",
              "      <td>94147</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9839420823</td>\n",
              "      <td>92349</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9839420823</td>\n",
              "      <td>87837</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  phase    query_time  item_id  label\n",
              "0        1      1  0.9839420823   101060    NaN\n",
              "1        1      1  0.9839420823   102129    NaN\n",
              "2        1      1  0.9839420823    94147    NaN\n",
              "3        1      1  0.9839420823    92349    NaN\n",
              "4        1      1  0.9839420823    87837    NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZLsm52KjF_u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "12c67486-1631-4cf8-d8e6-377c867b5fa9"
      },
      "source": [
        "df_useful_recall.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11489051, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3aSMvvEjImh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5a43574b-ea04-43d7-e142-d19379019baf"
      },
      "source": [
        "for phase in phases:\n",
        "    recall_phase = df_useful_recall[df_useful_recall['phase'] == phase]\n",
        "    df = recall_phase['user_id'].value_counts().reset_index()\n",
        "    df.columns = ['user_id', 'cnt']\n",
        "    print('phase', phase, df['cnt'].mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "phase 0 597.7490943455663\n",
            "phase 1 596.8211496407373\n",
            "phase 2 599.6428239665582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkzY4HCnjLFp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27c93609-f4ea-43d8-d21c-593edd97efae"
      },
      "source": [
        "df_useful_recall[df_useful_recall['label'].notnull()].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8384744, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5iZbruHjNZe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2cdea94c-a369-4d29-daff-498a8d689344"
      },
      "source": [
        "df_useful_recall[df_useful_recall['label'].notnull()]['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    8370613\n",
              "1.0      14131\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rboSFhfw66yo",
        "colab_type": "text"
      },
      "source": [
        "# Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD8xrbJ6RKab",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a4cc5a32-d711-41e7-abe6-f6f296bd92bb"
      },
      "source": [
        "!pip install pandarallel"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandarallel in /usr/local/lib/python3.6/dist-packages (1.4.8)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from pandarallel) (0.3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BabJl6_rj3FG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6e7c8d2a-5b42-475f-b0bd-b08f4de411ca"
      },
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import GroupKFold\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import math\n",
        "from pandarallel import pandarallel\n",
        "import pickle\n",
        "from gensim.models import Word2Vec\n",
        "import os\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pandarallel.initialize()\n",
        "warnings.filterwarnings('ignore')\n",
        "seed = 2020"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO: Pandarallel will run on 4 workers.\n",
            "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XY5U-RLRIqK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "86f48d94-971d-4c08-c270-2e23678f9526"
      },
      "source": [
        "df_feature = pd.read_pickle('kdd2020_data/my_model/recall.pkl')\n",
        "print(df_feature.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11489051, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Itt2ditERro_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "207e289c-e69f-408a-bc75-5ddac7d3d8c3"
      },
      "source": [
        "phases = sorted(list(df_feature['phase'].unique()))\n",
        "phases"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGreyEslRuNu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_item = pd.read_csv('kdd2020_data/underexpose_train/underexpose_item_feat.csv', header=None)\n",
        "df_item.columns = ['item_id'] + ['txt_vec' +\n",
        "                                 str(i) for i in range(128)] + ['img_vec'+str(i) for i in range(128)]\n",
        "df_item['txt_vec0'] = df_item['txt_vec0'].apply(lambda x: float(x[1:]))\n",
        "df_item['txt_vec127'] = df_item['txt_vec127'].apply(lambda x: float(x[:-1]))\n",
        "df_item['img_vec0'] = df_item['img_vec0'].apply(lambda x: float(x[1:]))\n",
        "df_item['img_vec127'] = df_item['img_vec127'].apply(lambda x: float(x[:-1]))\n",
        "df_item.drop_duplicates(['item_id'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiMVQnoHR_gx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_user = pd.read_csv('kdd2020_data/underexpose_train/underexpose_user_feat.csv', header=None)\n",
        "df_user.columns = ['user_id', 'user_age_level','user_gender', 'user_city_level']\n",
        "\n",
        "gender_map = {'F': 0, 'M': 1}\n",
        "df_user['user_gender'] = df_user['user_gender'].map(gender_map)\n",
        "\n",
        "df_user.drop_duplicates(['user_id'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fRBx7qmSHcK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#merge click info and user info\n",
        "df_click = pd.read_pickle('kdd2020_data/recall/click.pkl')\n",
        "df_click = df_click.merge(df_user, how='left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udZYVXSaTWh5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "35694198-c24e-46fa-e1a6-b7e39df2fb02"
      },
      "source": [
        "print(df_click[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   user_id  item_id      time  phase  user_age_level  user_gender  \\\n",
            "0        1    78142  0.983742      0             NaN          NaN   \n",
            "1        1    26646  0.983757      0             NaN          NaN   \n",
            "2        1    89568  0.983763      0             NaN          NaN   \n",
            "3        1    76240  0.983770      0             NaN          NaN   \n",
            "4        1    87533  0.983790      0             NaN          NaN   \n",
            "\n",
            "   user_city_level  \n",
            "0              NaN  \n",
            "1              NaN  \n",
            "2              NaN  \n",
            "3              NaN  \n",
            "4              NaN  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3510JwhSb9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def group_func(df, group_func_dic, group_key):\n",
        "    if isinstance(group_func_dic, str):\n",
        "      group_func_dic = [group_func_dic]\n",
        "\n",
        "    features = df.groupby(group_key).agg(group_func_dic)\n",
        "    features.columns = ['_'.join(group_key) + '_' + e[0] + \"_\" + e[1]\n",
        "                        for e in features.columns.tolist()]\n",
        "    features.reset_index(inplace=True)\n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfPZfyMpYL2Z",
        "colab_type": "text"
      },
      "source": [
        "**item feature**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWhCr-dcSmnR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "210b85bc-deb7-4d06-c9df-806dc0778e5a"
      },
      "source": [
        "#pca item info\n",
        "from sklearn.decomposition import PCA\n",
        "dim = 10\n",
        "pca = PCA(n_components=dim, random_state=seed)\n",
        "df_txt_pca = pd.DataFrame(pca.fit_transform(df_item[['txt_vec' + str(i) for i in range(128)]]))\n",
        "df_txt_pca.columns = ['txt_vec{}_pca{}'.format(dim, i) for i in range(dim)]\n",
        "df_txt_pca['item_id'] = df_item[['item_id']]\n",
        "df_feature = df_feature.merge(df_txt_pca, how='left')\n",
        "\n",
        "pca = PCA(n_components=dim, random_state=seed)\n",
        "df_img_pca = pd.DataFrame(pca.fit_transform(\n",
        "    df_item[['img_vec' + str(i) for i in range(128)]]))\n",
        "df_img_pca.columns = ['img_vec{}_pca{}'.format(dim, i) for i in range(dim)]\n",
        "df_img_pca['item_id'] = df_item[['item_id']]\n",
        "df_feature = df_feature.merge(df_img_pca, how='left')\n",
        "print(df_feature.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['user_id', 'phase', 'query_time', 'item_id', 'label', 'txt_vec10_pca0',\n",
            "       'txt_vec10_pca1', 'txt_vec10_pca2', 'txt_vec10_pca3', 'txt_vec10_pca4',\n",
            "       'txt_vec10_pca5', 'txt_vec10_pca6', 'txt_vec10_pca7', 'txt_vec10_pca8',\n",
            "       'txt_vec10_pca9', 'img_vec10_pca0', 'img_vec10_pca1', 'img_vec10_pca2',\n",
            "       'img_vec10_pca3', 'img_vec10_pca4', 'img_vec10_pca5', 'img_vec10_pca6',\n",
            "       'img_vec10_pca7', 'img_vec10_pca8', 'img_vec10_pca9'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buEphgYFTLHa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d46ec62a-6dca-495a-f8b1-506c6c2f65b5"
      },
      "source": [
        "#item count\n",
        "df_tmp = df_click.groupby(['phase', 'item_id']).size().reset_index()\n",
        "df_tmp.columns = ['phase', 'item_id', 'phase_item_clickd_count']\n",
        "df_feature = df_feature.merge(df_tmp, how='left',on=['phase', 'item_id'])\n",
        "print(df_feature.shape)\n",
        "del df_tmp\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11489051, 26)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkFr7KkEUudE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b8180a59-3cee-478d-98a0-2d9738220074"
      },
      "source": [
        "# item time diff\n",
        "df_temp = df_click[['phase', 'item_id', 'time']].copy()\n",
        "df_temp.sort_values(['time'], inplace=True)\n",
        "df_temp['phase_item_click_time_diff'] = df_temp.groupby(['item_id', 'phase'])['time'].diff()\n",
        "df_temp = df_temp.groupby(['item_id','phase'])['phase_item_click_time_diff'].agg(phase_item_click_time_diff_mean='mean').reset_index()\n",
        "df_feature = df_feature.merge(df_temp, how='left',on=['item_id','phase'])\n",
        "print(df_feature.shape)\n",
        "del df_temp\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11489051, 27)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLhiUPrQWT0C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a964d2a1-3679-4a4d-f646-1cf124e6dd37"
      },
      "source": [
        "# user age\n",
        "group_func_dict = {'user_age_level': ['mean', 'min', 'max', 'std']}\n",
        "df_temp = group_func(df_click, group_func_dict, group_key=['item_id', 'phase'])\n",
        "df_feature = df_feature.merge(df_temp, how='left',on=['item_id', 'phase'])\n",
        "del df_temp\n",
        "gc.collect()\n",
        "print(df_feature.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11489051, 31)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EydScYp2VU3M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae08f7fd-895d-4afe-8e6e-b46679c7befc"
      },
      "source": [
        "#user gender\n",
        "df_temp = df_click.groupby(['item_id', 'phase'])['user_gender'].mean().reset_index()\n",
        "df_temp.columns = ['item_id', 'phase', 'phase_item_click_gender_mean']\n",
        "df_feature = df_feature.merge(df_temp, how='left',on=['item_id', 'phase'])\n",
        "del df_temp\n",
        "gc.collect()\n",
        "print(df_feature.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11489051, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MP2ozFp2YTc-",
        "colab_type": "text"
      },
      "source": [
        "**user feature**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpM6NbuvW7x7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62cc38fb-c0d3-41cf-a61e-a65e489cdaa5"
      },
      "source": [
        "df_feature = df_feature.merge(df_user, how='left')\n",
        "print(df_feature.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11489051, 35)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuv8y9ovXU97",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3fb44453-8561-4f48-ff65-5144588af226"
      },
      "source": [
        "df_tmp = df_click.groupby(['user_id', 'phase']).size().reset_index()\n",
        "df_tmp.columns = ['user_id', 'phase', 'phase_user_click_count']\n",
        "df_feature = df_feature.merge(df_tmp, how='left',on=['user_id', 'phase'])\n",
        "print(df_feature.shape)\n",
        "del df_tmp\n",
        "gc.collect()\n",
        "\n",
        "df_tmp = df_click.groupby(['phase', 'user_age_level']).size().reset_index()\n",
        "df_tmp.columns = ['phase', 'user_age_level','phase_user_age_level_click_count']\n",
        "df_feature = df_feature.merge(df_tmp, how='left',on=['phase', 'user_age_level'])\n",
        "print(df_feature.shape)\n",
        "del df_tmp\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11489051, 36)\n",
            "(11489051, 37)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GjX1s3mXsg8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b99ad716-9af1-4a31-fb64-adeb322b3627"
      },
      "source": [
        "group_func_dict = {'time': ['min', 'max', 'std']}\n",
        "df_temp = group_func(df_click, group_func_dict, group_key=['user_id', 'phase'])\n",
        "df_feature = df_feature.merge(df_temp, how='left',on=['user_id', 'phase'])\n",
        "print(df_feature.shape)\n",
        "del df_temp\n",
        "gc.collect()\n",
        "\n",
        "df_feature['user_id_phase_time_max_min_diff'] = df_feature['user_id_phase_time_max'] - \\\n",
        "    df_feature['user_id_phase_time_min']\n",
        "\n",
        "df_feature['user_id_phase_query_lastbuy_time_diff'] = df_feature['query_time'] - \\\n",
        "    df_feature['user_id_phase_time_max']\n",
        "print(df_feature.shape)\n",
        "\n",
        "del df_feature['user_id_phase_time_max'], df_feature['user_id_phase_time_min']\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11489051, 40)\n",
            "(11489051, 42)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIS_RDIFX_-I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "3e836acf-40e5-4b7f-ef5d-0bbc7fa34f2e"
      },
      "source": [
        "df_feature.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>phase</th>\n",
              "      <th>query_time</th>\n",
              "      <th>item_id</th>\n",
              "      <th>label</th>\n",
              "      <th>txt_vec10_pca0</th>\n",
              "      <th>txt_vec10_pca1</th>\n",
              "      <th>txt_vec10_pca2</th>\n",
              "      <th>txt_vec10_pca3</th>\n",
              "      <th>txt_vec10_pca4</th>\n",
              "      <th>txt_vec10_pca5</th>\n",
              "      <th>txt_vec10_pca6</th>\n",
              "      <th>txt_vec10_pca7</th>\n",
              "      <th>txt_vec10_pca8</th>\n",
              "      <th>txt_vec10_pca9</th>\n",
              "      <th>img_vec10_pca0</th>\n",
              "      <th>img_vec10_pca1</th>\n",
              "      <th>img_vec10_pca2</th>\n",
              "      <th>img_vec10_pca3</th>\n",
              "      <th>img_vec10_pca4</th>\n",
              "      <th>img_vec10_pca5</th>\n",
              "      <th>img_vec10_pca6</th>\n",
              "      <th>img_vec10_pca7</th>\n",
              "      <th>img_vec10_pca8</th>\n",
              "      <th>img_vec10_pca9</th>\n",
              "      <th>phase_item_clickd_count</th>\n",
              "      <th>phase_item_click_time_diff_mean</th>\n",
              "      <th>item_id_phase_user_age_level_mean</th>\n",
              "      <th>item_id_phase_user_age_level_min</th>\n",
              "      <th>item_id_phase_user_age_level_max</th>\n",
              "      <th>item_id_phase_user_age_level_std</th>\n",
              "      <th>phase_item_click_gender_mean</th>\n",
              "      <th>user_age_level</th>\n",
              "      <th>user_gender</th>\n",
              "      <th>user_city_level</th>\n",
              "      <th>phase_user_click_count</th>\n",
              "      <th>phase_user_age_level_click_count</th>\n",
              "      <th>user_id_phase_time_std</th>\n",
              "      <th>user_id_phase_time_max_min_diff</th>\n",
              "      <th>user_id_phase_query_lastbuy_time_diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.983942</td>\n",
              "      <td>101060</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.033200</td>\n",
              "      <td>6.758050</td>\n",
              "      <td>2.445827</td>\n",
              "      <td>-0.980435</td>\n",
              "      <td>-5.504060</td>\n",
              "      <td>-3.220289</td>\n",
              "      <td>3.175805</td>\n",
              "      <td>-3.443489</td>\n",
              "      <td>-3.544041</td>\n",
              "      <td>-1.404752</td>\n",
              "      <td>-1.080519</td>\n",
              "      <td>10.324701</td>\n",
              "      <td>0.737499</td>\n",
              "      <td>-5.772706</td>\n",
              "      <td>-5.054800</td>\n",
              "      <td>0.035968</td>\n",
              "      <td>3.500112</td>\n",
              "      <td>-4.218156</td>\n",
              "      <td>3.957114</td>\n",
              "      <td>2.160977</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>3.571429</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.133893</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>0.000094</td>\n",
              "      <td>1.507822e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.983942</td>\n",
              "      <td>102129</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-2.176809</td>\n",
              "      <td>4.566637</td>\n",
              "      <td>15.910588</td>\n",
              "      <td>-1.040885</td>\n",
              "      <td>-4.075056</td>\n",
              "      <td>4.052314</td>\n",
              "      <td>-4.776940</td>\n",
              "      <td>6.171880</td>\n",
              "      <td>1.471331</td>\n",
              "      <td>-0.046035</td>\n",
              "      <td>-3.046730</td>\n",
              "      <td>2.478535</td>\n",
              "      <td>-0.859532</td>\n",
              "      <td>-6.448319</td>\n",
              "      <td>2.800530</td>\n",
              "      <td>8.910352</td>\n",
              "      <td>-3.699516</td>\n",
              "      <td>-3.066158</td>\n",
              "      <td>-2.527535</td>\n",
              "      <td>-2.049918</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>5.400000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.673320</td>\n",
              "      <td>0.20</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>0.000094</td>\n",
              "      <td>1.507822e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.983942</td>\n",
              "      <td>94147</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-9.188668</td>\n",
              "      <td>4.911909</td>\n",
              "      <td>3.100944</td>\n",
              "      <td>-5.318312</td>\n",
              "      <td>-2.562280</td>\n",
              "      <td>3.399558</td>\n",
              "      <td>0.779980</td>\n",
              "      <td>1.643967</td>\n",
              "      <td>-1.772803</td>\n",
              "      <td>-0.462451</td>\n",
              "      <td>-7.283262</td>\n",
              "      <td>1.301522</td>\n",
              "      <td>-3.056460</td>\n",
              "      <td>3.009867</td>\n",
              "      <td>1.882195</td>\n",
              "      <td>3.896656</td>\n",
              "      <td>-1.854984</td>\n",
              "      <td>8.029745</td>\n",
              "      <td>3.014313</td>\n",
              "      <td>2.492163</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.000039</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>0.000094</td>\n",
              "      <td>1.507822e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.983942</td>\n",
              "      <td>92349</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-4.942613</td>\n",
              "      <td>-4.970490</td>\n",
              "      <td>-4.758204</td>\n",
              "      <td>3.637302</td>\n",
              "      <td>-6.427946</td>\n",
              "      <td>-8.612261</td>\n",
              "      <td>-3.010530</td>\n",
              "      <td>-7.108364</td>\n",
              "      <td>2.320725</td>\n",
              "      <td>4.182026</td>\n",
              "      <td>0.793652</td>\n",
              "      <td>1.767247</td>\n",
              "      <td>4.539776</td>\n",
              "      <td>-7.067767</td>\n",
              "      <td>-6.766804</td>\n",
              "      <td>2.061429</td>\n",
              "      <td>0.491690</td>\n",
              "      <td>-5.229865</td>\n",
              "      <td>-1.015263</td>\n",
              "      <td>0.370548</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.816497</td>\n",
              "      <td>0.25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>0.000094</td>\n",
              "      <td>1.507822e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.983942</td>\n",
              "      <td>87837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-13.042260</td>\n",
              "      <td>9.058986</td>\n",
              "      <td>-6.033150</td>\n",
              "      <td>-3.498339</td>\n",
              "      <td>-6.060202</td>\n",
              "      <td>-6.887897</td>\n",
              "      <td>-4.746740</td>\n",
              "      <td>-1.703656</td>\n",
              "      <td>2.524373</td>\n",
              "      <td>4.857164</td>\n",
              "      <td>-10.924910</td>\n",
              "      <td>6.915727</td>\n",
              "      <td>2.614477</td>\n",
              "      <td>-7.167866</td>\n",
              "      <td>-0.803820</td>\n",
              "      <td>0.644362</td>\n",
              "      <td>0.781104</td>\n",
              "      <td>-0.132394</td>\n",
              "      <td>-4.022217</td>\n",
              "      <td>0.235267</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.121320</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>0.000094</td>\n",
              "      <td>1.507822e-07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  phase  query_time  item_id  label  txt_vec10_pca0  txt_vec10_pca1  \\\n",
              "0        1      1    0.983942   101060    NaN       -0.033200        6.758050   \n",
              "1        1      1    0.983942   102129    NaN       -2.176809        4.566637   \n",
              "2        1      1    0.983942    94147    NaN       -9.188668        4.911909   \n",
              "3        1      1    0.983942    92349    NaN       -4.942613       -4.970490   \n",
              "4        1      1    0.983942    87837    NaN      -13.042260        9.058986   \n",
              "\n",
              "   txt_vec10_pca2  txt_vec10_pca3  txt_vec10_pca4  txt_vec10_pca5  \\\n",
              "0        2.445827       -0.980435       -5.504060       -3.220289   \n",
              "1       15.910588       -1.040885       -4.075056        4.052314   \n",
              "2        3.100944       -5.318312       -2.562280        3.399558   \n",
              "3       -4.758204        3.637302       -6.427946       -8.612261   \n",
              "4       -6.033150       -3.498339       -6.060202       -6.887897   \n",
              "\n",
              "   txt_vec10_pca6  txt_vec10_pca7  txt_vec10_pca8  txt_vec10_pca9  \\\n",
              "0        3.175805       -3.443489       -3.544041       -1.404752   \n",
              "1       -4.776940        6.171880        1.471331       -0.046035   \n",
              "2        0.779980        1.643967       -1.772803       -0.462451   \n",
              "3       -3.010530       -7.108364        2.320725        4.182026   \n",
              "4       -4.746740       -1.703656        2.524373        4.857164   \n",
              "\n",
              "   img_vec10_pca0  img_vec10_pca1  img_vec10_pca2  img_vec10_pca3  \\\n",
              "0       -1.080519       10.324701        0.737499       -5.772706   \n",
              "1       -3.046730        2.478535       -0.859532       -6.448319   \n",
              "2       -7.283262        1.301522       -3.056460        3.009867   \n",
              "3        0.793652        1.767247        4.539776       -7.067767   \n",
              "4      -10.924910        6.915727        2.614477       -7.167866   \n",
              "\n",
              "   img_vec10_pca4  img_vec10_pca5  img_vec10_pca6  img_vec10_pca7  \\\n",
              "0       -5.054800        0.035968        3.500112       -4.218156   \n",
              "1        2.800530        8.910352       -3.699516       -3.066158   \n",
              "2        1.882195        3.896656       -1.854984        8.029745   \n",
              "3       -6.766804        2.061429        0.491690       -5.229865   \n",
              "4       -0.803820        0.644362        0.781104       -0.132394   \n",
              "\n",
              "   img_vec10_pca8  img_vec10_pca9  phase_item_clickd_count  \\\n",
              "0        3.957114        2.160977                     17.0   \n",
              "1       -2.527535       -2.049918                     17.0   \n",
              "2        3.014313        2.492163                      5.0   \n",
              "3       -1.015263        0.370548                     14.0   \n",
              "4       -4.022217        0.235267                     12.0   \n",
              "\n",
              "   phase_item_click_time_diff_mean  item_id_phase_user_age_level_mean  \\\n",
              "0                         0.000009                           3.571429   \n",
              "1                         0.000012                           5.400000   \n",
              "2                         0.000039                           2.000000   \n",
              "3                         0.000010                           4.000000   \n",
              "4                         0.000018                           3.500000   \n",
              "\n",
              "   item_id_phase_user_age_level_min  item_id_phase_user_age_level_max  \\\n",
              "0                               2.0                               5.0   \n",
              "1                               4.0                               8.0   \n",
              "2                               2.0                               2.0   \n",
              "3                               3.0                               5.0   \n",
              "4                               2.0                               5.0   \n",
              "\n",
              "   item_id_phase_user_age_level_std  phase_item_click_gender_mean  \\\n",
              "0                          1.133893                          0.00   \n",
              "1                          1.673320                          0.20   \n",
              "2                               NaN                          0.00   \n",
              "3                          0.816497                          0.25   \n",
              "4                          2.121320                          0.00   \n",
              "\n",
              "   user_age_level  user_gender  user_city_level  phase_user_click_count  \\\n",
              "0             NaN          NaN              NaN                       9   \n",
              "1             NaN          NaN              NaN                       9   \n",
              "2             NaN          NaN              NaN                       9   \n",
              "3             NaN          NaN              NaN                       9   \n",
              "4             NaN          NaN              NaN                       9   \n",
              "\n",
              "   phase_user_age_level_click_count  user_id_phase_time_std  \\\n",
              "0                               NaN                0.000024   \n",
              "1                               NaN                0.000024   \n",
              "2                               NaN                0.000024   \n",
              "3                               NaN                0.000024   \n",
              "4                               NaN                0.000024   \n",
              "\n",
              "   user_id_phase_time_max_min_diff  user_id_phase_query_lastbuy_time_diff  \n",
              "0                         0.000094                           1.507822e-07  \n",
              "1                         0.000094                           1.507822e-07  \n",
              "2                         0.000094                           1.507822e-07  \n",
              "3                         0.000094                           1.507822e-07  \n",
              "4                         0.000094                           1.507822e-07  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCXw7O63oxio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_feature.to_pickle('kdd2020_data/recall/rank_feature0.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNPMwiD4YZ2n",
        "colab_type": "text"
      },
      "source": [
        "**item-user feature**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xt4JJ7bpvw1q",
        "colab_type": "text"
      },
      "source": [
        "we have three kinds of sim:\n",
        "\n",
        "* dictionary:recall_1,recall_2,recall_5,recall_10\n",
        "\n",
        "dictionary format:{phase:{item:{item1:score,item2:score}}}\n",
        "\n",
        "* w2v model:recall_6,recall_7,recall_8\n",
        "\n",
        "* dataframe:recall_3,recall_4\n",
        "\n",
        "dataframe format:\n",
        "\n",
        "dataframe[['item_id','item_txt/img_vec]]\n",
        "\n",
        "dataframe[['user_id','user_txt/img_vec]]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxs_7y7KYlWu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "phase_user_item_dict = {}\n",
        "for phase in phases:\n",
        "    df_click_temp = df_click[df_click['phase'] == phase]\n",
        "    user_item_ = df_click_temp.groupby('user_id')['item_id'].agg(list).reset_index()\n",
        "    user_item_dict = dict(zip(user_item_['user_id'], user_item_['item_id']))\n",
        "    phase_user_item_dict[phase] = user_item_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4grcN4nPoTec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def consine_distance(vector1, vector2):\n",
        "    if type(vector1) != np.ndarray or type(vector2) != np.ndarray:\n",
        "        return -1\n",
        "    distance = np.dot(vector1, vector2) / \\\n",
        "        (np.linalg.norm(vector1)*(np.linalg.norm(vector2)))\n",
        "    return distance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSrAYv4xapBI",
        "colab_type": "text"
      },
      "source": [
        "**sim1 from recall_1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1EglvogYD9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open('kdd2020_data/my_model/sim1.pkl', 'rb')\n",
        "item_sim_if = pickle.load(f)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHNgUav2ZJ4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def func_if_sum(x):\n",
        "    user_id = x['user_id']\n",
        "    item_id = x['item_id']\n",
        "    phase = x['phase']\n",
        "\n",
        "    interacted_items = phase_user_item_dict[phase][user_id]\n",
        "    interacted_items = interacted_items[::-1]\n",
        "\n",
        "    sim_sum = 0\n",
        "    for loc, i in enumerate(interacted_items):\n",
        "        try:\n",
        "            sim_sum += item_sim_if[phase][i][item_id] * (0.7**loc)\n",
        "        except Exception as e:\n",
        "            pass\n",
        "    return sim_sum\n",
        "\n",
        "\n",
        "def func_if_max(x):\n",
        "    user_id = x['user_id']\n",
        "    item_id = x['item_id']\n",
        "    phase = x['phase']\n",
        "\n",
        "    interacted_items = phase_user_item_dict[phase][user_id]\n",
        "    interacted_items = interacted_items[::-1]\n",
        "\n",
        "    sim_max = 0\n",
        "    for loc, i in enumerate(interacted_items):\n",
        "        try:\n",
        "            sim = item_sim_if[phase][i][item_id]\n",
        "            if sim > sim_max:\n",
        "                sim_max = sim\n",
        "        except Exception as e:\n",
        "            pass\n",
        "    return sim_max\n",
        "\n",
        "\n",
        "def func_if_last(x):\n",
        "    user_id = x['user_id']\n",
        "    item_id = x['item_id']\n",
        "    phase = x['phase']\n",
        "\n",
        "    last_item = phase_user_item_dict[phase][user_id][-1]\n",
        "\n",
        "    sim = 0\n",
        "    try:\n",
        "        sim = item_sim_if[phase][last_item][item_id]\n",
        "    except Exception as e:\n",
        "        pass\n",
        "    return sim\n",
        "\n",
        "\n",
        "def func_if_rolling_sum(x, window):\n",
        "    user_id = x['user_id']\n",
        "    item_id = x['item_id']\n",
        "    phase = x['phase']\n",
        "\n",
        "    interacted_items = phase_user_item_dict[phase][user_id]\n",
        "    interacted_items = interacted_items[-window:]\n",
        "\n",
        "    sim_sum = 0\n",
        "    for loc, i in enumerate(interacted_items):\n",
        "        try:\n",
        "            sim_sum += item_sim_if[phase][i][item_id]\n",
        "        except Exception as e:\n",
        "            pass\n",
        "    return sim_sum\n",
        "\n",
        "\n",
        "def func_if_rolling_mean(x, window):\n",
        "    user_id = x['user_id']\n",
        "    item_id = x['item_id']\n",
        "    phase = x['phase']\n",
        "\n",
        "    interacted_items = phase_user_item_dict[phase][user_id]\n",
        "    interacted_items = interacted_items[-window:]\n",
        "\n",
        "    sim_sum = 0\n",
        "    count = 0\n",
        "    for loc, i in enumerate(interacted_items):\n",
        "        try:\n",
        "            sim_sum += item_sim_if[phase][i][item_id]\n",
        "            count += 1\n",
        "        except Exception as e:\n",
        "            pass\n",
        "    if count != 0:\n",
        "        return sim_sum / count\n",
        "    else:\n",
        "        return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxktxDngZQhA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bce50a1a-b46b-4f4a-b3f0-99e29bf22ac1"
      },
      "source": [
        "df_feature['user_click_item_if_sim_sum'] = df_feature[[\n",
        "  'user_id', 'phase', 'item_id']].parallel_apply(func_if_sum, axis=1)\n",
        "df_feature['user_click_item_if_sim_max'] = df_feature[[\n",
        "    'user_id', 'phase', 'item_id']].parallel_apply(func_if_max, axis=1)\n",
        "df_feature['user_last_click_item_if_sim'] = df_feature[[\n",
        "    'user_id', 'phase', 'item_id']].parallel_apply(func_if_last, axis=1)\n",
        "\n",
        "df_feature['user_click_item_if_sim_rolling2_sum'] = df_feature[[\n",
        "    'user_id', 'phase', 'item_id']].parallel_apply(lambda x: func_if_rolling_sum(x, 2), axis=1)\n",
        "print(df_feature.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11489051, 44)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_emGlQFtaUxl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fdfbe5ab-3cc7-4254-8d02-556e100546db"
      },
      "source": [
        "del item_sim_if\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuWlStynqHIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_feature.to_pickle('kdd2020_data/recall/rank_feature1.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0ZIpvK0awHO",
        "colab_type": "text"
      },
      "source": [
        "**sim2 from recall_2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnxC8iAQabik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open('kdd2020_data/my_model/sim2.pkl', 'rb')\n",
        "item_sim_bn = pickle.load(f)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbSPggHob7Ms",
        "colab_type": "text"
      },
      "source": [
        "**based on the recall assessment results in recall, if the results is good,we adopt more features,otherwise we adopt fewer features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_Ly-s8ubJep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def func_bn_sum(x):\n",
        "    user_id = x['user_id']\n",
        "    item_id = x['item_id']\n",
        "    phase = x['phase']\n",
        "\n",
        "    interacted_items = phase_user_item_dict[phase][user_id]\n",
        "    interacted_items = interacted_items[::-1]\n",
        "\n",
        "    sim_sum = 0\n",
        "    for loc, i in enumerate(interacted_items):\n",
        "        try:\n",
        "            sim_sum += item_sim_bn[phase][i][item_id] * (0.7**loc)\n",
        "        except Exception as e:\n",
        "            pass\n",
        "    return sim_sum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMUHIe3lbpXF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae130b29-2b10-4e95-a7a4-140617fbc34b"
      },
      "source": [
        "df_feature['user_click_item_bn_sim_sum'] = df_feature[[\n",
        "    'user_id', 'phase', 'item_id']].parallel_apply(func_bn_sum, axis=1)\n",
        "print(df_feature.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11489051, 45)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNq2u2mxb2Sz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a28cf2b7-e953-442f-e55d-4093c361b2bf"
      },
      "source": [
        "del item_sim_bn\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxnWB-p2vVpT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_feature.to_pickle('kdd2020_data/recall/rank_feature2.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzm9CEpEcuFv",
        "colab_type": "text"
      },
      "source": [
        "**sim3 from recall_3(item txt sim)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ebioUZEc6Ww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_user_txt_vec = pd.read_pickle('kdd2020_data/my_model/user_txt_vec.pkl')\n",
        "df_item_txt_vec = pd.read_pickle('kdd2020_data/my_model/item_txt_vec.pkl')\n",
        "item_txt_vec_dict = dict(zip(df_item_txt_vec['item_id'], df_item_txt_vec['item_txt_vec']))\n",
        "\n",
        "phase_user_txt_vec_dict = {}\n",
        "for phase in phases:\n",
        "    df_user_txt_vec_phase = df_user_txt_vec[df_user_txt_vec['phase'] == phase]\n",
        "    user_txt_vec_dict = dict(zip(df_user_txt_vec_phase['user_id'], df_user_txt_vec_phase['user_txt_vec']))\n",
        "    phase_user_txt_vec_dict[phase] = user_txt_vec_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xvH02DPegRE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def func_txt_sim(x):\n",
        "    user_id = x['user_id']\n",
        "    item_id = x['item_id']\n",
        "    phase = x['phase']\n",
        "\n",
        "    sim = 0\n",
        "    try:\n",
        "        sim = consine_distance(\n",
        "            phase_user_txt_vec_dict[phase][user_id], item_txt_vec_dict[item_id])\n",
        "    except Exception as e:\n",
        "        pass\n",
        "    return sim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEl5xHBrem2V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0eb0986e-5652-4a32-b86b-88c7292001c4"
      },
      "source": [
        "df_feature['user_item_txt_sim'] = df_feature[['user_id', 'phase', 'item_id']].parallel_apply(func_txt_sim, axis=1)\n",
        "print(df_feature.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11489051, 46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnVpy8Yfepvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def func_txt_sum(x):\n",
        "    user_id = x['user_id']\n",
        "    item_id = x['item_id']\n",
        "    phase = x['phase']\n",
        "\n",
        "    interacted_items = phase_user_item_dict[phase][user_id]\n",
        "    interacted_items = interacted_items[::-1]\n",
        "\n",
        "    sim_sum = 0\n",
        "    for loc, i in enumerate(interacted_items):\n",
        "        try:\n",
        "            sim_sum += consine_distance(\n",
        "                item_txt_vec_dict[i], item_txt_vec_dict[item_id]) * (0.7 ** loc)\n",
        "        except Exception as e:\n",
        "            pass\n",
        "    return sim_sum\n",
        "\n",
        "\n",
        "def func_txt_max(x):\n",
        "    user_id = x['user_id']\n",
        "    item_id = x['item_id']\n",
        "    phase = x['phase']\n",
        "\n",
        "    interacted_items = phase_user_item_dict[phase][user_id]\n",
        "    interacted_items = interacted_items[::-1]\n",
        "\n",
        "    sim_max = 0\n",
        "    for loc, i in enumerate(interacted_items):\n",
        "        try:\n",
        "            sim = consine_distance(\n",
        "                item_txt_vec_dict[i], item_txt_vec_dict[item_id])\n",
        "            if sim > sim_max:\n",
        "                sim_max = sim\n",
        "        except Exception as e:\n",
        "            pass\n",
        "    return sim_max\n",
        "\n",
        "\n",
        "def func_txt_last(x):\n",
        "    user_id = x['user_id']\n",
        "    item_id = x['item_id']\n",
        "    phase = x['phase']\n",
        "\n",
        "    last_item = phase_user_item_dict[phase][user_id][-1]\n",
        "\n",
        "    sim = 0\n",
        "    try:\n",
        "        sim = consine_distance(\n",
        "            item_txt_vec_dict[last_item], item_txt_vec_dict[item_id])\n",
        "    except Exception as e:\n",
        "        pass\n",
        "    return sim\n",
        "\n",
        "\n",
        "def func_txt_rolling_sum(x, window):\n",
        "    user_id = x['user_id']\n",
        "    item_id = x['item_id']\n",
        "    phase = x['phase']\n",
        "\n",
        "    interacted_items = phase_user_item_dict[phase][user_id]\n",
        "    interacted_items = interacted_items[-window:]\n",
        "\n",
        "    sim_sum = 0\n",
        "    for loc, i in enumerate(interacted_items):\n",
        "        try:\n",
        "            sim_sum += consine_distance(\n",
        "                item_txt_vec_dict[i], item_txt_vec_dict[item_id])\n",
        "        except Exception as e:\n",
        "            pass\n",
        "    return sim_sum\n",
        "\n",
        "\n",
        "def func_txt_rolling_mean(x, window):\n",
        "    user_id = x['user_id']\n",
        "    item_id = x['item_id']\n",
        "    phase = x['phase']\n",
        "\n",
        "    interacted_items = phase_user_item_dict[phase][user_id]\n",
        "    interacted_items = interacted_items[-window:]\n",
        "\n",
        "    sim_sum = 0\n",
        "    count = 0\n",
        "    for loc, i in enumerate(interacted_items):\n",
        "        try:\n",
        "            sim_sum += consine_distance(\n",
        "                item_txt_vec_dict[i], item_txt_vec_dict[item_id])\n",
        "            count += 1\n",
        "        except Exception as e:\n",
        "            pass\n",
        "    if count != 0:\n",
        "        return sim_sum / count\n",
        "    else:\n",
        "        return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3voAOMIeu6X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "3eb98675-bc2c-4f37-b5a4-8eaff7d04f67"
      },
      "source": [
        "df_feature['user_click_item_txt_sim_sum'] = df_feature[[\n",
        "    'user_id', 'phase', 'item_id']].parallel_apply(func_txt_sum, axis=1)\n",
        "print(df_feature.shape)\n",
        "df_feature['user_click_item_txt_sim_max'] = df_feature[[\n",
        "    'user_id', 'phase', 'item_id']].parallel_apply(func_txt_max, axis=1)\n",
        "print(df_feature.shape)\n",
        "df_feature['user_last_click_item_txt_sim'] = df_feature[[\n",
        "    'user_id', 'phase',  'item_id']].parallel_apply(func_txt_last, axis=1)\n",
        "print(df_feature.shape)\n",
        "\n",
        "df_feature['user_click_item_txt_sim_rolling2_sum'] = df_feature[[\n",
        "    'user_id', 'phase', 'item_id']].parallel_apply(lambda x: func_txt_rolling_sum(x, 2), axis=1)\n",
        "print(df_feature.shape)\n",
        "df_feature['user_click_item_txt_sim_rolling2_mean'] = df_feature[[\n",
        "    'user_id', 'phase', 'item_id']].parallel_apply(lambda x: func_txt_rolling_mean(x, 2), axis=1)\n",
        "print(df_feature.shape)\n",
        "df_feature['user_click_item_txt_sim_rolling3_mean'] = df_feature[[\n",
        "    'user_id', 'phase', 'item_id']].parallel_apply(lambda x: func_txt_rolling_mean(x, 3), axis=1)\n",
        "print(df_feature.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11489051, 47)\n",
            "(11489051, 48)\n",
            "(11489051, 49)\n",
            "(11489051, 50)\n",
            "(11489051, 51)\n",
            "(11489051, 52)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "low_zjXSex0v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "87488df2-f67f-44b9-bea1-b2d2dcdf392a"
      },
      "source": [
        "del df_user_txt_vec, df_item_txt_vec, phase_user_txt_vec_dict\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlYWwmBZv5UP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_feature.to_pickle('kdd2020_data/recall/rank_feature3.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ar0m_bODfycM",
        "colab_type": "text"
      },
      "source": [
        "**sim4 from recall_4(item img sim)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AambkK7hf8of",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_user_img_vec = pd.read_pickle('kdd2020_data/my_model/user_img_vec.pkl')\n",
        "df_item_img_vec = pd.read_pickle('kdd2020_data/my_model/item_img_vec.pkl')\n",
        "item_img_vec_dict = dict(\n",
        "    zip(df_item_img_vec['item_id'], df_item_img_vec['item_img_vec']))\n",
        "\n",
        "phase_user_img_vec_dict = {}\n",
        "for phase in phases:\n",
        "    df_user_img_vec_phase = df_user_img_vec[df_user_img_vec['phase'] == phase]\n",
        "    user_img_vec_dict = dict(zip(df_user_img_vec['user_id'], df_user_img_vec['user_img_vec']))\n",
        "    phase_user_img_vec_dict[phase] = user_txt_vec_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVftDPQVgFjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def func_img_sim(x):\n",
        "    user_id = x['user_id']\n",
        "    item_id = x['item_id']\n",
        "    phase = x['phase']\n",
        "\n",
        "    sim = 0\n",
        "    try:\n",
        "        sim = consine_distance(\n",
        "            phase_user_img_vec_dict[phase][user_id], item_img_vec_dict[item_id])\n",
        "    except Exception as e:\n",
        "        pass\n",
        "    return sim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpOAIsGNgIe_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c11979f-bd4b-4383-af07-5c936fcffd2f"
      },
      "source": [
        "df_feature['user_item_img_sim'] = df_feature[[\n",
        "    'user_id', 'phase', 'item_id']].parallel_apply(func_img_sim, axis=1)\n",
        "print(df_feature.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11489051, 53)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrQb_OMkgOqJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "803668e6-d3e2-4118-dded-4a2edf01b7f5"
      },
      "source": [
        "del df_user_img_vec, df_item_img_vec, item_img_vec_dict, phase_user_img_vec_dict\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "233"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAkrKEV8wZoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_feature.to_pickle('kdd2020_data/recall/rank_feature4.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqVsXxY9jqHA",
        "colab_type": "text"
      },
      "source": [
        "**sim5 from recall_5**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zs5zimIJj2br",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open('kdd2020_data/my_model/sim5.pkl', 'rb')\n",
        "item_sim_tc = pickle.load(f)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMEyG54WkC_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def func_tc_sum(x):\n",
        "    user_id = x['user_id']\n",
        "    item_id = x['item_id']\n",
        "    phase = x['phase']\n",
        "\n",
        "    interacted_items = phase_user_item_dict[phase][user_id]\n",
        "\n",
        "    sim_sum = 0\n",
        "    for loc, i in enumerate(interacted_items):\n",
        "        try:\n",
        "            sim_sum += item_sim_tc[phase][i][item_id]\n",
        "        except Exception as e:\n",
        "            pass\n",
        "    return sim_sum\n",
        "\n",
        "\n",
        "def func_tc_max(x):\n",
        "    user_id = x['user_id']\n",
        "    item_id = x['item_id']\n",
        "    phase = x['phase']\n",
        "\n",
        "    interacted_items = phase_user_item_dict[phase][user_id]\n",
        "    interacted_items = interacted_items[::-1]\n",
        "\n",
        "    sim_max = 0\n",
        "    for loc, i in enumerate(interacted_items):\n",
        "        try:\n",
        "            sim = item_sim_tc[phase][i][item_id]\n",
        "            if sim > sim_max:\n",
        "                sim_max = sim\n",
        "        except Exception as e:\n",
        "            pass\n",
        "    return sim_max\n",
        "\n",
        "\n",
        "def func_tc_rolling_sum(x, window):\n",
        "    user_id = x['user_id']\n",
        "    item_id = x['item_id']\n",
        "    phase = x['phase']\n",
        "\n",
        "    interacted_items = phase_user_item_dict[phase][user_id]\n",
        "    interacted_items = interacted_items[-window:]\n",
        "\n",
        "    sim_sum = 0\n",
        "    for loc, i in enumerate(interacted_items):\n",
        "        try:\n",
        "            sim_sum += item_sim_tc[phase][i][item_id]\n",
        "        except Exception as e:\n",
        "            pass\n",
        "    return sim_sum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xhf2s3w_kGbY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3bac2a6c-59a8-457c-8fc9-2dc2b33f838d"
      },
      "source": [
        "df_feature['user_click_item_tc_sim_sum'] = df_feature[[\n",
        "    'user_id', 'phase', 'item_id']].parallel_apply(func_tc_sum, axis=1)\n",
        "df_feature['user_click_item_tc_sim_max'] = df_feature[[\n",
        "    'user_id', 'phase', 'item_id']].parallel_apply(func_tc_max, axis=1)\n",
        "df_feature['user_click_item_tc_sim_rolling2_sum'] = df_feature[[\n",
        "    'user_id', 'phase', 'item_id']].parallel_apply(lambda x: func_tc_rolling_sum(x, 2), axis=1)\n",
        "print(df_feature.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11489051, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Bu_XMqokI40",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "02f50e8f-3f9d-4f03-f87c-c40b231d8714"
      },
      "source": [
        "del item_sim_tc\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1WqrCuKw58i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_feature.to_pickle('kdd2020_data/recall/rank_feature5.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72_m8sFXgRGR",
        "colab_type": "text"
      },
      "source": [
        "**sim6 from recall_6(w2v)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pac2bUGr4Lt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_feature=pd.read_pickle('kdd2020_data/recall/rank_feature5.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWVWIFMAggNm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "def get_emb_dict(phase):\n",
        "  model = Word2Vec.load('kdd2020_data/my_model/recall_6/w2v_{}.m'.format(phase))\n",
        "  words=list(set(df_feature[df_feature['phase']==phase]['item_id'].tolist()))\n",
        "  emb_matrix = []\n",
        "  items = []\n",
        "  for word in tqdm(words):\n",
        "    if str(word) in model:\n",
        "        items.append(word)\n",
        "        emb_matrix.append(model[str(word)])\n",
        "  item_w2w_vec_dict = dict(zip(items, emb_matrix))\n",
        "  return item_w2w_vec_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-jd7pyjsMKO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7e262b34-6d7e-4722-db15-f5e1d82b3394"
      },
      "source": [
        "item_w2w_vec_dict_0=get_emb_dict(0)\n",
        "item_w2w_vec_dict_1=get_emb_dict(1)\n",
        "item_w2w_vec_dict_2=get_emb_dict(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 109451/109451 [00:00<00:00, 181285.30it/s]\n",
            "100%|██████████| 108855/108855 [00:00<00:00, 182029.80it/s]\n",
            "100%|██████████| 108637/108637 [00:00<00:00, 182842.91it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htsDRgT7uPui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def get_emb_matrix(phase):\n",
        "#   model = Word2Vec.load('kdd2020_data/my_model/w2v_{}.m'.format(phase))\n",
        "#   words=list(set(df_feature[df_feature['phase']==phase]['item_id'].tolist()))\n",
        "#   emb_matrix = []\n",
        "#   items = []\n",
        "#   for word in tqdm(words):\n",
        "#     if str(word) in model:\n",
        "#         items.append(word)\n",
        "#         emb_matrix.append(model[str(word)])\n",
        "#   item_w2w_vec_dict = dict(zip(items, emb_matrix))\n",
        "#   df_item_w2v = pd.DataFrame(emb_matrix)\n",
        "#   df_item_w2v.columns = ['item_w2v_{}'.format(i) for i in range(128)]\n",
        "#   df_item_w2v['item_id'] = items\n",
        "#   df_feature = df_feature.merge(df_item_w2v, how='left')\n",
        "#   return df_feature"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wok7F_0Fglce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def func_w2w_sum(x, num):\n",
        "    user_id = x['user_id']\n",
        "    item_id = x['item_id']\n",
        "    phase = x['phase']\n",
        "\n",
        "    interacted_items = phase_user_item_dict[phase][user_id]\n",
        "    interacted_items = interacted_items[::-1][:num]\n",
        "    \n",
        "    if phase==0:\n",
        "      item_w2w_vec_dict=item_w2w_vec_dict_0\n",
        "    elif phase==1:\n",
        "      item_w2w_vec_dict=item_w2w_vec_dict_1\n",
        "    elif phase==2:\n",
        "      item_w2w_vec_dict=item_w2w_vec_dict_2\n",
        "    # item_w2w_vec_dict=get_emb_dict(phase)\n",
        "\n",
        "    sim_sum = 0\n",
        "    for loc, i in enumerate(interacted_items):\n",
        "        try:\n",
        "            sim_sum += consine_distance(\n",
        "                item_w2w_vec_dict[item_id], item_w2w_vec_dict[i])\n",
        "        except Exception as e:\n",
        "            pass\n",
        "    return sim_sum\n",
        "\n",
        "\n",
        "def func_w2w_last_sim(x):\n",
        "    user_id = x['user_id']\n",
        "    item_id = x['item_id']\n",
        "    phase = x['phase']\n",
        "\n",
        "    last_item = phase_user_item_dict[phase][user_id][-1]\n",
        "    # item_w2w_vec_dict=get_emb_dict(phase)\n",
        "\n",
        "    if phase==0:\n",
        "      item_w2w_vec_dict=item_w2w_vec_dict_0\n",
        "    elif phase==1:\n",
        "      item_w2w_vec_dict=item_w2w_vec_dict_1\n",
        "    elif phase==2:\n",
        "      item_w2w_vec_dict=item_w2w_vec_dict_2\n",
        "\n",
        "    sim = 0\n",
        "    try:\n",
        "        sim = consine_distance(\n",
        "            item_w2w_vec_dict[item_id], item_w2w_vec_dict[last_item])\n",
        "    except Exception as e:\n",
        "        pass\n",
        "    return sim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f3yoYKigoeP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "38bd7394-925f-453d-b1a5-3560e65f2b3b"
      },
      "source": [
        "df_feature['user_last_click_item_w2w_sim'] = df_feature[[\n",
        "    'user_id', 'phase', 'item_id']].parallel_apply(func_w2w_last_sim, axis=1) #run each row in parallel\n",
        "df_feature['user_click_item_w2w_sim_sum_2'] = df_feature[[\n",
        "    'user_id', 'phase', 'item_id']].parallel_apply(lambda x: func_w2w_sum(x, 2), axis=1)\n",
        "print(df_feature.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11489051, 58)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzBUzxPrgrPW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09c8817b-aa96-498a-ad2d-4fff9a675448"
      },
      "source": [
        "del item_w2w_vec_dict_0,item_w2w_vec_dict_1,item_w2w_vec_dict_2\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QFSy9eExlc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_feature.to_pickle('kdd2020_data/recall/rank_feature6.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA5nnyIjqYO3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d440ca2c-cdac-4a34-b13f-4e228e94d971"
      },
      "source": [
        "print(df_feature[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   user_id  phase  query_time  item_id  label  txt_vec10_pca0  txt_vec10_pca1  \\\n",
            "0        1      1    0.983942   101060    NaN       -0.033200        6.758050   \n",
            "1        1      1    0.983942   102129    NaN       -2.176809        4.566637   \n",
            "2        1      1    0.983942    94147    NaN       -9.188668        4.911909   \n",
            "3        1      1    0.983942    92349    NaN       -4.942613       -4.970490   \n",
            "4        1      1    0.983942    87837    NaN      -13.042260        9.058986   \n",
            "\n",
            "   txt_vec10_pca2  txt_vec10_pca3  txt_vec10_pca4  txt_vec10_pca5  \\\n",
            "0        2.445827       -0.980435       -5.504060       -3.220289   \n",
            "1       15.910588       -1.040885       -4.075056        4.052314   \n",
            "2        3.100944       -5.318312       -2.562280        3.399558   \n",
            "3       -4.758204        3.637302       -6.427946       -8.612261   \n",
            "4       -6.033150       -3.498339       -6.060202       -6.887897   \n",
            "\n",
            "   txt_vec10_pca6  txt_vec10_pca7  txt_vec10_pca8  txt_vec10_pca9  \\\n",
            "0        3.175805       -3.443489       -3.544041       -1.404752   \n",
            "1       -4.776940        6.171880        1.471331       -0.046035   \n",
            "2        0.779980        1.643967       -1.772803       -0.462451   \n",
            "3       -3.010530       -7.108364        2.320725        4.182026   \n",
            "4       -4.746740       -1.703656        2.524373        4.857164   \n",
            "\n",
            "   img_vec10_pca0  img_vec10_pca1  img_vec10_pca2  img_vec10_pca3  \\\n",
            "0       -1.080519       10.324701        0.737499       -5.772706   \n",
            "1       -3.046730        2.478535       -0.859532       -6.448319   \n",
            "2       -7.283262        1.301522       -3.056460        3.009867   \n",
            "3        0.793652        1.767247        4.539776       -7.067767   \n",
            "4      -10.924910        6.915727        2.614477       -7.167866   \n",
            "\n",
            "   img_vec10_pca4  img_vec10_pca5  img_vec10_pca6  img_vec10_pca7  \\\n",
            "0       -5.054800        0.035968        3.500112       -4.218156   \n",
            "1        2.800530        8.910352       -3.699516       -3.066158   \n",
            "2        1.882195        3.896656       -1.854984        8.029745   \n",
            "3       -6.766804        2.061429        0.491690       -5.229865   \n",
            "4       -0.803820        0.644362        0.781104       -0.132394   \n",
            "\n",
            "   img_vec10_pca8  img_vec10_pca9  phase_item_clickd_count  \\\n",
            "0        3.957114        2.160977                     17.0   \n",
            "1       -2.527535       -2.049918                     17.0   \n",
            "2        3.014313        2.492163                      5.0   \n",
            "3       -1.015263        0.370548                     14.0   \n",
            "4       -4.022217        0.235267                     12.0   \n",
            "\n",
            "   phase_item_click_time_diff_mean  item_id_phase_user_age_level_mean  \\\n",
            "0                         0.000009                           3.571429   \n",
            "1                         0.000012                           5.400000   \n",
            "2                         0.000039                           2.000000   \n",
            "3                         0.000010                           4.000000   \n",
            "4                         0.000018                           3.500000   \n",
            "\n",
            "   item_id_phase_user_age_level_min  item_id_phase_user_age_level_max  \\\n",
            "0                               2.0                               5.0   \n",
            "1                               4.0                               8.0   \n",
            "2                               2.0                               2.0   \n",
            "3                               3.0                               5.0   \n",
            "4                               2.0                               5.0   \n",
            "\n",
            "   item_id_phase_user_age_level_std  phase_item_click_gender_mean  \\\n",
            "0                          1.133893                          0.00   \n",
            "1                          1.673320                          0.20   \n",
            "2                               NaN                          0.00   \n",
            "3                          0.816497                          0.25   \n",
            "4                          2.121320                          0.00   \n",
            "\n",
            "   user_age_level  user_gender  user_city_level  phase_user_click_count  \\\n",
            "0             NaN          NaN              NaN                       9   \n",
            "1             NaN          NaN              NaN                       9   \n",
            "2             NaN          NaN              NaN                       9   \n",
            "3             NaN          NaN              NaN                       9   \n",
            "4             NaN          NaN              NaN                       9   \n",
            "\n",
            "   phase_user_age_level_click_count  user_id_phase_time_std  \\\n",
            "0                               NaN                0.000024   \n",
            "1                               NaN                0.000024   \n",
            "2                               NaN                0.000024   \n",
            "3                               NaN                0.000024   \n",
            "4                               NaN                0.000024   \n",
            "\n",
            "   user_id_phase_time_max_min_diff  user_id_phase_query_lastbuy_time_diff  \\\n",
            "0                         0.000094                           1.507822e-07   \n",
            "1                         0.000094                           1.507822e-07   \n",
            "2                         0.000094                           1.507822e-07   \n",
            "3                         0.000094                           1.507822e-07   \n",
            "4                         0.000094                           1.507822e-07   \n",
            "\n",
            "   user_click_item_if_sim_sum  user_click_item_if_sim_max  \\\n",
            "0                    0.040050                    0.040050   \n",
            "1                    0.020347                    0.020347   \n",
            "2                    0.066998                    0.066998   \n",
            "3                    0.024071                    0.049124   \n",
            "4                    0.028262                    0.069047   \n",
            "\n",
            "   user_last_click_item_if_sim  user_click_item_if_sim_rolling2_sum  \\\n",
            "0                     0.040050                             0.040050   \n",
            "1                     0.020347                             0.020347   \n",
            "2                     0.066998                             0.066998   \n",
            "3                     0.000000                             0.000000   \n",
            "4                     0.000000                             0.000000   \n",
            "\n",
            "   user_click_item_bn_sim_sum  user_item_txt_sim  user_click_item_txt_sim_sum  \\\n",
            "0                    0.206093           0.487541                     1.086775   \n",
            "1                    0.164092           0.228532                     0.494989   \n",
            "2                    0.189547           0.557425                     1.223766   \n",
            "3                    0.160867           0.727260                     1.668448   \n",
            "4                    0.152707           0.559162                     1.254520   \n",
            "\n",
            "   user_click_item_txt_sim_max  user_last_click_item_txt_sim  \\\n",
            "0                     0.478294                      0.360366   \n",
            "1                     0.418480                      0.119882   \n",
            "2                     0.589780                      0.487252   \n",
            "3                     0.860765                      0.285191   \n",
            "4                     0.571966                      0.314576   \n",
            "\n",
            "   user_click_item_txt_sim_rolling2_sum  \\\n",
            "0                              0.838660   \n",
            "1                              0.538362   \n",
            "2                              1.077032   \n",
            "3                              0.809211   \n",
            "4                              0.886541   \n",
            "\n",
            "   user_click_item_txt_sim_rolling2_mean  \\\n",
            "0                               0.419330   \n",
            "1                               0.269181   \n",
            "2                               0.538516   \n",
            "3                               0.404606   \n",
            "4                               0.443271   \n",
            "\n",
            "   user_click_item_txt_sim_rolling3_mean  user_item_img_sim  \\\n",
            "0                               0.369425          -0.167506   \n",
            "1                               0.200986          -0.003670   \n",
            "2                               0.444333          -0.049995   \n",
            "3                               0.517564          -0.015303   \n",
            "4                               0.434327          -0.134673   \n",
            "\n",
            "   user_click_item_tc_sim_sum  user_click_item_tc_sim_max  \\\n",
            "0                    0.001953                    0.001953   \n",
            "1                    0.001416                    0.001416   \n",
            "2                    0.003706                    0.003706   \n",
            "3                    0.005026                    0.005026   \n",
            "4                    0.006392                    0.003446   \n",
            "\n",
            "   user_click_item_tc_sim_rolling2_sum  user_last_click_item_w2w_sim  \\\n",
            "0                             0.001953                      0.446845   \n",
            "1                             0.001416                      0.452852   \n",
            "2                             0.003706                      0.551571   \n",
            "3                             0.000000                      0.315379   \n",
            "4                             0.000000                      0.306161   \n",
            "\n",
            "   user_click_item_w2w_sim_sum_2  \n",
            "0                       0.600401  \n",
            "1                       0.739120  \n",
            "2                       0.846373  \n",
            "3                       0.547425  \n",
            "4                       0.541286  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o32ZnD9Yg2HN",
        "colab_type": "text"
      },
      "source": [
        "**sim7 from recall_7(deepwalk)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPYgj7z5xsbp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_emb_dict(phase):\n",
        "  model = Word2Vec.load('kdd2020_data/my_model/recall_7/w2v_{}.m'.format(phase))\n",
        "  words=list(set(df_feature[df_feature['phase']==phase]['item_id'].tolist()))\n",
        "  emb_matrix = []\n",
        "  items = []\n",
        "  for word in tqdm(words):\n",
        "    if str(word) in model:\n",
        "        items.append(word)\n",
        "        emb_matrix.append(model[str(word)])\n",
        "  item_w2w_vec_dict = dict(zip(items, emb_matrix))\n",
        "  return item_w2w_vec_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jydEHJ6gyjlK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "819c5689-83d1-4baa-d3c4-30b880e91fc4"
      },
      "source": [
        "item_w2w_vec_dict_0=get_emb_dict(0)\n",
        "item_w2w_vec_dict_1=get_emb_dict(1)\n",
        "item_w2w_vec_dict_2=get_emb_dict(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 109451/109451 [00:00<00:00, 159864.90it/s]\n",
            "100%|██████████| 108855/108855 [00:00<00:00, 152043.04it/s]\n",
            "100%|██████████| 108637/108637 [00:00<00:00, 155447.56it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8H9sSrdyI_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def func_w2w_sum(x, num):\n",
        "    user_id = x['user_id']\n",
        "    item_id = x['item_id']\n",
        "    phase = x['phase']\n",
        "\n",
        "    interacted_items = phase_user_item_dict[phase][user_id]\n",
        "    interacted_items = interacted_items[::-1][:num]\n",
        "    \n",
        "    # item_w2w_vec_dict=get_emb_dict(phase)\n",
        "    if phase==0:\n",
        "      item_w2w_vec_dict=item_w2w_vec_dict_0\n",
        "    elif phase==1:\n",
        "      item_w2w_vec_dict=item_w2w_vec_dict_1\n",
        "    elif phase==2:\n",
        "      item_w2w_vec_dict=item_w2w_vec_dict_2\n",
        "\n",
        "    sim_sum = 0\n",
        "    for loc, i in enumerate(interacted_items):\n",
        "        try:\n",
        "            sim_sum += consine_distance(\n",
        "                item_w2w_vec_dict[item_id], item_w2w_vec_dict[i])\n",
        "        except Exception as e:\n",
        "            pass\n",
        "    return sim_sum\n",
        "\n",
        "\n",
        "def func_w2w_last_sim(x):\n",
        "    user_id = x['user_id']\n",
        "    item_id = x['item_id']\n",
        "    phase = x['phase']\n",
        "\n",
        "    last_item = phase_user_item_dict[phase][user_id][-1]\n",
        "    # item_w2w_vec_dict=get_emb_dict(phase)\n",
        "    if phase==0:\n",
        "      item_w2w_vec_dict=item_w2w_vec_dict_0\n",
        "    elif phase==1:\n",
        "      item_w2w_vec_dict=item_w2w_vec_dict_1\n",
        "    elif phase==2:\n",
        "      item_w2w_vec_dict=item_w2w_vec_dict_2\n",
        "\n",
        "    sim = 0\n",
        "    try:\n",
        "        sim = consine_distance(\n",
        "            item_w2w_vec_dict[item_id], item_w2w_vec_dict[last_item])\n",
        "    except Exception as e:\n",
        "        pass\n",
        "    return sim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw-sPTrOxyxF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5dd38066-c933-4201-8324-21264a756b0c"
      },
      "source": [
        "df_feature['user_last_click_item_deepwalk_sim'] = df_feature[[\n",
        "    'user_id', 'phase', 'item_id']].parallel_apply(func_w2w_last_sim, axis=1)\n",
        "df_feature['user_click_item_deepwalk_sim_sum_2'] = df_feature[[\n",
        "    'user_id', 'phase', 'item_id']].parallel_apply(lambda x: func_w2w_sum(x, 2), axis=1)\n",
        "print(df_feature.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11489051, 60)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6CMtLNUyTGO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d859ec43-670d-44eb-dfa3-26895ea2e3ee"
      },
      "source": [
        "del item_w2w_vec_dict_0,item_w2w_vec_dict_1,item_w2w_vec_dict_2\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHmUiraWya91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_feature.to_pickle('kdd2020_data/recall/rank_feature7.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeSPDLSNg8S7",
        "colab_type": "text"
      },
      "source": [
        "**sim8 from recall_8(node2vec)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v4vbySpydp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_emb_dict(phase):\n",
        "  model = Word2Vec.load('kdd2020_data/my_model/recall_8/w2v_{}.m'.format(phase))\n",
        "  words=list(set(df_feature[df_feature['phase']==phase]['item_id'].tolist()))\n",
        "  emb_matrix = []\n",
        "  items = []\n",
        "  for word in tqdm(words):\n",
        "    if str(word) in model:\n",
        "        items.append(word)\n",
        "        emb_matrix.append(model[str(word)])\n",
        "  item_w2w_vec_dict = dict(zip(items, emb_matrix))\n",
        "  return item_w2w_vec_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnS1IftEzJoI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c420bac5-03b9-4c7f-a9ed-9a5708e5bf4c"
      },
      "source": [
        "item_w2w_vec_dict_0=get_emb_dict(0)\n",
        "item_w2w_vec_dict_1=get_emb_dict(1)\n",
        "item_w2w_vec_dict_2=get_emb_dict(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 109451/109451 [00:00<00:00, 167395.50it/s]\n",
            "100%|██████████| 108855/108855 [00:00<00:00, 160258.26it/s]\n",
            "100%|██████████| 108637/108637 [00:00<00:00, 162142.74it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dy5uzSilymMf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def func_w2w_sum(x, num):\n",
        "    user_id = x['user_id']\n",
        "    item_id = x['item_id']\n",
        "    phase = x['phase']\n",
        "\n",
        "    interacted_items = phase_user_item_dict[phase][user_id]\n",
        "    interacted_items = interacted_items[::-1][:num]\n",
        "    \n",
        "    # item_w2w_vec_dict=get_emb_dict(phase)\n",
        "    if phase==0:\n",
        "      item_w2w_vec_dict=item_w2w_vec_dict_0\n",
        "    elif phase==1:\n",
        "      item_w2w_vec_dict=item_w2w_vec_dict_1\n",
        "    elif phase==2:\n",
        "      item_w2w_vec_dict=item_w2w_vec_dict_2\n",
        "\n",
        "    sim_sum = 0\n",
        "    for loc, i in enumerate(interacted_items):\n",
        "        try:\n",
        "            sim_sum += consine_distance(\n",
        "                item_w2w_vec_dict[item_id], item_w2w_vec_dict[i])\n",
        "        except Exception as e:\n",
        "            pass\n",
        "    return sim_sum\n",
        "\n",
        "\n",
        "def func_w2w_last_sim(x):\n",
        "    user_id = x['user_id']\n",
        "    item_id = x['item_id']\n",
        "    phase = x['phase']\n",
        "\n",
        "    last_item = phase_user_item_dict[phase][user_id][-1]\n",
        "    # item_w2w_vec_dict=get_emb_dict(phase)\n",
        "    if phase==0:\n",
        "      item_w2w_vec_dict=item_w2w_vec_dict_0\n",
        "    elif phase==1:\n",
        "      item_w2w_vec_dict=item_w2w_vec_dict_1\n",
        "    elif phase==2:\n",
        "      item_w2w_vec_dict=item_w2w_vec_dict_2\n",
        "\n",
        "    sim = 0\n",
        "    try:\n",
        "        sim = consine_distance(\n",
        "            item_w2w_vec_dict[item_id], item_w2w_vec_dict[last_item])\n",
        "    except Exception as e:\n",
        "        pass\n",
        "    return sim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dv2KW9tJyrTa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c8d57d7c-7aa2-43a0-a9c6-a0fff3c1dc1f"
      },
      "source": [
        "df_feature['user_last_click_item_n2v_sim'] = df_feature[[\n",
        "    'user_id', 'phase', 'item_id']].parallel_apply(func_w2w_last_sim, axis=1)\n",
        "df_feature['user_click_item_n2v_sim_sum_2'] = df_feature[[\n",
        "    'user_id', 'phase', 'item_id']].parallel_apply(lambda x: func_w2w_sum(x, 2), axis=1)\n",
        "print(df_feature.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11489051, 62)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBOupH3QyvQ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fee02be4-215e-448c-ef80-f46c65b2e86c"
      },
      "source": [
        "del item_w2w_vec_dict_0,item_w2w_vec_dict_1,item_w2w_vec_dict_2\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ax1hm9SmzWeQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_feature.to_pickle('kdd2020_data/recall/rank_feature8.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "im2VDNG4hBoW",
        "colab_type": "text"
      },
      "source": [
        "**sim9 from recall_9(gcn)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YR5QhXzehGMq",
        "colab_type": "text"
      },
      "source": [
        "**sim10 from recall_10(common neighbors)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdF55xmtzdkz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open('kdd2020_data/my_model/sim10.pkl', 'rb')\n",
        "item_sim_if = pickle.load(f)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwPEODedz6o_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def func_if_sum(x):\n",
        "    user_id = x['user_id']\n",
        "    item_id = x['item_id']\n",
        "    phase = x['phase']\n",
        "\n",
        "    interacted_items = phase_user_item_dict[phase][user_id]\n",
        "    interacted_items = interacted_items[::-1]\n",
        "\n",
        "    sim_sum = 0\n",
        "    for loc, i in enumerate(interacted_items):\n",
        "        try:\n",
        "            sim_sum += item_sim_if[phase][i][item_id] * (0.7**loc)\n",
        "        except Exception as e:\n",
        "            pass\n",
        "    return sim_sum\n",
        "\n",
        "\n",
        "def func_if_max(x):\n",
        "    user_id = x['user_id']\n",
        "    item_id = x['item_id']\n",
        "    phase = x['phase']\n",
        "\n",
        "    interacted_items = phase_user_item_dict[phase][user_id]\n",
        "    interacted_items = interacted_items[::-1]\n",
        "\n",
        "    sim_max = 0\n",
        "    for loc, i in enumerate(interacted_items):\n",
        "        try:\n",
        "            sim = item_sim_if[phase][i][item_id]\n",
        "            if sim > sim_max:\n",
        "                sim_max = sim\n",
        "        except Exception as e:\n",
        "            pass\n",
        "    return sim_max\n",
        "\n",
        "\n",
        "def func_if_last(x):\n",
        "    user_id = x['user_id']\n",
        "    item_id = x['item_id']\n",
        "    phase = x['phase']\n",
        "\n",
        "    last_item = phase_user_item_dict[phase][user_id][-1]\n",
        "\n",
        "    sim = 0\n",
        "    try:\n",
        "        sim = item_sim_if[phase][last_item][item_id]\n",
        "    except Exception as e:\n",
        "        pass\n",
        "    return sim\n",
        "\n",
        "\n",
        "def func_if_rolling_sum(x, window):\n",
        "    user_id = x['user_id']\n",
        "    item_id = x['item_id']\n",
        "    phase = x['phase']\n",
        "\n",
        "    interacted_items = phase_user_item_dict[phase][user_id]\n",
        "    interacted_items = interacted_items[-window:]\n",
        "\n",
        "    sim_sum = 0\n",
        "    for loc, i in enumerate(interacted_items):\n",
        "        try:\n",
        "            sim_sum += item_sim_if[phase][i][item_id]\n",
        "        except Exception as e:\n",
        "            pass\n",
        "    return sim_sum\n",
        "\n",
        "\n",
        "def func_if_rolling_mean(x, window):\n",
        "    user_id = x['user_id']\n",
        "    item_id = x['item_id']\n",
        "    phase = x['phase']\n",
        "\n",
        "    interacted_items = phase_user_item_dict[phase][user_id]\n",
        "    interacted_items = interacted_items[-window:]\n",
        "\n",
        "    sim_sum = 0\n",
        "    count = 0\n",
        "    for loc, i in enumerate(interacted_items):\n",
        "        try:\n",
        "            sim_sum += item_sim_if[phase][i][item_id]\n",
        "            count += 1\n",
        "        except Exception as e:\n",
        "            pass\n",
        "    if count != 0:\n",
        "        return sim_sum / count\n",
        "    else:\n",
        "        return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOubwDUe0DTu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "623cd1f8-c3d6-4676-80a7-b63138b29639"
      },
      "source": [
        "df_feature['user_click_item_common_sim_sum'] = df_feature[[\n",
        "  'user_id', 'phase', 'item_id']].parallel_apply(func_if_sum, axis=1)\n",
        "df_feature['user_click_item_common_sim_max'] = df_feature[[\n",
        "    'user_id', 'phase', 'item_id']].parallel_apply(func_if_max, axis=1)\n",
        "df_feature['user_last_click_common_if_sim'] = df_feature[[\n",
        "    'user_id', 'phase', 'item_id']].parallel_apply(func_if_last, axis=1)\n",
        "\n",
        "df_feature['user_click_item_common_sim_rolling2_sum'] = df_feature[[\n",
        "    'user_id', 'phase', 'item_id']].parallel_apply(lambda x: func_if_rolling_sum(x, 2), axis=1)\n",
        "print(df_feature.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11489051, 66)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDoCUu_X0W0f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "79c03961-3884-466c-8458-3a07b779e8c3"
      },
      "source": [
        "del item_sim_if\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksxAs9Gb0X1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_feature.to_pickle('kdd2020_data/recall/rank_feature10.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SStH5ePQ0kLO",
        "colab_type": "text"
      },
      "source": [
        "**plus a low dimension embedding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjqJwCv9_0TN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_feature=pd.read_pickle('kdd2020_data/recall/rank_feature10.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNbeE1Vd0hTS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "acc2cc94-235d-4c21-ce36-240071ae0df2"
      },
      "source": [
        "emb_size = 8\n",
        "#it will be better to adopt a bigger num \n",
        "tmp = df_click.groupby(['user_id', 'phase'], as_index=False)['item_id'].agg({'list': list})\n",
        "sentences = tmp['list'].values.tolist()\n",
        "words = []\n",
        "for i in range(len(sentences)):\n",
        "    words += [x for x in sentences[i]]\n",
        "    sentences[i] = [str(x) for x in sentences[i]]\n",
        "\n",
        "if os.path.exists('kdd2020_data/recall/word2vec.model'):\n",
        "    model = Word2Vec.load('kdd2020_data/recall/word2vec.model')\n",
        "else:\n",
        "    model = Word2Vec(sentences, size=emb_size, window=10,\n",
        "                     min_count=1, sg=1, hs=1, seed=seed)\n",
        "    model.save('kdd2020_data/recall/word2vec.model')\n",
        "\n",
        "emb_matrix = []\n",
        "words = list(set(words))\n",
        "items = []\n",
        "for word in tqdm(words):\n",
        "    if str(word) in model:\n",
        "        items.append(word)\n",
        "        emb_matrix.append(model[str(word)])\n",
        "        \n",
        "item_w2w_vec_dict = dict(zip(items, emb_matrix))\n",
        "df_item_w2v = pd.DataFrame(emb_matrix)\n",
        "df_item_w2v.columns = ['item_w2v_{}'.format(i) for i in range(emb_size)]\n",
        "df_item_w2v['item_id'] = items\n",
        "df_feature = df_feature.merge(df_item_w2v, how='left')\n",
        "print(df_feature.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 61894/61894 [00:00<00:00, 91218.62it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(11489051, 74)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7_vtlGG1lvZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2c84a3c7-902d-45ac-ba20-bf958a872df5"
      },
      "source": [
        "print(df_feature[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   user_id  phase    query_time  item_id  label  txt_vec10_pca0  \\\n",
            "0        1      1  0.9839420823   101060    NaN   -0.0332000578   \n",
            "1        1      1  0.9839420823   102129    NaN   -2.1768086403   \n",
            "2        1      1  0.9839420823    94147    NaN   -9.1886678487   \n",
            "3        1      1  0.9839420823    92349    NaN   -4.9426130199   \n",
            "4        1      1  0.9839420823    87837    NaN  -13.0422602060   \n",
            "\n",
            "   txt_vec10_pca1  txt_vec10_pca2  txt_vec10_pca3  txt_vec10_pca4  \\\n",
            "0    6.7580501287    2.4458265697   -0.9804350560   -5.5040604974   \n",
            "1    4.5666371248   15.9105881809   -1.0408846348   -4.0750558759   \n",
            "2    4.9119086750    3.1009435427   -5.3183116031   -2.5622802797   \n",
            "3   -4.9704899321   -4.7582041896    3.6373023621   -6.4279457169   \n",
            "4    9.0589856870   -6.0331498105   -3.4983394658   -6.0602022344   \n",
            "\n",
            "   txt_vec10_pca5  txt_vec10_pca6  txt_vec10_pca7  txt_vec10_pca8  \\\n",
            "0   -3.2202888321    3.1758053886   -3.4434892283   -3.5440414567   \n",
            "1    4.0523142690   -4.7769398462    6.1718804250    1.4713313268   \n",
            "2    3.3995575176    0.7799796819    1.6439672587   -1.7728033925   \n",
            "3   -8.6122610794   -3.0105297758   -7.1083639054    2.3207251749   \n",
            "4   -6.8878974258   -4.7467398182   -1.7036563476    2.5243729208   \n",
            "\n",
            "   txt_vec10_pca9  img_vec10_pca0  img_vec10_pca1  img_vec10_pca2  \\\n",
            "0   -1.4047519048   -1.0805191610   10.3247008942    0.7374987797   \n",
            "1   -0.0460354822   -3.0467301739    2.4785345986   -0.8595316838   \n",
            "2   -0.4624512185   -7.2832617785    1.3015222343   -3.0564600487   \n",
            "3    4.1820262074    0.7936519419    1.7672469943    4.5397756615   \n",
            "4    4.8571641733  -10.9249101830    6.9157268479    2.6144772287   \n",
            "\n",
            "   img_vec10_pca3  img_vec10_pca4  img_vec10_pca5  img_vec10_pca6  \\\n",
            "0   -5.7727058134   -5.0547997144    0.0359676187    3.5001119013   \n",
            "1   -6.4483193717    2.8005296512    8.9103521173   -3.6995161386   \n",
            "2    3.0098668506    1.8821951398    3.8966564739   -1.8549841013   \n",
            "3   -7.0677665920   -6.7668036389    2.0614286626    0.4916899518   \n",
            "4   -7.1678662788   -0.8038197175    0.6443619757    0.7811042440   \n",
            "\n",
            "   img_vec10_pca7  img_vec10_pca8  img_vec10_pca9  phase_item_clickd_count  \\\n",
            "0   -4.2181561745    3.9571144595    2.1609767872                     17.0   \n",
            "1   -3.0661575689   -2.5275351852   -2.0499175195                     17.0   \n",
            "2    8.0297446083    3.0143131042    2.4921626308                      5.0   \n",
            "3   -5.2298645319   -1.0152632505    0.3705481052                     14.0   \n",
            "4   -0.1323939203   -4.0222165995    0.2352667089                     12.0   \n",
            "\n",
            "   phase_item_click_time_diff_mean  item_id_phase_user_age_level_mean  \\\n",
            "0                     0.0000094722                       3.5714285714   \n",
            "1                     0.0000115139                       5.4000000000   \n",
            "2                     0.0000394346                       2.0000000000   \n",
            "3                     0.0000103140                       4.0000000000   \n",
            "4                     0.0000176807                       3.5000000000   \n",
            "\n",
            "   item_id_phase_user_age_level_min  item_id_phase_user_age_level_max  \\\n",
            "0                               2.0                               5.0   \n",
            "1                               4.0                               8.0   \n",
            "2                               2.0                               2.0   \n",
            "3                               3.0                               5.0   \n",
            "4                               2.0                               5.0   \n",
            "\n",
            "   item_id_phase_user_age_level_std  phase_item_click_gender_mean  \\\n",
            "0                      1.1338934190                          0.00   \n",
            "1                      1.6733200531                          0.20   \n",
            "2                               NaN                          0.00   \n",
            "3                      0.8164965809                          0.25   \n",
            "4                      2.1213203436                          0.00   \n",
            "\n",
            "   user_age_level  user_gender  user_city_level  phase_user_click_count  \\\n",
            "0             NaN          NaN              NaN                       9   \n",
            "1             NaN          NaN              NaN                       9   \n",
            "2             NaN          NaN              NaN                       9   \n",
            "3             NaN          NaN              NaN                       9   \n",
            "4             NaN          NaN              NaN                       9   \n",
            "\n",
            "   phase_user_age_level_click_count  user_id_phase_time_std  \\\n",
            "0                               NaN             0.000024422   \n",
            "1                               NaN             0.000024422   \n",
            "2                               NaN             0.000024422   \n",
            "3                               NaN             0.000024422   \n",
            "4                               NaN             0.000024422   \n",
            "\n",
            "   user_id_phase_time_max_min_diff  user_id_phase_query_lastbuy_time_diff  \\\n",
            "0                     0.0000937323                           0.0000001508   \n",
            "1                     0.0000937323                           0.0000001508   \n",
            "2                     0.0000937323                           0.0000001508   \n",
            "3                     0.0000937323                           0.0000001508   \n",
            "4                     0.0000937323                           0.0000001508   \n",
            "\n",
            "   user_click_item_if_sim_sum  user_click_item_if_sim_max  \\\n",
            "0                0.0400501075                0.0400501075   \n",
            "1                0.0203474753                0.0203474753   \n",
            "2                0.0669981759                0.0669981759   \n",
            "3                0.0240708147                0.0491241117   \n",
            "4                0.0282618425                0.0690469185   \n",
            "\n",
            "   user_last_click_item_if_sim  user_click_item_if_sim_rolling2_sum  \\\n",
            "0                 0.0400501075                         0.0400501075   \n",
            "1                 0.0203474753                         0.0203474753   \n",
            "2                 0.0669981759                         0.0669981759   \n",
            "3                 0.0000000000                         0.0000000000   \n",
            "4                 0.0000000000                         0.0000000000   \n",
            "\n",
            "   user_click_item_bn_sim_sum  user_item_txt_sim  user_click_item_txt_sim_sum  \\\n",
            "0                0.2060931612       0.4875407571                 1.0867752930   \n",
            "1                0.1640923957       0.2285317812                 0.4949889135   \n",
            "2                0.1895473571       0.5574247648                 1.2237656753   \n",
            "3                0.1608667082       0.7272603827                 1.6684480986   \n",
            "4                0.1527071758       0.5591618695                 1.2545198943   \n",
            "\n",
            "   user_click_item_txt_sim_max  user_last_click_item_txt_sim  \\\n",
            "0                 0.4782942962                  0.3603658645   \n",
            "1                 0.4184795437                  0.1198822800   \n",
            "2                 0.5897804929                  0.4872517893   \n",
            "3                 0.8607653024                  0.2851907231   \n",
            "4                 0.5719658488                  0.3145756494   \n",
            "\n",
            "   user_click_item_txt_sim_rolling2_sum  \\\n",
            "0                          0.8386601607   \n",
            "1                          0.5383618237   \n",
            "2                          1.0770322822   \n",
            "3                          0.8092110152   \n",
            "4                          0.8865414982   \n",
            "\n",
            "   user_click_item_txt_sim_rolling2_mean  \\\n",
            "0                           0.4193300804   \n",
            "1                           0.2691809119   \n",
            "2                           0.5385161411   \n",
            "3                           0.4046055076   \n",
            "4                           0.4432707491   \n",
            "\n",
            "   user_click_item_txt_sim_rolling3_mean  user_item_img_sim  \\\n",
            "0                           0.3694248213      -0.1675064749   \n",
            "1                           0.2009857378      -0.0036695947   \n",
            "2                           0.4443331234      -0.0499948765   \n",
            "3                           0.5175642622      -0.0153030475   \n",
            "4                           0.4343267802      -0.1346725787   \n",
            "\n",
            "   user_click_item_tc_sim_sum  user_click_item_tc_sim_max  \\\n",
            "0                0.0019529755                0.0019529755   \n",
            "1                0.0014159819                0.0014159819   \n",
            "2                0.0037058675                0.0037058675   \n",
            "3                0.0050261766                0.0050261766   \n",
            "4                0.0063923379                0.0034455543   \n",
            "\n",
            "   user_click_item_tc_sim_rolling2_sum  user_last_click_item_w2w_sim  \\\n",
            "0                         0.0019529755                  0.4468453526   \n",
            "1                         0.0014159819                  0.4528516829   \n",
            "2                         0.0037058675                  0.5515706539   \n",
            "3                         0.0000000000                  0.3153794408   \n",
            "4                         0.0000000000                  0.3061614037   \n",
            "\n",
            "   user_click_item_w2w_sim_sum_2  user_last_click_item_deepwalk_sim  \\\n",
            "0                   0.6004013419                       0.4024359584   \n",
            "1                   0.7391204238                       0.1367129683   \n",
            "2                   0.8463729322                       0.6443635821   \n",
            "3                   0.5474252999                       0.2334325463   \n",
            "4                   0.5412856191                       0.0078991186   \n",
            "\n",
            "   user_click_item_deepwalk_sim_sum_2  user_last_click_item_n2v_sim  \\\n",
            "0                        0.6042726636                  0.5650578737   \n",
            "1                        0.2870390266                  0.1509240568   \n",
            "2                        1.0071338117                  0.6129270792   \n",
            "3                        0.4655575454                  0.2343081087   \n",
            "4                        0.1122677680                  0.0148069067   \n",
            "\n",
            "   user_click_item_n2v_sim_sum_2  user_click_item_common_sim_sum  \\\n",
            "0                   0.7618068606                     0.000000000   \n",
            "1                   0.1084156148                     0.000000000   \n",
            "2                   1.1346628070                     0.000000000   \n",
            "3                   0.5205992311                     0.001097649   \n",
            "4                  -0.0526197748                     0.000000000   \n",
            "\n",
            "   user_click_item_common_sim_max  user_last_click_common_if_sim  \\\n",
            "0                           0.000                            0.0   \n",
            "1                           0.000                            0.0   \n",
            "2                           0.000                            0.0   \n",
            "3                           0.002                            0.0   \n",
            "4                           0.000                            0.0   \n",
            "\n",
            "   user_click_item_common_sim_rolling2_sum    item_w2v_0    item_w2v_1  \\\n",
            "0                                      0.0  0.0362549759  0.4140025079   \n",
            "1                                      0.0  0.2583474219 -0.4907061160   \n",
            "2                                      0.0 -0.4437107742  0.6012257934   \n",
            "3                                      0.0 -0.0993281826 -0.1222960353   \n",
            "4                                      0.0  0.1410841346 -0.2899507582   \n",
            "\n",
            "     item_w2v_2    item_w2v_3    item_w2v_4    item_w2v_5    item_w2v_6  \\\n",
            "0  0.0928555652  1.4888186455  0.1782057583 -0.5997493863 -0.8491199017   \n",
            "1  1.4354695082  1.7119598389  1.0541996956 -0.1339686215 -0.5721409917   \n",
            "2 -0.3170594275  1.2992721796 -0.2043489069 -0.2148962021 -1.1002122164   \n",
            "3  0.4545617998  0.6520951986  0.0070799636  0.6574224830 -1.0509569645   \n",
            "4 -0.0172832292  0.2417341769 -0.7331549525  0.2949186563 -1.1820083857   \n",
            "\n",
            "     item_w2v_7  \n",
            "0 -0.0341746807  \n",
            "1  0.0303222649  \n",
            "2  0.4000023305  \n",
            "3 -0.2042080611  \n",
            "4 -0.2546038628  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3wX2hxs1pY4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "a3e85c16-dc02-4e02-884c-9e4efd8e61b7"
      },
      "source": [
        "print(df_feature.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['user_id', 'phase', 'query_time', 'item_id', 'label', 'txt_vec10_pca0',\n",
            "       'txt_vec10_pca1', 'txt_vec10_pca2', 'txt_vec10_pca3', 'txt_vec10_pca4',\n",
            "       'txt_vec10_pca5', 'txt_vec10_pca6', 'txt_vec10_pca7', 'txt_vec10_pca8',\n",
            "       'txt_vec10_pca9', 'img_vec10_pca0', 'img_vec10_pca1', 'img_vec10_pca2',\n",
            "       'img_vec10_pca3', 'img_vec10_pca4', 'img_vec10_pca5', 'img_vec10_pca6',\n",
            "       'img_vec10_pca7', 'img_vec10_pca8', 'img_vec10_pca9',\n",
            "       'phase_item_clickd_count', 'phase_item_click_time_diff_mean',\n",
            "       'item_id_phase_user_age_level_mean', 'item_id_phase_user_age_level_min',\n",
            "       'item_id_phase_user_age_level_max', 'item_id_phase_user_age_level_std',\n",
            "       'phase_item_click_gender_mean', 'user_age_level', 'user_gender',\n",
            "       'user_city_level', 'phase_user_click_count',\n",
            "       'phase_user_age_level_click_count', 'user_id_phase_time_std',\n",
            "       'user_id_phase_time_max_min_diff',\n",
            "       'user_id_phase_query_lastbuy_time_diff', 'user_click_item_if_sim_sum',\n",
            "       'user_click_item_if_sim_max', 'user_last_click_item_if_sim',\n",
            "       'user_click_item_if_sim_rolling2_sum', 'user_click_item_bn_sim_sum',\n",
            "       'user_item_txt_sim', 'user_click_item_txt_sim_sum',\n",
            "       'user_click_item_txt_sim_max', 'user_last_click_item_txt_sim',\n",
            "       'user_click_item_txt_sim_rolling2_sum',\n",
            "       'user_click_item_txt_sim_rolling2_mean',\n",
            "       'user_click_item_txt_sim_rolling3_mean', 'user_item_img_sim',\n",
            "       'user_click_item_tc_sim_sum', 'user_click_item_tc_sim_max',\n",
            "       'user_click_item_tc_sim_rolling2_sum', 'user_last_click_item_w2w_sim',\n",
            "       'user_click_item_w2w_sim_sum_2', 'user_last_click_item_deepwalk_sim',\n",
            "       'user_click_item_deepwalk_sim_sum_2', 'user_last_click_item_n2v_sim',\n",
            "       'user_click_item_n2v_sim_sum_2', 'user_click_item_common_sim_sum',\n",
            "       'user_click_item_common_sim_max', 'user_last_click_common_if_sim',\n",
            "       'user_click_item_common_sim_rolling2_sum', 'item_w2v_0', 'item_w2v_1',\n",
            "       'item_w2v_2', 'item_w2v_3', 'item_w2v_4', 'item_w2v_5', 'item_w2v_6',\n",
            "       'item_w2v_7'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbhUWGLu1dsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del item_w2w_vec_dict,df_item_w2v\n",
        "gc.collect()\n",
        "df_feature.to_pickle('kdd2020_data/recall/rank_feature11.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haSN1i6x7GRO",
        "colab_type": "text"
      },
      "source": [
        "# Rank_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blsaHleLJCd1",
        "colab_type": "text"
      },
      "source": [
        "**LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQicuRiH56Gb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "d4917fc0-598b-4464-ca4a-a181ff182ff0"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import lightgbm as lgb\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "import gc\n",
        "from collections import defaultdict  \n",
        "import math  \n",
        "import random\n",
        "from random import sample\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "from sklearn.model_selection import train_test_split\n",
        "import scipy.sparse as sp\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,Activation,Input,Convolution1D,Conv1D,GlobalMaxPooling1D,MaxPooling1D,Flatten,concatenate,Embedding,GRU,Lambda, LSTM, TimeDistributed\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.models import model_from_json\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import load_model,Model\n",
        "from keras.layers import Dense, Embedding, LSTM,Flatten,BatchNormalization\n",
        "from gensim.models import word2vec \n",
        "import keras\n",
        "import time\n",
        "from keras.optimizers import *\n",
        "from keras.callbacks import *\n",
        "pd.set_option('display.max_rows',200)\n",
        "\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TJYXP0U6py8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "whole_click = pd.DataFrame()  \n",
        "for c in range(3):  \n",
        "    click_train = pd.read_csv('kdd2020_data/underexpose_train/underexpose_train_click-{}.csv'.format(c), header=None,  names=['user_id', 'item_id', 'time'])  \n",
        "    click_test = pd.read_csv('kdd2020_data/underexpose_test/underexpose_test_click-{}.csv'.format(c), header=None,  names=['user_id', 'item_id', 'time'])  \n",
        "    all_click = click_train.append(click_test)  \n",
        "    whole_click = whole_click.append(all_click)  \n",
        "\n",
        "whole_click = whole_click.drop_duplicates(subset=['user_id','item_id','time'])\n",
        "whole_click = whole_click.sort_values('time',ascending=True)   \n",
        "whole_click = whole_click.reset_index(drop=True)\n",
        "for col in ['item_id','time']:#,'time_interval_cumsum']:\n",
        "    whole_click[col]=whole_click[col].astype(str)\n",
        "\n",
        "whole_item_df = whole_click.groupby('user_id').agg(\n",
        "                                item_list = pd.NamedAgg(column = 'item_id',aggfunc=(lambda x : list(x))),\n",
        "                                time_list = pd.NamedAgg(column = 'time',aggfunc=(lambda x : list(x))),\n",
        "                                ).reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_PJe1e6Ca6d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3eb4dbed-bb88-437d-959c-e3a539592b66"
      },
      "source": [
        "#generate positive samples\n",
        "positive_df = []\n",
        "#for each seq, we only consider of last 5 words\n",
        "last_n = 5\n",
        "for i in tqdm(whole_item_df.index):\n",
        "    user_id = whole_item_df.loc[i,'user_id']\n",
        "    item_list = whole_item_df.loc[i,'item_list']\n",
        "    time_list = whole_item_df.loc[i,'time_list']\n",
        "    if len(item_list)<=1: \n",
        "        continue\n",
        "    if len(item_list)<last_n: \n",
        "        for j in range(3,len(item_list)+1):\n",
        "            positive_df.append([user_id,' '.join(item_list[:j]),time_list[j-1]])\n",
        "    else:\n",
        "        for j in range(3,last_n):\n",
        "            positive_df.append([user_id,' '.join(item_list[:j]),time_list[j-1]])\n",
        "        for j in range(last_n,len(item_list)+1,1):\n",
        "            recent_item_list = item_list[j-last_n:j]\n",
        "            positive_df.append([user_id,' '.join(recent_item_list),time_list[j-1]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23816/23816 [00:01<00:00, 15331.45it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHuksxuLDbwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#the last one as label\n",
        "train_set_df_p = pd.DataFrame(positive_df,columns=['user_id','recent_items','time'])\n",
        "train_set_df_p['label'] = 1\n",
        "train_set_df_p['target_item'] = train_set_df_p['recent_items'].apply(lambda x : x.split(' ')[-1])\n",
        "train_set_df_p['recent_items'] = train_set_df_p['recent_items'].apply(lambda x : ' '.join(x.split(' ')[:-1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLgQRXYXDoHP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fad4b8b1-29ec-4d05-bdb7-060d65e30d2a"
      },
      "source": [
        "#generate negative samples 50:1\n",
        "negative_ratio = 50\n",
        "negative_list = whole_click['item_id'].sample(len(train_set_df_p)*negative_ratio,replace=True).values.tolist()\n",
        "train_set_df = train_set_df_p[['user_id','time','target_item','label']].copy()\n",
        "for i in tqdm(range(negative_ratio)):\n",
        "    tmp_negative_list = negative_list[i*len(train_set_df_p):(i+1)*len(train_set_df_p)]\n",
        "    tmp_df = train_set_df_p[['user_id','time','target_item','label']].copy()\n",
        "    tmp_df['target_item']=tmp_negative_list\n",
        "    tmp_df['label'] = 0\n",
        "    train_set_df=train_set_df.append(tmp_df,ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:44<00:00,  1.12it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxf5oVogEN85",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#combine user info\n",
        "user_data = pd.read_csv('kdd2020_data/underexpose_train/underexpose_user_feat.csv',names=['user_id', 'user_age_level', 'user_gender', 'user_city_level'])\n",
        "user_data = pd.concat([user_data,pd.get_dummies(user_data['user_gender'])],axis=1)\n",
        "user_data = user_data.drop_duplicates(subset=['user_id'])\n",
        "user_data.drop(columns=['user_gender'],inplace=True)\n",
        "\n",
        "train_set_df_p = train_set_df_p.merge(user_data,on='user_id',how='left')\n",
        "\n",
        "scaler_user = sklearn.preprocessing.StandardScaler()\n",
        "scaler_user.fit(train_set_df_p[['user_age_level', 'user_city_level','F', 'M']])\n",
        "train_set_df_p[['user_age_level', 'user_city_level','F', 'M']] = scaler_user.transform(train_set_df_p[['user_age_level', 'user_city_level','F', 'M']])\n",
        "\n",
        "train_set_df_p['user_age_level'].fillna(0,inplace=True)\n",
        "train_set_df_p['user_city_level'].fillna(0,inplace=True)\n",
        "train_set_df_p['F'].fillna(0,inplace=True)\n",
        "train_set_df_p['M'].fillna(0,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ou0-y1gdEU6E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "393f54b0-1929-41de-d2fe-515cf333986c"
      },
      "source": [
        "#filter the click who's occur time after qtime\n",
        "test_query = pd.DataFrame()\n",
        "for c in range(3):  \n",
        "    tmp_query = pd.read_csv('kdd2020_data/underexpose_test/underexpose_test_qtime-{}.csv'.format(c), header=None,  names=['user_id', 'query_time'])  \n",
        "    test_query = test_query.append(tmp_query,ignore_index=True)\n",
        "    \n",
        "whole_click=whole_click.sort_values(by =['user_id','time'],ascending=False).reset_index(drop=True)    \n",
        "whole_click['time']=whole_click['time'].astype('float64')\n",
        "recent_items_df = pd.DataFrame()\n",
        "for i in tqdm(test_query.index):\n",
        "    user = test_query.loc[i,'user_id']\n",
        "    time = test_query.loc[i,'query_time']\n",
        "    time_left = str(whole_click.loc[(whole_click['user_id']==user)&(whole_click['time']<time)]['time'].max())\n",
        "    time_right =  str(whole_click.loc[(whole_click['user_id']==user)&(whole_click['time']>time)]['time'].min())\n",
        "    recent_items_df =recent_items_df.append([{'user_id':user,'time':time_left,'isval':1},{'user_id':user,'time':time_right,'isval':2}],ignore_index=True)\n",
        "recent_items_df = recent_items_df[recent_items_df['time']!='nan']\n",
        "train_set_df = train_set_df.merge(recent_items_df,on=['user_id','time'],how='left')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5079/5079 [00:30<00:00, 168.74it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEUJ3TdkEmvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_set_df = train_set_df[train_set_df['isval']==1].reset_index(drop=True)\n",
        "train_set_df = train_set_df[train_set_df['isval'].isnull()].reset_index(drop=True)\n",
        "\n",
        "#train:val=19:1\n",
        "val_data_ratio = 20\n",
        "random.seed(2020)\n",
        "sample_ind = sample(range(train_set_df.label.sum()),train_set_df.label.sum()//val_data_ratio)\n",
        "train_sample_ind = list(set(list(range(train_set_df.label.sum()))) - set(sample_ind))\n",
        "val_sample_ind = sample_ind[:len(sample_ind)]\n",
        "\n",
        "val_sample_ind_all = []\n",
        "for i in range(negative_ratio+1):\n",
        "    tmp_ind = np.add(val_sample_ind,train_set_df.label.sum()*i)\n",
        "    val_sample_ind_all.extend(tmp_ind)\n",
        "\n",
        "train_sample_ind_all = []\n",
        "for i in range(negative_ratio+1):\n",
        "    tmp_ind = np.add(train_sample_ind,train_set_df.label.sum()*i)\n",
        "    train_sample_ind_all.extend(tmp_ind)\n",
        "    \n",
        "\n",
        "test_len = test_set_df.shape[0]\n",
        "train_set_df = train_set_df.append(test_set_df,ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2icB4AiREuH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "whole_item_df['item_list'] = whole_item_df['item_list'].apply(lambda x : ' '.join([str(i) for i in x]))\n",
        "max_word_len = whole_click.item_id.nunique()\n",
        "tokenizer = Tokenizer(num_words=max_word_len, split=' ')\n",
        "tokenizer.fit_on_texts(whole_item_df['item_list'])\n",
        "recent_items_list = pad_sequences(tokenizer.texts_to_sequences(train_set_df_p['recent_items']))\n",
        "train_set_df_p['recent_items5'] = recent_items_list.tolist()\n",
        "train_set_df['target_item'] = pad_sequences(tokenizer.texts_to_sequences(train_set_df['target_item'])).tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQNheUmrE0zL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_set_df = train_set_df[-test_len:]\n",
        "val_set_df = train_set_df.loc[val_sample_ind_all]\n",
        "train_set_df = train_set_df.loc[train_sample_ind_all]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Chgp-2CFDCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set_df['target']=train_set_df['target_item'].apply(lambda x :x[0])\n",
        "train_set_df.drop_duplicates(subset=['user_id','time','target'],keep='first',inplace=True)\n",
        "train_set_df.drop(columns=['target','isval'],inplace = True)\n",
        "\n",
        "val_set_df['target']=val_set_df['target_item'].apply(lambda x :x[0])\n",
        "val_set_df.drop_duplicates(subset=['user_id','time','target'],keep='first',inplace=True)\n",
        "val_set_df.drop(columns=['target','isval'],inplace = True)\n",
        "\n",
        "test_set_df['target']=test_set_df['target_item'].apply(lambda x :x[0])\n",
        "test_set_df.drop_duplicates(subset=['user_id','time','target'],keep='first',inplace=True)\n",
        "test_set_df.drop(columns=['target','isval'],inplace = True)\n",
        "\n",
        "train_set_df = train_set_df.reset_index(drop=True)\n",
        "val_set_df = val_set_df.reset_index(drop=True)\n",
        "test_set_df = test_set_df.reset_index(drop=True)\n",
        "\n",
        "train_set_df_p.drop(columns=['target_item','label'],inplace=True,errors='ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf4xIKsSFk85",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class data_generator:\n",
        "    def __init__(self, data, batch_size=128):\n",
        "        self.data = data\n",
        "        self.batch_size = batch_size\n",
        "        self.steps = len(self.data) // self.batch_size\n",
        "        if len(self.data) % self.batch_size != 0:\n",
        "            self.steps += 1\n",
        "    def __len__(self):\n",
        "        return self.steps\n",
        "\n",
        "    def __iter__(self):\n",
        "        global train_set_df_p\n",
        "        while True:\n",
        "            train_set = self.data\n",
        "            idxs = list(range(len(self.data)))\n",
        "            np.random.shuffle(idxs)\n",
        "            index_list = []\n",
        "            X1,  X3 ,Y = [], [], []\n",
        "            for c, i in enumerate(idxs):\n",
        "                index_list.append(i)\n",
        "                if len(index_list) == self.batch_size or i == idxs[-1]:\n",
        "                    tmp_df = train_set.loc[index_list]\n",
        "                    tmp_df = tmp_df.merge(train_set_df_p,on=['user_id','time'])\n",
        "                    tmp_df['recent_items5'] = tmp_df['recent_items5']+tmp_df['target_item']\n",
        "                    X1 = np.array(tmp_df['recent_items5'].values.tolist())\n",
        "                    X3 = np.array(tmp_df[['user_age_level', 'user_city_level','F', 'M']].values.tolist())\n",
        "                    Y = np.array(tmp_df['label'].values.tolist())\n",
        "                    yield [X1,X3], Y\n",
        "                    tmp_df = pd.DataFrame()\n",
        "                    X1, X3 ,Y = [],  [] ,[]\n",
        "                    index_list = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRIBaehrFowr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "outputId": "99d71e44-d463-437b-bb22-af7148e6a1fc"
      },
      "source": [
        "last_n=5\n",
        "embed_size=32\n",
        "model = Sequential()\n",
        "seq = Input(shape=[last_n])\n",
        "emb = Embedding(\n",
        "           max_word_len+1,       \n",
        "           embed_size,                \n",
        "           trainable=True)(seq)       \n",
        "lstm_1 = LSTM(embed_size, input_shape=(last_n, embed_size),return_sequences=True)(emb)\n",
        "lstm_2 = LSTM(embed_size)(lstm_1)\n",
        "input_2 = Input(shape=[4,])\n",
        "merge = concatenate([lstm_2,input_2])\n",
        "mlp = Dense(units=100,activation='relu')(merge)\n",
        "mlp = Dropout(0.3)(mlp)\n",
        "mlp=  BatchNormalization()(mlp)\n",
        "output = Dense(units=1,activation='sigmoid')(mlp)\n",
        "\n",
        "model = Model([seq,input_2],output)\n",
        "print(model.summary())\n",
        "model.compile( optimizer=keras.optimizers.RMSprop(1e-3),loss=keras.losses.BinaryCrossentropy(),metrics=[keras.metrics.AUC()])\n",
        "\n",
        "filepath = \"kdd2020_data/recall/lstm_.h5\" \n",
        "monitor_name = 'val_auc_1'\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath, monitor=monitor_name, verbose=1, save_best_only=True, mode='max')\n",
        "reduce_lr2 = ReduceLROnPlateau(\n",
        "    monitor=monitor_name, factor=0.8, patience=1, min_lr=0.0001, verbose=1)\n",
        "earlystopping2 = EarlyStopping(\n",
        "    monitor=monitor_name, min_delta=0.0001, patience=2, verbose=1, mode='max')\n",
        "callbacks2 = [checkpoint, earlystopping2 ,reduce_lr2]\n",
        "train_D = data_generator(train_set_df,batch_size=8192)\n",
        "valid_D = data_generator(val_set_df,batch_size=8192)\n",
        "model.fit_generator(train_D.__iter__(),validation_data=valid_D.__iter__(),validation_steps=len(valid_D),steps_per_epoch=len(train_D),epochs=10, shuffle=True,callbacks=callbacks2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 5)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 5, 32)        1980992     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 5, 32)        8320        embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 32)           8320        lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 4)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 36)           0           lstm_2[0][0]                     \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 100)          3700        concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 100)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 100)          400         dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            101         batch_normalization_1[0][0]      \n",
            "==================================================================================================\n",
            "Total params: 2,001,833\n",
            "Trainable params: 2,001,633\n",
            "Non-trainable params: 200\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2496/2496 [==============================] - 728s 292ms/step - loss: 0.1099 - auc_1: 0.5001 - val_loss: 0.1022 - val_auc_1: 0.5000\n",
            "\n",
            "Epoch 00001: val_auc_1 improved from -inf to 0.50000, saving model to kdd2020_data/recall/lstm_.h5\n",
            "Epoch 2/10\n",
            "2496/2496 [==============================] - 727s 291ms/step - loss: 0.0966 - auc_1: 0.5003 - val_loss: 0.1116 - val_auc_1: 0.5000\n",
            "\n",
            "Epoch 00002: val_auc_1 did not improve from 0.50000\n",
            "\n",
            "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
            "Epoch 3/10\n",
            "2496/2496 [==============================] - 719s 288ms/step - loss: 0.0966 - auc_1: 0.5001 - val_loss: 0.1048 - val_auc_1: 0.5000\n",
            "\n",
            "Epoch 00003: val_auc_1 did not improve from 0.50000\n",
            "\n",
            "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
            "Epoch 00003: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fb160057f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y89uKcYvHl3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_D = data_generator(test_set_df.reset_index(drop=True),batch_size=8192)\n",
        "model.evaluate_generator(test_D.__iter__(),steps=len(test_D))\n",
        "model = load_model('kdd2020_data/recall/lstm_.h5',compile=False)\n",
        "model.compile( optimizer=keras.optimizers.RMSprop(1e-3),loss=keras.losses.BinaryCrossentropy(),metrics=[keras.metrics.AUC()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qztn-2Rl9iIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_feature(train_set_df , query_df,whole_click,isval=False):\n",
        "    recent_items_df = pd.DataFrame()\n",
        "    last_n=5\n",
        "    for i in tqdm(query_df.index):\n",
        "        user = query_df.loc[i,'user_id']\n",
        "        time = query_df.loc[i,'query_time']\n",
        "        phase = query_df.loc[i,'phase']\n",
        "        recent_items = ' '.join([str(i) for i in  whole_click.loc[(whole_click['user_id']==user)&(whole_click['time']<time)&(whole_click['phase']==phase)]['item_id'][:last_n-1].values.tolist()[::-1]])\n",
        "        recent_items_df = recent_items_df.append({'user_id':user,'query_time':time,'recent_items_5':recent_items,'phase':phase},ignore_index=True)\n",
        "    train_set_df = train_set_df.merge(recent_items_df,on=['user_id','query_time','phase'])\n",
        "    train_set_df['recent_items_5'] = train_set_df['recent_items_5']+' '+ train_set_df['item_id'].astype(str)\n",
        "#     tokenizer = joblib.load('./tokenizer.m')\n",
        "#     scaler_user = joblib.load('./user_info_std_scalar.m')\n",
        "    user_data = pd.read_csv('kdd2020_data/underexpose_train/underexpose_user_feat.csv',names=['user_id', 'user_age_level', 'user_gender', 'user_city_level'])\n",
        "    user_data = pd.concat([user_data,pd.get_dummies(user_data['user_gender'])],axis=1)\n",
        "    user_data = user_data.drop_duplicates(subset=['user_id'])\n",
        "    user_data.drop(columns=['user_gender'],inplace=True)\n",
        "    train_set_df = train_set_df.merge(user_data,on='user_id',how='left')\n",
        "    train_set_df[['user_age_level', 'user_city_level','F', 'M']] = scaler_user.transform(train_set_df[['user_age_level', 'user_city_level','F', 'M']])\n",
        "    train_set_df['user_age_level'].fillna(0,inplace=True)\n",
        "    train_set_df['user_city_level'].fillna(0,inplace=True)\n",
        "    train_set_df['F'].fillna(0,inplace=True)\n",
        "    train_set_df['M'].fillna(0,inplace=True)\n",
        "    X = tokenizer.texts_to_sequences(train_set_df['recent_items_5'])\n",
        "    X = pad_sequences(X)\n",
        "    if isval:\n",
        "        return X,train_set_df[['user_age_level', 'user_city_level','F', 'M']],train_set_df['label']\n",
        "        #return train_set_df\n",
        "    else:\n",
        "        return X,train_set_df[['user_age_level', 'user_city_level','F', 'M']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNAHqbM4LQNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_recall = pd.read_pickle('kdd2020_data/my_model/recall.pkl')\n",
        "final_recall = final_recall[['user_id', 'phase', 'query_time', 'item_id', 'label']]\n",
        "train_set_df = final_recall[~final_recall['label'].isnull()].reset_index(drop=True)\n",
        "test_set_df = final_recall[final_recall['label'].isnull()].reset_index(drop=True)\n",
        "query_df = train_set_df[train_set_df['label']==1]\n",
        "\n",
        "\n",
        "whole_click = pd.DataFrame()  \n",
        "for c in range(3):  \n",
        "    click_train = pd.read_csv('kdd2020_data/underexpose_train/underexpose_train_click-{}.csv'.format(c), header=None,  names=['user_id', 'item_id', 'time'])  \n",
        "    click_test = pd.read_csv('kdd2020_data/underexpose_test/underexpose_test_click-{}.csv'.format(c), header=None,  names=['user_id', 'item_id', 'time'])  \n",
        "    all_click = click_train.append(click_test)  \n",
        "    all_click['phase']=c\n",
        "    whole_click = whole_click.append(all_click)  \n",
        "whole_click = whole_click.drop_duplicates(subset=['user_id','item_id','time','phase'])\n",
        "whole_click = whole_click.sort_values(by =['user_id','time'],ascending=False).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkW8PzEuLzet",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "989da7fc-f9ef-455a-a1d3-c7c79f62d99d"
      },
      "source": [
        "X_1,X_2,y = get_feature(train_set_df,query_df,whole_click,isval=True)\n",
        "train_set_df['pred'] = model.predict([X_1,X_2],batch_size=4096)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14131/14131 [01:59<00:00, 118.35it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2unMoT_wL2xh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5ebb7065-2f74-48bd-b1a6-4ddc8b8690ee"
      },
      "source": [
        "test_query = test_set_df.drop_duplicates(['user_id','phase','query_time'])\n",
        "test_x_1,test_x_2 =get_feature(whole_click=whole_click,train_set_df=test_set_df,query_df=test_query,isval=False,)\n",
        "test_set_df['pred'] = model.predict([test_x_1,test_x_2 ],batch_size=4096)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5079/5079 [00:42<00:00, 120.44it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmTQ5oh-L5HX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_all = train_set_df.append(test_set_df,ignore_index=True)\n",
        "data_all.to_pickle('kdd2020_data/recall/lstm_rank.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzB1efIarF7O",
        "colab_type": "text"
      },
      "source": [
        "# Rank_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nojmAqncVVQX",
        "colab_type": "text"
      },
      "source": [
        "**transformer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThI8DpomrKmD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "c4102b9e-75c0-4fe0-86f9-7bd2b7a0ee3d"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import lightgbm as lgb\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "import gc\n",
        "from collections import defaultdict  \n",
        "import math  \n",
        "import random\n",
        "from random import sample\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "from sklearn.model_selection import train_test_split\n",
        "import scipy.sparse as sp\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,Activation,Input,Convolution1D,Conv1D,GlobalMaxPooling1D,MaxPooling1D,Flatten,concatenate,Embedding,GRU,Lambda, LSTM, TimeDistributed\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.models import model_from_json\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import load_model,Model\n",
        "from keras.layers import Dense, Embedding, LSTM,Flatten,BatchNormalization\n",
        "from gensim.models import word2vec \n",
        "import keras\n",
        "import time\n",
        "from keras.optimizers import *\n",
        "from keras.callbacks import *\n",
        "pd.set_option('display.max_rows',200)\n",
        "\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEYsXejX0ywQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "whole_click = pd.DataFrame()  \n",
        "for c in range(3):  \n",
        "    click_train = pd.read_csv('kdd2020_data/underexpose_train/underexpose_train_click-{}.csv'.format(c), header=None,  names=['user_id', 'item_id', 'time'])  \n",
        "    click_test = pd.read_csv('kdd2020_data/underexpose_test/underexpose_test_click-{}.csv'.format(c), header=None,  names=['user_id', 'item_id', 'time'])  \n",
        "    all_click = click_train.append(click_test)  \n",
        "    whole_click = whole_click.append(all_click)  \n",
        "\n",
        "whole_click = whole_click.drop_duplicates(subset=['user_id','item_id','time'])\n",
        "whole_click = whole_click.sort_values('time',ascending=True)   \n",
        "whole_click = whole_click.reset_index(drop=True)\n",
        "for col in ['item_id','time']:#,'time_interval_cumsum']:\n",
        "    whole_click[col]=whole_click[col].astype(str)\n",
        "\n",
        "whole_item_df = whole_click.groupby('user_id').agg(\n",
        "                                item_list = pd.NamedAgg(column = 'item_id',aggfunc=(lambda x : list(x))),\n",
        "                                time_list = pd.NamedAgg(column = 'time',aggfunc=(lambda x : list(x))),\n",
        "                                ).reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDaOwS6o05-q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f94e598b-77dc-4c2f-88d2-8f21f3369511"
      },
      "source": [
        "#generate positive samples\n",
        "positive_df = []\n",
        "#for each seq, we only consider of last 5 words\n",
        "last_n = 5\n",
        "for i in tqdm(whole_item_df.index):\n",
        "    user_id = whole_item_df.loc[i,'user_id']\n",
        "    item_list = whole_item_df.loc[i,'item_list']\n",
        "    time_list = whole_item_df.loc[i,'time_list']\n",
        "    if len(item_list)<=1: \n",
        "        continue\n",
        "    if len(item_list)<last_n: \n",
        "        for j in range(3,len(item_list)+1):\n",
        "            positive_df.append([user_id,' '.join(item_list[:j]),time_list[j-1]])\n",
        "    else:\n",
        "        for j in range(3,last_n):\n",
        "            positive_df.append([user_id,' '.join(item_list[:j]),time_list[j-1]])\n",
        "        for j in range(last_n,len(item_list)+1,1):\n",
        "            recent_item_list = item_list[j-last_n:j]\n",
        "            positive_df.append([user_id,' '.join(recent_item_list),time_list[j-1]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23816/23816 [00:01<00:00, 15343.91it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBAi5sQz08-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#the last one as label\n",
        "train_set_df_p = pd.DataFrame(positive_df,columns=['user_id','recent_items','time'])\n",
        "train_set_df_p['label'] = 1\n",
        "train_set_df_p['target_item'] = train_set_df_p['recent_items'].apply(lambda x : x.split(' ')[-1])\n",
        "train_set_df_p['recent_items'] = train_set_df_p['recent_items'].apply(lambda x : ' '.join(x.split(' ')[:-1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZPf_1l41CJ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5c3aa051-7719-4a0d-dc78-207986b7886f"
      },
      "source": [
        "#generate negative samples 50:1\n",
        "negative_ratio = 50\n",
        "negative_list = whole_click['item_id'].sample(len(train_set_df_p)*negative_ratio,replace=True).values.tolist()\n",
        "train_set_df = train_set_df_p[['user_id','time','target_item','label']].copy()\n",
        "for i in tqdm(range(negative_ratio)):\n",
        "    tmp_negative_list = negative_list[i*len(train_set_df_p):(i+1)*len(train_set_df_p)]\n",
        "    tmp_df = train_set_df_p[['user_id','time','target_item','label']].copy()\n",
        "    tmp_df['target_item']=tmp_negative_list\n",
        "    tmp_df['label'] = 0\n",
        "    train_set_df=train_set_df.append(tmp_df,ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:46<00:00,  1.07it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yu2_wyWf1Kll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#combine user info\n",
        "user_data = pd.read_csv('kdd2020_data/underexpose_train/underexpose_user_feat.csv',names=['user_id', 'user_age_level', 'user_gender', 'user_city_level'])\n",
        "user_data = pd.concat([user_data,pd.get_dummies(user_data['user_gender'])],axis=1)\n",
        "user_data = user_data.drop_duplicates(subset=['user_id'])\n",
        "user_data.drop(columns=['user_gender'],inplace=True)\n",
        "\n",
        "train_set_df_p = train_set_df_p.merge(user_data,on='user_id',how='left')\n",
        "\n",
        "scaler_user = sklearn.preprocessing.StandardScaler()\n",
        "scaler_user.fit(train_set_df_p[['user_age_level', 'user_city_level','F', 'M']])\n",
        "train_set_df_p[['user_age_level', 'user_city_level','F', 'M']] = scaler_user.transform(train_set_df_p[['user_age_level', 'user_city_level','F', 'M']])\n",
        "\n",
        "train_set_df_p['user_age_level'].fillna(0,inplace=True)\n",
        "train_set_df_p['user_city_level'].fillna(0,inplace=True)\n",
        "train_set_df_p['F'].fillna(0,inplace=True)\n",
        "train_set_df_p['M'].fillna(0,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-otxKc1k1Ue5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25044ef7-9d3d-4aad-8184-09d2bac8ecc2"
      },
      "source": [
        "#filter the click who's occur time after qtime\n",
        "test_query = pd.DataFrame()\n",
        "for c in range(3):  \n",
        "    tmp_query = pd.read_csv('kdd2020_data/underexpose_test/underexpose_test_qtime-{}.csv'.format(c), header=None,  names=['user_id', 'query_time'])  \n",
        "    test_query = test_query.append(tmp_query,ignore_index=True)\n",
        "    \n",
        "whole_click=whole_click.sort_values(by =['user_id','time'],ascending=False).reset_index(drop=True)    \n",
        "whole_click['time']=whole_click['time'].astype('float64')\n",
        "recent_items_df = pd.DataFrame()\n",
        "for i in tqdm(test_query.index):\n",
        "    user = test_query.loc[i,'user_id']\n",
        "    time = test_query.loc[i,'query_time']\n",
        "    time_left = str(whole_click.loc[(whole_click['user_id']==user)&(whole_click['time']<time)]['time'].max())\n",
        "    time_right =  str(whole_click.loc[(whole_click['user_id']==user)&(whole_click['time']>time)]['time'].min())\n",
        "    recent_items_df =recent_items_df.append([{'user_id':user,'time':time_left,'isval':1},{'user_id':user,'time':time_right,'isval':2}],ignore_index=True)\n",
        "recent_items_df = recent_items_df[recent_items_df['time']!='nan']\n",
        "train_set_df = train_set_df.merge(recent_items_df,on=['user_id','time'],how='left')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5079/5079 [00:29<00:00, 172.10it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEZTCCdZ1Yuc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_set_df = train_set_df[train_set_df['isval']==1].reset_index(drop=True)\n",
        "train_set_df = train_set_df[train_set_df['isval'].isnull()].reset_index(drop=True)\n",
        "\n",
        "#train:val=19:1\n",
        "val_data_ratio = 20\n",
        "random.seed(2020)\n",
        "sample_ind = sample(range(train_set_df.label.sum()),train_set_df.label.sum()//val_data_ratio)\n",
        "train_sample_ind = list(set(list(range(train_set_df.label.sum()))) - set(sample_ind))\n",
        "val_sample_ind = sample_ind[:len(sample_ind)]\n",
        "\n",
        "val_sample_ind_all = []\n",
        "for i in range(negative_ratio+1):\n",
        "    tmp_ind = np.add(val_sample_ind,train_set_df.label.sum()*i)\n",
        "    val_sample_ind_all.extend(tmp_ind)\n",
        "\n",
        "train_sample_ind_all = []\n",
        "for i in range(negative_ratio+1):\n",
        "    tmp_ind = np.add(train_sample_ind,train_set_df.label.sum()*i)\n",
        "    train_sample_ind_all.extend(tmp_ind)\n",
        "    \n",
        "\n",
        "test_len = test_set_df.shape[0]\n",
        "train_set_df = train_set_df.append(test_set_df,ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DX9qsQkF1ctI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "whole_item_df['item_list'] = whole_item_df['item_list'].apply(lambda x : ' '.join([str(i) for i in x]))\n",
        "max_word_len = whole_click.item_id.nunique()\n",
        "tokenizer = Tokenizer(num_words=max_word_len, split=' ')\n",
        "tokenizer.fit_on_texts(whole_item_df['item_list'])\n",
        "recent_items_list = pad_sequences(tokenizer.texts_to_sequences(train_set_df_p['recent_items']))\n",
        "train_set_df_p['recent_items5'] = recent_items_list.tolist()\n",
        "train_set_df['target_item'] = pad_sequences(tokenizer.texts_to_sequences(train_set_df['target_item'])).tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1EEMz2B1hII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_set_df = train_set_df[-test_len:]\n",
        "val_set_df = train_set_df.loc[val_sample_ind_all]\n",
        "train_set_df = train_set_df.loc[train_sample_ind_all]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKcQht-o1kYg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set_df['target']=train_set_df['target_item'].apply(lambda x :x[0])\n",
        "train_set_df.drop_duplicates(subset=['user_id','time','target'],keep='first',inplace=True)\n",
        "train_set_df.drop(columns=['target','isval'],inplace = True)\n",
        "\n",
        "val_set_df['target']=val_set_df['target_item'].apply(lambda x :x[0])\n",
        "val_set_df.drop_duplicates(subset=['user_id','time','target'],keep='first',inplace=True)\n",
        "val_set_df.drop(columns=['target','isval'],inplace = True)\n",
        "\n",
        "test_set_df['target']=test_set_df['target_item'].apply(lambda x :x[0])\n",
        "test_set_df.drop_duplicates(subset=['user_id','time','target'],keep='first',inplace=True)\n",
        "test_set_df.drop(columns=['target','isval'],inplace = True)\n",
        "\n",
        "train_set_df = train_set_df.reset_index(drop=True)\n",
        "val_set_df = val_set_df.reset_index(drop=True)\n",
        "test_set_df = test_set_df.reset_index(drop=True)\n",
        "\n",
        "train_set_df_p.drop(columns=['target_item','label'],inplace=True,errors='ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdAYx2851nQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class data_generator:\n",
        "    def __init__(self, data, batch_size=128):\n",
        "        self.data = data\n",
        "        self.batch_size = batch_size\n",
        "        self.steps = len(self.data) // self.batch_size\n",
        "        if len(self.data) % self.batch_size != 0:\n",
        "            self.steps += 1\n",
        "    def __len__(self):\n",
        "        return self.steps\n",
        "\n",
        "    def __iter__(self):\n",
        "        global train_set_df_p\n",
        "        while True:\n",
        "            train_set = self.data\n",
        "            idxs = list(range(len(self.data)))\n",
        "            np.random.shuffle(idxs)\n",
        "            index_list = []\n",
        "            X1,  X3 ,Y = [], [], []\n",
        "            for c, i in enumerate(idxs):\n",
        "                index_list.append(i)\n",
        "                if len(index_list) == self.batch_size or i == idxs[-1]:\n",
        "                    tmp_df = train_set.loc[index_list]\n",
        "                    tmp_df = tmp_df.merge(train_set_df_p,on=['user_id','time'])\n",
        "                    tmp_df['recent_items5'] = tmp_df['recent_items5']+tmp_df['target_item']\n",
        "                    X1 = np.array(tmp_df['recent_items5'].values.tolist())\n",
        "                    X3 = np.array(tmp_df[['user_age_level', 'user_city_level','F', 'M']].values.tolist())\n",
        "                    Y = np.array(tmp_df['label'].values.tolist())\n",
        "                    yield [X1,X3], Y\n",
        "                    tmp_df = pd.DataFrame()\n",
        "                    X1, X3 ,Y = [],  [] ,[]\n",
        "                    index_list = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3xHr2ft2rrQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.callbacks import *\n",
        "from keras.initializers import *\n",
        "import tensorflow as tf\n",
        "from keras.engine.topology import Layer\n",
        "\n",
        "try:\n",
        "    from dataloader import TokenList, pad_to_longest\n",
        "    # for transformer\n",
        "except: pass\n",
        "\n",
        "embed_size = 32\n",
        "class LayerNormalization(Layer):\n",
        "    def __init__(self, eps=1e-6, **kwargs):\n",
        "        self.eps = eps\n",
        "        super(LayerNormalization, self).__init__(**kwargs)\n",
        "    def build(self, input_shape):\n",
        "        self.gamma = self.add_weight(name='gamma', shape=input_shape[-1:],\n",
        "                                     initializer=Ones(), trainable=True)\n",
        "        self.beta = self.add_weight(name='beta', shape=input_shape[-1:],\n",
        "                                    initializer=Zeros(), trainable=True)\n",
        "        super(LayerNormalization, self).build(input_shape)\n",
        "    def call(self, x):\n",
        "        mean = K.mean(x, axis=-1, keepdims=True)\n",
        "        std = K.std(x, axis=-1, keepdims=True)\n",
        "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "class ScaledDotProductAttention():\n",
        "    def __init__(self, d_model, attn_dropout=0.1):\n",
        "        self.temper = np.sqrt(d_model)\n",
        "        self.dropout = Dropout(attn_dropout)\n",
        "    def __call__(self, q, k, v, mask):\n",
        "        attn = Lambda(lambda x:K.batch_dot(x[0],x[1],axes=[2,2])/self.temper)([q, k])\n",
        "        if mask is not None:\n",
        "            mmask = Lambda(lambda x:(-1e+10)*(1-x))(mask)\n",
        "            attn = Add()([attn, mmask])\n",
        "        attn = Activation('softmax')(attn)\n",
        "        attn = self.dropout(attn)\n",
        "        output = Lambda(lambda x:K.batch_dot(x[0], x[1]))([attn, v])\n",
        "        return output, attn\n",
        "\n",
        "class MultiHeadAttention():\n",
        "    # mode 0 - big martixes, faster; mode 1 - more clear implementation\n",
        "    def __init__(self, n_head, d_model, d_k, d_v, dropout, mode=0, use_norm=True):\n",
        "        self.mode = mode\n",
        "        self.n_head = n_head\n",
        "        self.d_k = d_k\n",
        "        self.d_v = d_v\n",
        "        self.dropout = dropout\n",
        "        if mode == 0:\n",
        "            self.qs_layer = Dense(n_head*d_k, use_bias=False)\n",
        "            self.ks_layer = Dense(n_head*d_k, use_bias=False)\n",
        "            self.vs_layer = Dense(n_head*d_v, use_bias=False)\n",
        "        elif mode == 1:\n",
        "            self.qs_layers = []\n",
        "            self.ks_layers = []\n",
        "            self.vs_layers = []\n",
        "            for _ in range(n_head):\n",
        "                self.qs_layers.append(TimeDistributed(Dense(d_k, use_bias=False)))\n",
        "                self.ks_layers.append(TimeDistributed(Dense(d_k, use_bias=False)))\n",
        "                self.vs_layers.append(TimeDistributed(Dense(d_v, use_bias=False)))\n",
        "        self.attention = ScaledDotProductAttention(d_model)\n",
        "        self.layer_norm = LayerNormalization() if use_norm else None\n",
        "        self.w_o = TimeDistributed(Dense(d_model))\n",
        "\n",
        "    def __call__(self, q, k, v, mask=None):\n",
        "        d_k, d_v = self.d_k, self.d_v\n",
        "        n_head = self.n_head\n",
        "\n",
        "        if self.mode == 0:\n",
        "            qs = self.qs_layer(q)  # [batch_size, len_q, n_head*d_k]\n",
        "            ks = self.ks_layer(k)\n",
        "            vs = self.vs_layer(v)\n",
        "\n",
        "            def reshape1(x):\n",
        "                s = tf.shape(x)   # [batch_size, len_q, n_head * d_k]\n",
        "                x = tf.reshape(x, [s[0], s[1], n_head, d_k])\n",
        "                x = tf.transpose(x, [2, 0, 1, 3])  \n",
        "                x = tf.reshape(x, [-1, s[1], d_k])  # [n_head * batch_size, len_q, d_k]\n",
        "                return x\n",
        "            qs = Lambda(reshape1)(qs)\n",
        "            ks = Lambda(reshape1)(ks)\n",
        "            vs = Lambda(reshape1)(vs)\n",
        "\n",
        "            if mask is not None:\n",
        "                mask = Lambda(lambda x:K.repeat_elements(x, n_head, 0))(mask)\n",
        "            head, attn = self.attention(qs, ks, vs, mask=mask)  \n",
        "                \n",
        "            def reshape2(x):\n",
        "                s = tf.shape(x)   # [n_head * batch_size, len_v, d_v]\n",
        "                x = tf.reshape(x, [n_head, -1, s[1], s[2]]) \n",
        "                x = tf.transpose(x, [1, 2, 0, 3])\n",
        "                x = tf.reshape(x, [-1, s[1], n_head*d_v])  # [batch_size, len_v, n_head * d_v]\n",
        "                return x\n",
        "            head = Lambda(reshape2)(head)\n",
        "        elif self.mode == 1:\n",
        "            heads = []; attns = []\n",
        "            for i in range(n_head):\n",
        "                qs = self.qs_layers[i](q)   \n",
        "                ks = self.ks_layers[i](k) \n",
        "                vs = self.vs_layers[i](v) \n",
        "                head, attn = self.attention(qs, ks, vs, mask)\n",
        "                heads.append(head); attns.append(attn)\n",
        "            head = Concatenate()(heads) if n_head > 1 else heads[0]\n",
        "            attn = Concatenate()(attns) if n_head > 1 else attns[0]\n",
        "\n",
        "        outputs = self.w_o(head)\n",
        "        outputs = Dropout(self.dropout)(outputs)\n",
        "        if not self.layer_norm: return outputs, attn\n",
        "        outputs = Add()([outputs, q])\n",
        "        return self.layer_norm(outputs), attn\n",
        "\n",
        "class PositionwiseFeedForward():\n",
        "    def __init__(self, d_hid, d_inner_hid, dropout=0.1):\n",
        "        self.w_1 = Conv1D(d_inner_hid, 1, activation='relu')\n",
        "        self.w_2 = Conv1D(d_hid, 1)\n",
        "        self.layer_norm = LayerNormalization()\n",
        "        self.dropout = Dropout(dropout)\n",
        "    def __call__(self, x):\n",
        "        output = self.w_1(x) \n",
        "        output = self.w_2(output)\n",
        "        output = self.dropout(output)\n",
        "        output = Add()([output, x])\n",
        "        return self.layer_norm(output)\n",
        "\n",
        "class EncoderLayer():\n",
        "    def __init__(self, d_model, d_inner_hid, n_head, d_k, d_v, dropout=0.1):\n",
        "        self.self_att_layer = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout=dropout)\n",
        "        self.pos_ffn_layer  = PositionwiseFeedForward(d_model, d_inner_hid, dropout=dropout)\n",
        "    def __call__(self, enc_input, mask=None):\n",
        "        output, slf_attn = self.self_att_layer(enc_input, enc_input, enc_input, mask=mask)\n",
        "        output = self.pos_ffn_layer(output)\n",
        "        return output, slf_attn\n",
        "\n",
        "class DecoderLayer():\n",
        "    def __init__(self, d_model, d_inner_hid, n_head, d_k, d_v, dropout=0.1):\n",
        "        self.self_att_layer = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout=dropout)\n",
        "        self.enc_att_layer  = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout=dropout)\n",
        "        self.pos_ffn_layer  = PositionwiseFeedForward(d_model, d_inner_hid, dropout=dropout)\n",
        "    def __call__(self, dec_input, enc_output, self_mask=None, enc_mask=None):\n",
        "        output, slf_attn = self.self_att_layer(dec_input, dec_input, dec_input, mask=self_mask)\n",
        "        output, enc_attn = self.enc_att_layer(output, enc_output, enc_output, mask=enc_mask)\n",
        "        output = self.pos_ffn_layer(output)\n",
        "        return output, slf_attn, enc_attn\n",
        "\n",
        "def GetPosEncodingMatrix(max_len, d_emb):\n",
        "    pos_enc = np.array([\n",
        "        [pos / np.power(10000, 2 * (j // 2) / d_emb) for j in range(d_emb)] \n",
        "        if pos != 0 else np.zeros(d_emb) \n",
        "            for pos in range(max_len)\n",
        "            ])\n",
        "    pos_enc[1:, 0::2] = np.sin(pos_enc[1:, 0::2]) # dim 2i\n",
        "    pos_enc[1:, 1::2] = np.cos(pos_enc[1:, 1::2]) # dim 2i+1\n",
        "    return pos_enc\n",
        "\n",
        "def GetPadMask(q, k):\n",
        "    ones = K.expand_dims(K.ones_like(q, 'float32'), -1)\n",
        "    mask = K.cast(K.expand_dims(K.not_equal(k, 0), 1), 'float32')\n",
        "    mask = K.batch_dot(ones, mask, axes=[2,1])\n",
        "    return mask\n",
        "\n",
        "def GetSubMask(s):\n",
        "    len_s = tf.shape(s)[1]\n",
        "    bs = tf.shape(s)[:1]\n",
        "    mask = K.cumsum(tf.eye(len_s, batch_shape=bs), 1)\n",
        "    return mask\n",
        "\n",
        "class Encoder():\n",
        "    def __init__(self, d_model, d_inner_hid, n_head, d_k, d_v, \\\n",
        "                layers=6, dropout=0.1, word_emb=None, pos_emb=None):\n",
        "        self.emb_layer = word_emb\n",
        "        self.pos_layer = pos_emb\n",
        "        self.emb_dropout = Dropout(dropout)\n",
        "        self.layers = [EncoderLayer(d_model, d_inner_hid, n_head, d_k, d_v, dropout) for _ in range(layers)]\n",
        "        \n",
        "    def __call__(self, src_seq, src_pos, return_att=False, active_layers=999):\n",
        "        x = self.emb_layer(src_seq)\n",
        "        if src_pos is not None:\n",
        "            pos = self.pos_layer(src_pos)\n",
        "            x = Add()([x, pos])\n",
        "        x = self.emb_dropout(x)\n",
        "        if return_att: atts = []\n",
        "        mask = Lambda(lambda x:GetPadMask(x, x))(src_seq)\n",
        "        for enc_layer in self.layers[:active_layers]:\n",
        "            x, att = enc_layer(x, mask)\n",
        "            if return_att: atts.append(att)\n",
        "        return (x, atts) if return_att else x\n",
        "\n",
        "\n",
        "class Transformer():\n",
        "    def __init__(self, len_limit, d_model=embed_size, \\\n",
        "              d_inner_hid=512, n_head=10, d_k=64, d_v=64, layers=2, dropout=0.1, \\\n",
        "              share_word_emb=False, **kwargs):\n",
        "        self.name = 'Transformer'\n",
        "        self.len_limit = len_limit\n",
        "        self.src_loc_info = True\n",
        "        self.d_model = d_model\n",
        "        self.decode_model = None\n",
        "        d_emb = d_model\n",
        "\n",
        "        pos_emb = Embedding(len_limit, d_emb, trainable=False, \\\n",
        "                            weights=[GetPosEncodingMatrix(len_limit, d_emb)])\n",
        "\n",
        "        i_word_emb = Embedding(max_features, d_emb) # Add embedding here\n",
        "\n",
        "        self.encoder = Encoder(d_model, d_inner_hid, n_head, d_k, d_v, layers, dropout, \\\n",
        "                               word_emb=i_word_emb, pos_emb=pos_emb)\n",
        "\n",
        "        \n",
        "    def get_pos_seq(self, x):\n",
        "        mask = K.cast(K.not_equal(x, 0), 'int32')\n",
        "        pos = K.cumsum(K.ones_like(x, 'int32'), 1)\n",
        "        return pos * mask\n",
        "\n",
        "    def compile(self, active_layers=999):\n",
        "        src_seq_input = Input(shape=(None,))\n",
        "        src_seq = src_seq_input\n",
        "        src_pos = Lambda(self.get_pos_seq)(src_seq)\n",
        "        if not self.src_loc_info: src_pos = None\n",
        "\n",
        "        x = self.encoder(src_seq, src_pos, active_layers=active_layers)\n",
        "        # x = GlobalMaxPool1D()(x) # Not sure about this layer. Just wanted to reduce dimension\n",
        "        x = GlobalAveragePooling1D()(x)\n",
        "        input_2=Input(shape=[4,])\n",
        "        merge = concatenate([x,input_2])\n",
        "        mlp = Dense(units=100,activation='relu')(merge)\n",
        "        mlp = Dropout(0.3)(mlp)\n",
        "        outp = Dense(units=1,activation='sigmoid')(mlp)  \n",
        "\n",
        "        self.model = Model(inputs=[src_seq_input,input_2], outputs=outp)\n",
        "        # self.model.compile(optimizer=keras.optimizers.RMSprop(1e-3),loss=keras.losses.BinaryCrossentropy(),metrics=[keras.metrics.AUC()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIMSWF7b4qzQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "38d3a0a6-b2d9-49e3-ccd4-f1bceae2d7d2"
      },
      "source": [
        "maxlen=5\n",
        "max_features=max_word_len+1\n",
        "s2s = Transformer(maxlen, layers=1)\n",
        "s2s.compile()\n",
        "model = s2s.model\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(1e-3),loss=keras.losses.BinaryCrossentropy(),metrics=[keras.metrics.AUC()])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, None)         0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 32)     1980992     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 32)     160         lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, None, 32)     0           embedding_2[0][0]                \n",
            "                                                                 embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, None, 32)     0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 640)    20480       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, None, 640)    20480       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, None, None)   0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, None, 64)     0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4 (Lambda)               (None, None, 64)     0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_6 (Lambda)               (None, None, None)   0           lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_7 (Lambda)               (None, None, None)   0           lambda_3[0][0]                   \n",
            "                                                                 lambda_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_8 (Lambda)               (None, None, None)   0           lambda_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, None, None)   0           lambda_7[0][0]                   \n",
            "                                                                 lambda_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, None, None)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, None, 640)    20480       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, None, None)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lambda_5 (Lambda)               (None, None, 64)     0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_9 (Lambda)               (None, None, 64)     0           dropout_2[0][0]                  \n",
            "                                                                 lambda_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_10 (Lambda)              (None, None, 640)    0           lambda_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, None, 32)     20512       lambda_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, None, 32)     0           time_distributed_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, None, 32)     0           dropout_4[0][0]                  \n",
            "                                                                 dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_1 (LayerNor (None, None, 32)     64          add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, None, 512)    16896       layer_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, None, 32)     16416       conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, None, 32)     0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, None, 32)     0           dropout_3[0][0]                  \n",
            "                                                                 layer_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_2 (LayerNor (None, None, 32)     64          add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_1 (Glo (None, 32)           0           layer_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 4)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 36)           0           global_average_pooling1d_1[0][0] \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 100)          3700        concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 100)          0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 1)            101         dropout_5[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,100,345\n",
            "Trainable params: 2,100,185\n",
            "Non-trainable params: 160\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRGo91uR44--",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "a3b4a83c-5d45-42f2-b557-8adeece658b7"
      },
      "source": [
        "filepath = \"kdd2020_data/recall/attention_.h5\" \n",
        "monitor_name = 'val_auc_1'\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath, monitor=monitor_name, verbose=1, save_best_only=False,save_weights_only=True,mode='max')\n",
        "reduce_lr2 = ReduceLROnPlateau(\n",
        "    monitor=monitor_name, factor=0.8, patience=1, min_lr=0.0001, verbose=1)\n",
        "earlystopping2 = EarlyStopping(\n",
        "    monitor=monitor_name, min_delta=0.0001, patience=2, verbose=1, mode='max')\n",
        "callbacks2 = [earlystopping2 ,reduce_lr2]\n",
        "train_D = data_generator(train_set_df,batch_size=8192)\n",
        "valid_D = data_generator(val_set_df,batch_size=8192)\n",
        "model.fit_generator(train_D.__iter__(),validation_data=valid_D.__iter__(),validation_steps=len(valid_D),steps_per_epoch=len(train_D),epochs=10, shuffle=True,callbacks=callbacks2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2496/2496 [==============================] - 752s 301ms/step - loss: 0.0982 - auc_1: 0.4997 - val_loss: 0.1160 - val_auc_1: 0.5000\n",
            "Epoch 2/10\n",
            "2496/2496 [==============================] - 722s 289ms/step - loss: 0.0974 - auc_1: 0.4996 - val_loss: 0.0896 - val_auc_1: 0.5000\n",
            "\n",
            "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
            "Epoch 3/10\n",
            "2496/2496 [==============================] - 717s 287ms/step - loss: 0.0971 - auc_1: 0.4997 - val_loss: 0.0897 - val_auc_1: 0.5000\n",
            "\n",
            "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
            "Epoch 00003: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f639dcc1c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFBkA_uG12r4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c723382f-08bd-46b8-c60d-800236d0a2f1"
      },
      "source": [
        "test_D = data_generator(test_set_df.reset_index(drop=True),batch_size=8192)\n",
        "model.evaluate_generator(test_D.__iter__(),steps=len(test_D))\n",
        "# model = load_model('kdd2020_data/recall/attention_.h5',compile=False)\n",
        "# model.compile( optimizer=keras.optimizers.RMSprop(1e-3),loss=keras.losses.BinaryCrossentropy(),metrics=[keras.metrics.AUC()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0772295594215393, 0.5000154972076416]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcUAdlkd137K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_feature(train_set_df , query_df,whole_click,isval=False):\n",
        "    recent_items_df = pd.DataFrame()\n",
        "    last_n=5\n",
        "    for i in tqdm(query_df.index):\n",
        "        user = query_df.loc[i,'user_id']\n",
        "        time = query_df.loc[i,'query_time']\n",
        "        phase = query_df.loc[i,'phase']\n",
        "        recent_items = ' '.join([str(i) for i in  whole_click.loc[(whole_click['user_id']==user)&(whole_click['time']<time)&(whole_click['phase']==phase)]['item_id'][:last_n-1].values.tolist()[::-1]])\n",
        "        recent_items_df = recent_items_df.append({'user_id':user,'query_time':time,'recent_items_5':recent_items,'phase':phase},ignore_index=True)\n",
        "    train_set_df = train_set_df.merge(recent_items_df,on=['user_id','query_time','phase'])\n",
        "    train_set_df['recent_items_5'] = train_set_df['recent_items_5']+' '+ train_set_df['item_id'].astype(str)\n",
        "#     tokenizer = joblib.load('./tokenizer.m')\n",
        "#     scaler_user = joblib.load('./user_info_std_scalar.m')\n",
        "    user_data = pd.read_csv('kdd2020_data/underexpose_train/underexpose_user_feat.csv',names=['user_id', 'user_age_level', 'user_gender', 'user_city_level'])\n",
        "    user_data = pd.concat([user_data,pd.get_dummies(user_data['user_gender'])],axis=1)\n",
        "    user_data = user_data.drop_duplicates(subset=['user_id'])\n",
        "    user_data.drop(columns=['user_gender'],inplace=True)\n",
        "    train_set_df = train_set_df.merge(user_data,on='user_id',how='left')\n",
        "    train_set_df[['user_age_level', 'user_city_level','F', 'M']] = scaler_user.transform(train_set_df[['user_age_level', 'user_city_level','F', 'M']])\n",
        "    train_set_df['user_age_level'].fillna(0,inplace=True)\n",
        "    train_set_df['user_city_level'].fillna(0,inplace=True)\n",
        "    train_set_df['F'].fillna(0,inplace=True)\n",
        "    train_set_df['M'].fillna(0,inplace=True)\n",
        "    X = tokenizer.texts_to_sequences(train_set_df['recent_items_5'])\n",
        "    X = pad_sequences(X)\n",
        "    if isval:\n",
        "        return X,train_set_df[['user_age_level', 'user_city_level','F', 'M']],train_set_df['label']\n",
        "        #return train_set_df\n",
        "    else:\n",
        "        return X,train_set_df[['user_age_level', 'user_city_level','F', 'M']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRq9G3r817aJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_recall = pd.read_pickle('kdd2020_data/my_model/recall.pkl')\n",
        "final_recall = final_recall[['user_id', 'phase', 'query_time', 'item_id', 'label']]\n",
        "train_set_df = final_recall[~final_recall['label'].isnull()].reset_index(drop=True)\n",
        "test_set_df = final_recall[final_recall['label'].isnull()].reset_index(drop=True)\n",
        "query_df = train_set_df[train_set_df['label']==1]\n",
        "\n",
        "\n",
        "whole_click = pd.DataFrame()  \n",
        "for c in range(3):  \n",
        "    click_train = pd.read_csv('kdd2020_data/underexpose_train/underexpose_train_click-{}.csv'.format(c), header=None,  names=['user_id', 'item_id', 'time'])  \n",
        "    click_test = pd.read_csv('kdd2020_data/underexpose_test/underexpose_test_click-{}.csv'.format(c), header=None,  names=['user_id', 'item_id', 'time'])  \n",
        "    all_click = click_train.append(click_test)  \n",
        "    all_click['phase']=c\n",
        "    whole_click = whole_click.append(all_click)  \n",
        "whole_click = whole_click.drop_duplicates(subset=['user_id','item_id','time','phase'])\n",
        "whole_click = whole_click.sort_values(by =['user_id','time'],ascending=False).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jm_vxpYK1_LJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e2de28f-cf28-4335-eb82-1dbd4b8c3649"
      },
      "source": [
        "X_1,X_2,y = get_feature(train_set_df,query_df,whole_click,isval=True)\n",
        "train_set_df['pred'] = model.predict([X_1,X_2],batch_size=4096)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14131/14131 [01:59<00:00, 118.15it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KvHcW2W2CC1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8585b38b-73ce-42b0-e0c1-370cb7dbd7c8"
      },
      "source": [
        "test_query = test_set_df.drop_duplicates(['user_id','phase','query_time'])\n",
        "test_x_1,test_x_2 =get_feature(whole_click=whole_click,train_set_df=test_set_df,query_df=test_query,isval=False)\n",
        "test_set_df['pred'] = model.predict([test_x_1,test_x_2],batch_size=4096)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5079/5079 [00:41<00:00, 121.54it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X4Z2ObS2E5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_all = train_set_df.append(test_set_df,ignore_index=True)\n",
        "data_all.to_pickle('kdd2020_data/recall/transformer_rank.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0cN-ARQrLGL",
        "colab_type": "text"
      },
      "source": [
        "# Rank_3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0E0jvg-2VY1o",
        "colab_type": "text"
      },
      "source": [
        "**target attention** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQh3ZmqpjZXD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df_data = pd.read_pickle('kdd2020_data/recall/rank_feature11.pkl')\n",
        "df_history = pd.read_pickle('kdd2020_data/recall/click.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IGS9ifijuEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_data['user_phase'] = df_data['user_id'].astype('str') + '_' + df_data['phase'].astype('str')\n",
        "df_history['user_phase'] = df_history['user_id'].astype('str') + '_' + df_history['phase'].astype('str')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bvy-PIepjy_A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ff168f3e-3de1-405a-be74-c7e2b09834fc"
      },
      "source": [
        "print(df_history.shape)\n",
        "df_history = df_history[df_history['user_phase'].isin(df_data['user_phase'].values)]\n",
        "print(df_history.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(745415, 5)\n",
            "(280239, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NUKioi0j7Du",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_history.sort_values(['user_id', 'time'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9PHOFIOkAq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_temp = df_history.groupby(['user_phase'])['item_id'].agg(history=list).reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Se9ZaByNkFCu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f6d832df-a009-4aa7-9355-8ba0d204686f"
      },
      "source": [
        "df_temp.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_phase</th>\n",
              "      <th>history</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10001_2</td>\n",
              "      <td>[58374, 15105, 9978, 25595, 66100, 82523, 7536...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10004_2</td>\n",
              "      <td>[35531, 11683, 12916, 66435, 23362, 85444, 764...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10005_0</td>\n",
              "      <td>[93726, 8048, 66055, 68189, 76335, 46620, 3978...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10005_2</td>\n",
              "      <td>[12691, 63720, 74150, 113203, 27093, 63486, 48...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10007_1</td>\n",
              "      <td>[53651, 111664, 93799]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  user_phase                                            history\n",
              "0    10001_2  [58374, 15105, 9978, 25595, 66100, 82523, 7536...\n",
              "1    10004_2  [35531, 11683, 12916, 66435, 23362, 85444, 764...\n",
              "2    10005_0  [93726, 8048, 66055, 68189, 76335, 46620, 3978...\n",
              "3    10005_2  [12691, 63720, 74150, 113203, 27093, 63486, 48...\n",
              "4    10007_1                             [53651, 111664, 93799]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeUg5fu1kJh4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_data = df_data.merge(df_temp, how='left')\n",
        "del df_data['user_phase']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Grt5GAa0kroD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to reduce the memory usage\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import GroupKFold\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import math\n",
        "import pickle\n",
        "from gensim.models import Word2Vec\n",
        "import os\n",
        "\n",
        "def reduce_mem_usage(df, verbose=True):\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    for col in tqdm([f for f in df.columns if f not in ['query_time']]):\n",
        "        col_type = df[col].dtypes\n",
        "        if col_type in numerics:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(\n",
        "                        np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(\n",
        "                        np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(\n",
        "                        np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(\n",
        "                        np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)\n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(\n",
        "                        np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(\n",
        "                        np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    if verbose:\n",
        "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(\n",
        "            end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5tFwKymlTPm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "acc26cf1-1c7f-4d41-a800-65ae4e0e704e"
      },
      "source": [
        "df_data=reduce_mem_usage(df_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 74/74 [00:32<00:00,  2.26it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 1895.53 Mb (71.5% reduction)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBR4ceankNJj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "83b0c094-4d97-447b-e66d-88faa0af88be"
      },
      "source": [
        "df_data.to_pickle('kdd2020_data/recall/nn_input.pkl')\n",
        "print(df_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11489051, 75)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7Jv2H9UvjTZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "70034241-cc2e-45d9-8486-2456dc12cbbd"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.layers import *\n",
        "from keras import backend as BKD\n",
        "import keras.backend.tensorflow_backend as TFBKD\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from gensim.models import Word2Vec\n",
        "import gensim\n",
        "import gc\n",
        "import time\n",
        "pd.set_option('display.max_columns', None)\n",
        "tqdm.pandas(desc='pandas bar')\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(\n",
        "    level=logging.DEBUG,\n",
        "    filename='logging_log.txt',\n",
        "    filemode='w',\n",
        "    format= '%(asctime)s - %(pathname)s[line:%(lineno)d] - %(levelname)s: %(message)s'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbVV-lXnvmmS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "698a2abb-b4e2-4bb9-ecec-ee99e2a14c91"
      },
      "source": [
        "df = pd.read_pickle('kdd2020_data/recall/nn_input.pkl')\n",
        "print(df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11489051, 75)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7J9h2ySvuQI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f350587e-58c4-48ec-c43a-0218025ebf5a"
      },
      "source": [
        "embedding_size=2\n",
        "emb_size = embedding_size\n",
        "sentences = df.drop_duplicates(['user_id', 'phase'])['history'].values.tolist()\n",
        "print(len(sentences))\n",
        "for i in tqdm(range(len(sentences))):\n",
        "    sentences[i] = [str(x) for x in sentences[i]]\n",
        "model = Word2Vec(sentences, size=emb_size, window=5, min_count=1, sg=1, hs=0, iter=5, seed=2020, workers=12)\n",
        "del sentences\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19210/19210 [00:00<00:00, 204646.97it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "19210\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHJoktBuyUOg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "14ff864d-477b-4a61-89b5-784d3c6b5766"
      },
      "source": [
        "words = set()\n",
        "for line in tqdm(df['history'].values):\n",
        "    words |= set(line)\n",
        "words = np.sort(list(words))\n",
        "print(words[:10])\n",
        "vocab_size = len(words)\n",
        "words_idx_dict = dict(zip(words, range(vocab_size)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 11489051/11489051 [00:13<00:00, 850222.43it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[ 1  3  9 10 14 18 19 20 21 22]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2BagY3RyFOa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "658aeb9f-3a73-416e-bb5e-86edfd4f5e67"
      },
      "source": [
        "emb_size = embedding_size\n",
        "embedding_matrix = np.zeros((vocab_size + 1, emb_size))\n",
        "for w in tqdm(words_idx_dict.keys()):\n",
        "    if str(w) in model:\n",
        "        embedding_matrix[words_idx_dict[w] + 1] = model[str(w)]\n",
        "embedding_matrix = embedding_matrix.astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/56098 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "100%|██████████| 56098/56098 [00:01<00:00, 48306.92it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dwn77UWIzLXu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5c626652-f5aa-4e6f-8e63-86660a475dc4"
      },
      "source": [
        "max_len=5\n",
        "df['history'] = df['history'].progress_apply(lambda seq: [words_idx_dict[int(x)] + 1 for x in seq])\n",
        "df['history'] = df['history'].progress_apply(\n",
        "    lambda seq: seq[-max_len:] if len(seq) >= max_len else seq + ([0] * (max_len - len(seq))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "pandas bar:   0%|          | 0/11489051 [00:00<?, ?it/s]\u001b[A\n",
            "pandas bar:   0%|          | 1/11489051 [00:00<676:20:41,  4.72it/s]\u001b[A\n",
            "pandas bar:   1%|          | 60512/11489051 [00:00<470:56:58,  6.74it/s]\u001b[A\n",
            "pandas bar:   1%|          | 117859/11489051 [00:00<328:00:43,  9.63it/s]\u001b[A\n",
            "pandas bar:   2%|▏         | 181469/11489051 [00:00<228:19:31, 13.76it/s]\u001b[A\n",
            "pandas bar:   2%|▏         | 245841/11489051 [00:00<158:55:10, 19.65it/s]\u001b[A\n",
            "pandas bar:   3%|▎         | 311345/11489051 [00:00<110:35:48, 28.07it/s]\u001b[A\n",
            "pandas bar:   3%|▎         | 378705/11489051 [00:00<76:57:09, 40.11it/s] \u001b[A\n",
            "pandas bar:   4%|▍         | 445696/11489051 [00:00<53:32:36, 57.29it/s]\u001b[A\n",
            "pandas bar:   4%|▍         | 513604/11489051 [00:01<37:15:04, 81.84it/s]\u001b[A\n",
            "pandas bar:   5%|▌         | 582587/11489051 [00:01<25:54:47, 116.91it/s]\u001b[A\n",
            "pandas bar:   6%|▌         | 649407/11489051 [00:01<18:01:46, 167.00it/s]\u001b[A\n",
            "pandas bar:   6%|▌         | 714655/11489051 [00:01<12:32:45, 238.55it/s]\u001b[A\n",
            "pandas bar:   7%|▋         | 780440/11489051 [00:01<8:43:47, 340.73it/s] \u001b[A\n",
            "pandas bar:   7%|▋         | 846857/11489051 [00:01<6:04:27, 486.66it/s]\u001b[A\n",
            "pandas bar:   8%|▊         | 915662/11489051 [00:01<4:13:33, 695.01it/s]\u001b[A\n",
            "pandas bar:   9%|▊         | 984485/11489051 [00:01<2:56:24, 992.45it/s]\u001b[A\n",
            "pandas bar:   9%|▉         | 1053763/11489051 [00:01<2:02:44, 1416.91it/s]\u001b[A\n",
            "pandas bar:  10%|▉         | 1121879/11489051 [00:01<1:25:26, 2022.36it/s]\u001b[A\n",
            "pandas bar:  10%|█         | 1189826/11489051 [00:02<59:29, 2885.33it/s]  \u001b[A\n",
            "pandas bar:  11%|█         | 1259157/11489051 [00:02<41:26, 4114.56it/s]\u001b[A\n",
            "pandas bar:  12%|█▏        | 1327243/11489051 [00:02<28:53, 5862.75it/s]\u001b[A\n",
            "pandas bar:  12%|█▏        | 1395328/11489051 [00:05<22:43, 7404.87it/s]\u001b[A\n",
            "pandas bar:  13%|█▎        | 1461596/11489051 [00:05<15:52, 10527.97it/s]\u001b[A\n",
            "pandas bar:  13%|█▎        | 1528146/11489051 [00:05<11:06, 14938.68it/s]\u001b[A\n",
            "pandas bar:  14%|█▍        | 1590754/11489051 [00:06<07:48, 21124.95it/s]\u001b[A\n",
            "pandas bar:  14%|█▍        | 1657261/11489051 [00:06<05:30, 29773.19it/s]\u001b[A\n",
            "pandas bar:  15%|█▌        | 1724426/11489051 [00:06<03:53, 41740.13it/s]\u001b[A\n",
            "pandas bar:  16%|█▌        | 1791398/11489051 [00:06<02:46, 58077.47it/s]\u001b[A\n",
            "pandas bar:  16%|█▌        | 1859026/11489051 [00:06<02:00, 80022.57it/s]\u001b[A\n",
            "pandas bar:  17%|█▋        | 1924970/11489051 [00:06<01:28, 108666.54it/s]\u001b[A\n",
            "pandas bar:  17%|█▋        | 1991724/11489051 [00:06<01:05, 145113.82it/s]\u001b[A\n",
            "pandas bar:  18%|█▊        | 2059279/11489051 [00:06<00:49, 189823.55it/s]\u001b[A\n",
            "pandas bar:  19%|█▊        | 2128676/11489051 [00:06<00:38, 242672.97it/s]\u001b[A\n",
            "pandas bar:  19%|█▉        | 2195900/11489051 [00:06<00:31, 298965.30it/s]\u001b[A\n",
            "pandas bar:  20%|█▉        | 2263264/11489051 [00:07<00:25, 358678.71it/s]\u001b[A\n",
            "pandas bar:  20%|██        | 2332192/11489051 [00:07<00:21, 418962.79it/s]\u001b[A\n",
            "pandas bar:  21%|██        | 2399615/11489051 [00:07<00:19, 471620.60it/s]\u001b[A\n",
            "pandas bar:  21%|██▏       | 2468687/11489051 [00:07<00:17, 521220.18it/s]\u001b[A\n",
            "pandas bar:  22%|██▏       | 2538398/11489051 [00:07<00:15, 563903.10it/s]\u001b[A\n",
            "pandas bar:  23%|██▎       | 2606752/11489051 [00:07<00:14, 592725.20it/s]\u001b[A\n",
            "pandas bar:  23%|██▎       | 2675546/11489051 [00:07<00:14, 618401.68it/s]\u001b[A\n",
            "pandas bar:  24%|██▍       | 2743811/11489051 [00:07<00:13, 631532.21it/s]\u001b[A\n",
            "pandas bar:  24%|██▍       | 2811530/11489051 [00:07<00:13, 642969.13it/s]\u001b[A\n",
            "pandas bar:  25%|██▌       | 2879552/11489051 [00:07<00:13, 653707.67it/s]\u001b[A\n",
            "pandas bar:  26%|██▌       | 2947239/11489051 [00:08<00:12, 659038.09it/s]\u001b[A\n",
            "pandas bar:  26%|██▋       | 3016786/11489051 [00:08<00:12, 669558.82it/s]\u001b[A\n",
            "pandas bar:  27%|██▋       | 3084925/11489051 [00:08<00:12, 669918.44it/s]\u001b[A\n",
            "pandas bar:  27%|██▋       | 3152745/11489051 [00:08<00:12, 672032.95it/s]\u001b[A\n",
            "pandas bar:  28%|██▊       | 3220530/11489051 [00:08<00:12, 670588.28it/s]\u001b[A\n",
            "pandas bar:  29%|██▊       | 3288916/11489051 [00:08<00:12, 674515.10it/s]\u001b[A\n",
            "pandas bar:  29%|██▉       | 3356659/11489051 [00:08<00:12, 659327.68it/s]\u001b[A\n",
            "pandas bar:  30%|██▉       | 3425885/11489051 [00:08<00:12, 668869.17it/s]\u001b[A\n",
            "pandas bar:  30%|███       | 3494936/11489051 [00:08<00:11, 675217.36it/s]\u001b[A\n",
            "pandas bar:  31%|███       | 3563592/11489051 [00:08<00:11, 678578.40it/s]\u001b[A\n",
            "pandas bar:  32%|███▏      | 3631962/11489051 [00:09<00:11, 680106.03it/s]\u001b[A\n",
            "pandas bar:  32%|███▏      | 3700062/11489051 [00:09<00:11, 676269.83it/s]\u001b[A\n",
            "pandas bar:  33%|███▎      | 3767757/11489051 [00:09<00:11, 675750.89it/s]\u001b[A\n",
            "pandas bar:  33%|███▎      | 3838369/11489051 [00:09<00:11, 684581.56it/s]\u001b[A\n",
            "pandas bar:  34%|███▍      | 3906889/11489051 [00:09<00:11, 681806.96it/s]\u001b[A\n",
            "pandas bar:  35%|███▍      | 3975115/11489051 [00:09<00:11, 678333.95it/s]\u001b[A\n",
            "pandas bar:  35%|███▌      | 4043293/11489051 [00:09<00:10, 679363.81it/s]\u001b[A\n",
            "pandas bar:  36%|███▌      | 4111255/11489051 [00:09<00:10, 676863.53it/s]\u001b[A\n",
            "pandas bar:  36%|███▋      | 4178962/11489051 [00:09<00:10, 668055.66it/s]\u001b[A\n",
            "pandas bar:  37%|███▋      | 4245808/11489051 [00:10<00:10, 667889.16it/s]\u001b[A\n",
            "pandas bar:  38%|███▊      | 4312627/11489051 [00:10<00:10, 667978.14it/s]\u001b[A\n",
            "pandas bar:  38%|███▊      | 4379950/11489051 [00:10<00:10, 669544.79it/s]\u001b[A\n",
            "pandas bar:  39%|███▊      | 4446920/11489051 [00:10<00:10, 667098.85it/s]\u001b[A\n",
            "pandas bar:  39%|███▉      | 4514679/11489051 [00:10<00:10, 670211.64it/s]\u001b[A\n",
            "pandas bar:  40%|███▉      | 4583500/11489051 [00:10<00:10, 675510.76it/s]\u001b[A\n",
            "pandas bar:  40%|████      | 4651070/11489051 [00:14<02:08, 53076.87it/s] \u001b[A\n",
            "pandas bar:  41%|████      | 4714312/11489051 [00:14<01:32, 73191.48it/s]\u001b[A\n",
            "pandas bar:  42%|████▏     | 4780008/11489051 [00:14<01:07, 99794.35it/s]\u001b[A\n",
            "pandas bar:  42%|████▏     | 4846750/11489051 [00:14<00:49, 133977.80it/s]\u001b[A\n",
            "pandas bar:  43%|████▎     | 4914936/11489051 [00:14<00:37, 176531.24it/s]\u001b[A\n",
            "pandas bar:  43%|████▎     | 4980499/11489051 [00:15<00:28, 226096.87it/s]\u001b[A\n",
            "pandas bar:  44%|████▍     | 5048139/11489051 [00:15<00:22, 282462.50it/s]\u001b[A\n",
            "pandas bar:  45%|████▍     | 5114373/11489051 [00:15<00:18, 341163.57it/s]\u001b[A\n",
            "pandas bar:  45%|████▌     | 5180047/11489051 [00:15<00:15, 398628.06it/s]\u001b[A\n",
            "pandas bar:  46%|████▌     | 5245245/11489051 [00:15<00:13, 451005.84it/s]\u001b[A\n",
            "pandas bar:  46%|████▌     | 5313199/11489051 [00:15<00:12, 501610.17it/s]\u001b[A\n",
            "pandas bar:  47%|████▋     | 5380287/11489051 [00:15<00:11, 542687.68it/s]\u001b[A\n",
            "pandas bar:  47%|████▋     | 5448396/11489051 [00:15<00:10, 577916.53it/s]\u001b[A\n",
            "pandas bar:  48%|████▊     | 5517322/11489051 [00:15<00:09, 607347.89it/s]\u001b[A\n",
            "pandas bar:  49%|████▊     | 5586925/11489051 [00:15<00:09, 631484.75it/s]\u001b[A\n",
            "pandas bar:  49%|████▉     | 5656958/11489051 [00:16<00:08, 650672.35it/s]\u001b[A\n",
            "pandas bar:  50%|████▉     | 5725749/11489051 [00:16<00:08, 661394.43it/s]\u001b[A\n",
            "pandas bar:  50%|█████     | 5794468/11489051 [00:16<00:08, 667162.03it/s]\u001b[A\n",
            "pandas bar:  51%|█████     | 5863002/11489051 [00:16<00:08, 663465.65it/s]\u001b[A\n",
            "pandas bar:  52%|█████▏    | 5930626/11489051 [00:16<00:08, 663309.76it/s]\u001b[A\n",
            "pandas bar:  52%|█████▏    | 5997852/11489051 [00:16<00:08, 665968.96it/s]\u001b[A\n",
            "pandas bar:  53%|█████▎    | 6065078/11489051 [00:16<00:08, 661155.67it/s]\u001b[A\n",
            "pandas bar:  53%|█████▎    | 6133217/11489051 [00:16<00:08, 666222.71it/s]\u001b[A\n",
            "pandas bar:  54%|█████▍    | 6200162/11489051 [00:16<00:07, 663475.15it/s]\u001b[A\n",
            "pandas bar:  55%|█████▍    | 6267794/11489051 [00:16<00:07, 666628.54it/s]\u001b[A\n",
            "pandas bar:  55%|█████▌    | 6334679/11489051 [00:17<00:07, 667293.14it/s]\u001b[A\n",
            "pandas bar:  56%|█████▌    | 6403111/11489051 [00:17<00:07, 672296.16it/s]\u001b[A\n",
            "pandas bar:  56%|█████▋    | 6470430/11489051 [00:17<00:07, 672394.64it/s]\u001b[A\n",
            "pandas bar:  57%|█████▋    | 6539037/11489051 [00:17<00:07, 676389.29it/s]\u001b[A\n",
            "pandas bar:  58%|█████▊    | 6607022/11489051 [00:17<00:07, 677423.03it/s]\u001b[A\n",
            "pandas bar:  58%|█████▊    | 6676829/11489051 [00:17<00:07, 683486.48it/s]\u001b[A\n",
            "pandas bar:  59%|█████▊    | 6745215/11489051 [00:17<00:07, 670802.17it/s]\u001b[A\n",
            "pandas bar:  59%|█████▉    | 6812375/11489051 [00:17<00:07, 667608.68it/s]\u001b[A\n",
            "pandas bar:  60%|█████▉    | 6880052/11489051 [00:17<00:06, 670330.64it/s]\u001b[A\n",
            "pandas bar:  60%|██████    | 6947768/11489051 [00:17<00:06, 672363.70it/s]\u001b[A\n",
            "pandas bar:  61%|██████    | 7015037/11489051 [00:18<00:06, 670781.17it/s]\u001b[A\n",
            "pandas bar:  62%|██████▏   | 7084790/11489051 [00:18<00:06, 678585.73it/s]\u001b[A\n",
            "pandas bar:  62%|██████▏   | 7153141/11489051 [00:18<00:06, 680052.35it/s]\u001b[A\n",
            "pandas bar:  63%|██████▎   | 7222086/11489051 [00:18<00:06, 682843.86it/s]\u001b[A\n",
            "pandas bar:  63%|██████▎   | 7290393/11489051 [00:18<00:06, 680963.59it/s]\u001b[A\n",
            "pandas bar:  64%|██████▍   | 7359955/11489051 [00:18<00:06, 685293.03it/s]\u001b[A\n",
            "pandas bar:  65%|██████▍   | 7428558/11489051 [00:18<00:05, 685232.06it/s]\u001b[A\n",
            "pandas bar:  65%|██████▌   | 7499402/11489051 [00:18<00:05, 692032.91it/s]\u001b[A\n",
            "pandas bar:  66%|██████▌   | 7569445/11489051 [00:18<00:05, 694500.48it/s]\u001b[A\n",
            "pandas bar:  66%|██████▋   | 7638915/11489051 [00:18<00:05, 694279.01it/s]\u001b[A\n",
            "pandas bar:  67%|██████▋   | 7708357/11489051 [00:19<00:05, 688913.85it/s]\u001b[A\n",
            "pandas bar:  68%|██████▊   | 7777268/11489051 [00:19<00:05, 679624.98it/s]\u001b[A\n",
            "pandas bar:  68%|██████▊   | 7845939/11489051 [00:19<00:05, 681732.38it/s]\u001b[A\n",
            "pandas bar:  69%|██████▉   | 7914143/11489051 [00:19<00:05, 679345.55it/s]\u001b[A\n",
            "pandas bar:  69%|██████▉   | 7982101/11489051 [00:19<00:05, 672668.88it/s]\u001b[A\n",
            "pandas bar:  70%|███████   | 8050580/11489051 [00:19<00:05, 676257.72it/s]\u001b[A\n",
            "pandas bar:  71%|███████   | 8119700/11489051 [00:19<00:04, 680669.92it/s]\u001b[A\n",
            "pandas bar:  71%|███████▏  | 8189789/11489051 [00:19<00:04, 686592.84it/s]\u001b[A\n",
            "pandas bar:  72%|███████▏  | 8260234/11489051 [00:19<00:04, 691847.59it/s]\u001b[A\n",
            "pandas bar:  72%|███████▏  | 8329450/11489051 [00:19<00:04, 691083.15it/s]\u001b[A\n",
            "pandas bar:  73%|███████▎  | 8398580/11489051 [00:20<00:04, 685239.80it/s]\u001b[A\n",
            "pandas bar:  74%|███████▎  | 8467199/11489051 [00:20<00:04, 685518.41it/s]\u001b[A\n",
            "pandas bar:  74%|███████▍  | 8535770/11489051 [00:20<00:04, 683790.28it/s]\u001b[A\n",
            "pandas bar:  75%|███████▍  | 8604164/11489051 [00:20<00:04, 678405.00it/s]\u001b[A\n",
            "pandas bar:  75%|███████▌  | 8672025/11489051 [00:20<00:04, 677526.27it/s]\u001b[A\n",
            "pandas bar:  76%|███████▌  | 8739792/11489051 [00:25<00:59, 46444.57it/s] \u001b[A\n",
            "pandas bar:  77%|███████▋  | 8804043/11489051 [00:25<00:41, 64355.65it/s]\u001b[A\n",
            "pandas bar:  77%|███████▋  | 8869669/11489051 [00:25<00:29, 88227.61it/s]\u001b[A\n",
            "pandas bar:  78%|███████▊  | 8935797/11489051 [00:25<00:21, 119222.25it/s]\u001b[A\n",
            "pandas bar:  78%|███████▊  | 9001399/11489051 [00:25<00:15, 158010.42it/s]\u001b[A\n",
            "pandas bar:  79%|███████▉  | 9067907/11489051 [00:25<00:11, 204869.16it/s]\u001b[A\n",
            "pandas bar:  80%|███████▉  | 9135862/11489051 [00:25<00:09, 259182.36it/s]\u001b[A\n",
            "pandas bar:  80%|████████  | 9203400/11489051 [00:25<00:07, 317965.31it/s]\u001b[A\n",
            "pandas bar:  81%|████████  | 9273197/11489051 [00:25<00:05, 380037.75it/s]\u001b[A\n",
            "pandas bar:  81%|████████▏ | 9341696/11489051 [00:25<00:04, 438617.92it/s]\u001b[A\n",
            "pandas bar:  82%|████████▏ | 9409575/11489051 [00:26<00:04, 490703.67it/s]\u001b[A\n",
            "pandas bar:  82%|████████▏ | 9476995/11489051 [00:26<00:03, 528099.33it/s]\u001b[A\n",
            "pandas bar:  83%|████████▎ | 9544292/11489051 [00:26<00:03, 564558.36it/s]\u001b[A\n",
            "pandas bar:  84%|████████▎ | 9611594/11489051 [00:26<00:03, 593237.62it/s]\u001b[A\n",
            "pandas bar:  84%|████████▍ | 9679484/11489051 [00:26<00:02, 616573.75it/s]\u001b[A\n",
            "pandas bar:  85%|████████▍ | 9746883/11489051 [00:26<00:02, 632743.01it/s]\u001b[A\n",
            "pandas bar:  85%|████████▌ | 9814136/11489051 [00:26<00:02, 637766.66it/s]\u001b[A\n",
            "pandas bar:  86%|████████▌ | 9882990/11489051 [00:26<00:02, 652192.59it/s]\u001b[A\n",
            "pandas bar:  87%|████████▋ | 9950246/11489051 [00:26<00:02, 649674.06it/s]\u001b[A\n",
            "pandas bar:  87%|████████▋ | 10019765/11489051 [00:26<00:02, 662688.41it/s]\u001b[A\n",
            "pandas bar:  88%|████████▊ | 10087970/11489051 [00:27<00:02, 668377.85it/s]\u001b[A\n",
            "pandas bar:  88%|████████▊ | 10157333/11489051 [00:27<00:01, 675757.55it/s]\u001b[A\n",
            "pandas bar:  89%|████████▉ | 10225458/11489051 [00:27<00:01, 675607.74it/s]\u001b[A\n",
            "pandas bar:  90%|████████▉ | 10293403/11489051 [00:27<00:01, 674484.16it/s]\u001b[A\n",
            "pandas bar:  90%|█████████ | 10361121/11489051 [00:27<00:01, 671382.31it/s]\u001b[A\n",
            "pandas bar:  91%|█████████ | 10430590/11489051 [00:27<00:01, 678198.02it/s]\u001b[A\n",
            "pandas bar:  91%|█████████▏| 10498561/11489051 [00:27<00:01, 675447.72it/s]\u001b[A\n",
            "pandas bar:  92%|█████████▏| 10566214/11489051 [00:27<00:01, 669501.35it/s]\u001b[A\n",
            "pandas bar:  93%|█████████▎| 10633604/11489051 [00:27<00:01, 670812.70it/s]\u001b[A\n",
            "pandas bar:  93%|█████████▎| 10701021/11489051 [00:28<00:01, 671813.70it/s]\u001b[A\n",
            "pandas bar:  94%|█████████▎| 10768247/11489051 [00:28<00:01, 665018.22it/s]\u001b[A\n",
            "pandas bar:  94%|█████████▍| 10838403/11489051 [00:28<00:00, 675572.57it/s]\u001b[A\n",
            "pandas bar:  95%|█████████▍| 10907443/11489051 [00:28<00:00, 679953.20it/s]\u001b[A\n",
            "pandas bar:  96%|█████████▌| 10975497/11489051 [00:28<00:00, 673372.72it/s]\u001b[A\n",
            "pandas bar:  96%|█████████▌| 11043064/11489051 [00:28<00:00, 674059.49it/s]\u001b[A\n",
            "pandas bar:  97%|█████████▋| 11111294/11489051 [00:28<00:00, 676510.38it/s]\u001b[A\n",
            "pandas bar:  97%|█████████▋| 11178975/11489051 [00:28<00:00, 670781.06it/s]\u001b[A\n",
            "pandas bar:  98%|█████████▊| 11247793/11489051 [00:28<00:00, 675907.38it/s]\u001b[A\n",
            "pandas bar:  99%|█████████▊| 11318388/11489051 [00:28<00:00, 684646.50it/s]\u001b[A\n",
            "pandas bar:  99%|█████████▉| 11387119/11489051 [00:29<00:00, 685440.64it/s]\u001b[A\n",
            "pandas bar: 100%|██████████| 11489051/11489051 [00:29<00:00, 389389.04it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMtAzJHZz3N5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TargetAttentionLayer(Layer):\n",
        "    def __init__(self, n_steps, embedding_size, hidden_dim, random_state, **kwargs):\n",
        "        self.n_steps = n_steps\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.random_state = random_state\n",
        "        super(TargetAttentionLayer, self).__init__(**kwargs)\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(\n",
        "            name='W',\n",
        "            shape=(self.embedding_size, self.hidden_dim),\n",
        "            initializer=keras.initializers.truncated_normal(stddev=0.1, seed=self.random_state),\n",
        "            trainable=True\n",
        "        )\n",
        "        self.W_BIAS = self.add_weight(\n",
        "            name='W_BIAS',\n",
        "            shape=(self.hidden_dim,),\n",
        "            initializer=keras.initializers.Constant(value=0.1),\n",
        "            trainable=True\n",
        "        )\n",
        "        self.O = self.add_weight(\n",
        "            name='O',\n",
        "            shape=(self.hidden_dim, 1),\n",
        "            initializer=keras.initializers.truncated_normal(stddev=0.1, seed=self.random_state),\n",
        "            trainable=True\n",
        "        )\n",
        "        self.O_BIAS = self.add_weight(\n",
        "            name='O_BIAS',\n",
        "            shape=(1,),\n",
        "            initializer=keras.initializers.Constant(value=0.1),\n",
        "            trainable=True\n",
        "        )\n",
        "        super(TargetAttentionLayer, self).build(input_shape)\n",
        "    \n",
        "    def call(self, x):\n",
        "        his_embedding_vectors, target_embedding_vector, mask = x\n",
        "        mask = BKD.reshape(mask, [-1, 1, self.n_steps])\n",
        "        target_embedding_vector = BKD.tile(target_embedding_vector, [1, self.n_steps, 1])\n",
        "        diff = his_embedding_vectors - target_embedding_vector\n",
        "        attention_vec = concatenate([his_embedding_vectors, diff, target_embedding_vector], axis=2)\n",
        "        alpha = BKD.relu(BKD.bias_add(BKD.dot(attention_vec, self.W), self.W_BIAS))\n",
        "        alpha = BKD.bias_add(BKD.dot(alpha, self.O), self.O_BIAS)\n",
        "        alpha = BKD.permute_dimensions(alpha, [0, 2, 1]) - mask * 1e10\n",
        "        attention = BKD.batch_dot(BKD.softmax(alpha), his_embedding_vectors)\n",
        "        return BKD.squeeze(attention, axis=1)\n",
        "    \n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0][0], input_shape[0][2])\n",
        "\n",
        "\n",
        "class SelfAttentionLayer(Layer):\n",
        "    def __init__(self, head_count, n_steps, embedding_size, QKV_dim, random_state, **kwargs):\n",
        "        self.head_count = head_count\n",
        "        self.n_steps = n_steps\n",
        "        self.embedding_size = embedding_size\n",
        "        self.QKV_dim = QKV_dim\n",
        "        self.random_state = random_state\n",
        "        super(SelfAttentionLayer, self).__init__(**kwargs)\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.WQ, self.WK, self.WV = [], [], []\n",
        "        for i in range(self.head_count):\n",
        "            self.WQ.append(\n",
        "                self.add_weight(\n",
        "                    name='WQ{}'.format(i),\n",
        "                    shape=(self.embedding_size, self.QKV_dim),\n",
        "                    initializer=keras.initializers.truncated_normal(stddev=0.1, seed=self.random_state),\n",
        "                    trainable=True\n",
        "                )\n",
        "            )\n",
        "            self.WK.append(\n",
        "                self.add_weight(\n",
        "                    name='WK{}'.format(i),\n",
        "                    shape=(self.embedding_size, self.QKV_dim),\n",
        "                    initializer=keras.initializers.truncated_normal(stddev=0.1, seed=self.random_state),\n",
        "                    trainable=True\n",
        "                )\n",
        "            )\n",
        "            self.WV.append(\n",
        "                self.add_weight(\n",
        "                    name='WV{}'.format(i),\n",
        "                    shape=(self.embedding_size, self.QKV_dim),\n",
        "                    initializer=keras.initializers.truncated_normal(stddev=0.1, seed=self.random_state),\n",
        "                    trainable=True\n",
        "                )\n",
        "            )\n",
        "        self.BE = self.add_weight(\n",
        "            name='BE',\n",
        "            shape=(self.n_steps, self.embedding_size),\n",
        "            initializer=keras.initializers.truncated_normal(stddev=0.1, seed=self.random_state),\n",
        "            trainable=True\n",
        "        )\n",
        "        self.WO = self.add_weight(\n",
        "            name='WO',\n",
        "            shape=(self.head_count * self.QKV_dim, self.embedding_size),\n",
        "            initializer=keras.initializers.truncated_normal(stddev=0.1, seed=self.random_state),\n",
        "            trainable=True\n",
        "        )\n",
        "        super(SelfAttentionLayer, self).build(input_shape)\n",
        "    \n",
        "    def call(self, x):\n",
        "        his_embedding_vectors, mask = x\n",
        "        mask = BKD.reshape(mask, [-1, 1, self.n_steps])\n",
        "        mask = BKD.tile(mask, [1, self.n_steps, 1])\n",
        "        his_embedding_vectors = his_embedding_vectors + self.BE\n",
        "        attention = []\n",
        "        for i in range(self.head_count):\n",
        "            Q = BKD.dot(his_embedding_vectors, self.WQ[i])\n",
        "            K = BKD.dot(his_embedding_vectors, self.WK[i])\n",
        "            V = BKD.dot(his_embedding_vectors, self.WV[i])\n",
        "            alpha = BKD.batch_dot(Q, BKD.permute_dimensions(K, [0, 2, 1])) / np.sqrt(self.embedding_size)\n",
        "            alpha = BKD.softmax(alpha - mask * 1e10)\n",
        "            attention.append(BKD.batch_dot(alpha, V))\n",
        "        if self.head_count > 1:\n",
        "            attention = concatenate(attention, axis=2)\n",
        "        else:\n",
        "            attention = attention[0]\n",
        "        return BKD.dot(attention, self.WO)\n",
        "    \n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0][0], input_shape[0][1], input_shape[0][2])\n",
        "\n",
        "\n",
        "def TargetAttentionNet(\n",
        "    n_steps, vocab_size, embedding_matrix_init, embedding_size, feats_dim,\n",
        "    head_count, QKV_dim, attention_hidden_dim=32, output_dim=2, random_state=None\n",
        "):\n",
        "\n",
        "\n",
        "\n",
        "    X_HIS = Input(shape=(n_steps,), dtype='int32')\n",
        "    X_MASK = Input(shape=(n_steps,), dtype='float32')\n",
        "    X_TARGET = Input(shape=(1,), dtype='int32')\n",
        "    X_FEATS = Input(shape=(feats_dim,), dtype='float32')\n",
        "    \n",
        "    embedding_matrix = Embedding(\n",
        "        input_dim=vocab_size+1,\n",
        "        output_dim=embedding_size,\n",
        "        embeddings_initializer=keras.initializers.Constant(value=embedding_matrix_init),\n",
        "        dtype='float32',\n",
        "        trainable=False #because we had aready use w2v vec as embedding initializer\n",
        "    )\n",
        "    \n",
        "    his_embedding_vectors = embedding_matrix(X_HIS)\n",
        "    his_embedding_vectors = SelfAttentionLayer(head_count, n_steps, embedding_size, QKV_dim, random_state)([his_embedding_vectors, X_MASK])\n",
        "    lstm_out = Bidirectional(LSTM(embedding_size, return_sequences=True), merge_mode='sum')(his_embedding_vectors)\n",
        "    \n",
        "    target_embedding_vector = embedding_matrix(X_TARGET)\n",
        "    attention_vector = TargetAttentionLayer(\n",
        "        n_steps, 3 * embedding_size, attention_hidden_dim, random_state, name='emb')([lstm_out, target_embedding_vector, X_MASK])\n",
        "    target_embedding_vector = Lambda(lambda x: BKD.reshape(x, [-1, embedding_size]))(target_embedding_vector)\n",
        "    \n",
        "    dense_input = concatenate([\n",
        "        attention_vector,\n",
        "        target_embedding_vector,\n",
        "        X_FEATS\n",
        "    ], axis=1)\n",
        "        \n",
        "    a = Dense(\n",
        "        512,\n",
        "        activation='relu',\n",
        "        kernel_initializer=keras.initializers.truncated_normal(stddev=0.1, seed=random_state),\n",
        "        bias_initializer=keras.initializers.Constant(value=0.1)\n",
        "    )(dense_input)\n",
        "    a = Dense(\n",
        "        128,\n",
        "        activation='relu',\n",
        "        kernel_initializer=keras.initializers.truncated_normal(stddev=0.1, seed=random_state),\n",
        "        bias_initializer=keras.initializers.Constant(value=0.1)\n",
        "    )(a)\n",
        "    output = Dense(\n",
        "        output_dim,\n",
        "        activation='softmax',\n",
        "        kernel_initializer=keras.initializers.truncated_normal(stddev=0.1, seed=random_state),\n",
        "        bias_initializer=keras.initializers.Constant(value=0.1)\n",
        "    )(a)\n",
        "    \n",
        "    model = keras.models.Model(inputs=[X_HIS, X_MASK, X_TARGET, X_FEATS], outputs=output)\n",
        "    model.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer='adam',\n",
        "    )\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPg8Kric1hAZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0c148009-5c52-43b4-8da3-52feaf91fab5"
      },
      "source": [
        "feats_cols = [f for f in df.columns if f not in ['user_id', 'phase', 'query_time', 'item_id', 'label', 'history']]\n",
        "print(feats_cols)\n",
        "drop_cols = []\n",
        "for f in feats_cols:\n",
        "    if df[f].count() / df[f].shape[0] <= 0.7:\n",
        "        drop_cols.append(f)\n",
        "print(drop_cols)\n",
        "feats_cols = [f for f in feats_cols if f not in drop_cols]\n",
        "for f in tqdm(feats_cols):\n",
        "    df[f] = df[f].astype('float32')\n",
        "    df[f] = df[f].fillna(df[f].mean())\n",
        "    df[f] = StandardScaler().fit_transform(df[[f]].values).squeeze()\n",
        "print(df.shape)\n",
        "print(feats_cols)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['txt_vec10_pca0', 'txt_vec10_pca1', 'txt_vec10_pca2', 'txt_vec10_pca3', 'txt_vec10_pca4', 'txt_vec10_pca5', 'txt_vec10_pca6', 'txt_vec10_pca7', 'txt_vec10_pca8', 'txt_vec10_pca9', 'img_vec10_pca0', 'img_vec10_pca1', 'img_vec10_pca2', 'img_vec10_pca3', 'img_vec10_pca4', 'img_vec10_pca5', 'img_vec10_pca6', 'img_vec10_pca7', 'img_vec10_pca8', 'img_vec10_pca9', 'phase_item_clickd_count', 'phase_item_click_time_diff_mean', 'item_id_phase_user_age_level_mean', 'item_id_phase_user_age_level_min', 'item_id_phase_user_age_level_max', 'item_id_phase_user_age_level_std', 'phase_item_click_gender_mean', 'user_age_level', 'user_gender', 'user_city_level', 'phase_user_click_count', 'phase_user_age_level_click_count', 'user_id_phase_time_std', 'user_id_phase_time_max_min_diff', 'user_id_phase_query_lastbuy_time_diff', 'user_click_item_if_sim_sum', 'user_click_item_if_sim_max', 'user_last_click_item_if_sim', 'user_click_item_if_sim_rolling2_sum', 'user_click_item_bn_sim_sum', 'user_item_txt_sim', 'user_click_item_txt_sim_sum', 'user_click_item_txt_sim_max', 'user_last_click_item_txt_sim', 'user_click_item_txt_sim_rolling2_sum', 'user_click_item_txt_sim_rolling2_mean', 'user_click_item_txt_sim_rolling3_mean', 'user_item_img_sim', 'user_click_item_tc_sim_sum', 'user_click_item_tc_sim_max', 'user_click_item_tc_sim_rolling2_sum', 'user_last_click_item_w2w_sim', 'user_click_item_w2w_sim_sum_2', 'user_last_click_item_deepwalk_sim', 'user_click_item_deepwalk_sim_sum_2', 'user_last_click_item_n2v_sim', 'user_click_item_n2v_sim_sum_2', 'user_click_item_common_sim_sum', 'user_click_item_common_sim_max', 'user_last_click_common_if_sim', 'user_click_item_common_sim_rolling2_sum', 'item_w2v_0', 'item_w2v_1', 'item_w2v_2', 'item_w2v_3', 'item_w2v_4', 'item_w2v_5', 'item_w2v_6', 'item_w2v_7']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/60 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['item_id_phase_user_age_level_mean', 'item_id_phase_user_age_level_min', 'item_id_phase_user_age_level_max', 'item_id_phase_user_age_level_std', 'phase_item_click_gender_mean', 'user_age_level', 'user_gender', 'user_city_level', 'phase_user_age_level_click_count']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  2%|▏         | 1/60 [00:00<00:55,  1.07it/s]\u001b[A\n",
            "  3%|▎         | 2/60 [00:01<00:51,  1.13it/s]\u001b[A\n",
            "  5%|▌         | 3/60 [00:02<00:48,  1.18it/s]\u001b[A\n",
            "  7%|▋         | 4/60 [00:03<00:45,  1.22it/s]\u001b[A\n",
            "  8%|▊         | 5/60 [00:04<00:47,  1.16it/s]\u001b[A\n",
            " 10%|█         | 6/60 [00:04<00:45,  1.20it/s]\u001b[A\n",
            " 12%|█▏        | 7/60 [00:05<00:43,  1.22it/s]\u001b[A\n",
            " 13%|█▎        | 8/60 [00:06<00:42,  1.23it/s]\u001b[A\n",
            " 15%|█▌        | 9/60 [00:07<00:41,  1.24it/s]\u001b[A\n",
            " 17%|█▋        | 10/60 [00:08<00:40,  1.24it/s]\u001b[A\n",
            " 18%|█▊        | 11/60 [00:08<00:39,  1.24it/s]\u001b[A\n",
            " 20%|██        | 12/60 [00:09<00:38,  1.24it/s]\u001b[A\n",
            " 22%|██▏       | 13/60 [00:10<00:38,  1.23it/s]\u001b[A\n",
            " 23%|██▎       | 14/60 [00:11<00:37,  1.23it/s]\u001b[A\n",
            " 25%|██▌       | 15/60 [00:12<00:36,  1.22it/s]\u001b[A\n",
            " 27%|██▋       | 16/60 [00:13<00:36,  1.21it/s]\u001b[A\n",
            " 28%|██▊       | 17/60 [00:13<00:36,  1.17it/s]\u001b[A\n",
            " 30%|███       | 18/60 [00:15<00:45,  1.08s/it]\u001b[A\n",
            " 32%|███▏      | 19/60 [00:16<00:41,  1.02s/it]\u001b[A\n",
            " 33%|███▎      | 20/60 [00:17<00:39,  1.02it/s]\u001b[A\n",
            " 35%|███▌      | 21/60 [00:18<00:40,  1.05s/it]\u001b[A\n",
            " 37%|███▋      | 22/60 [00:19<00:38,  1.02s/it]\u001b[A\n",
            " 38%|███▊      | 23/60 [00:20<00:34,  1.08it/s]\u001b[A\n",
            " 40%|████      | 24/60 [00:21<00:33,  1.09it/s]\u001b[A\n",
            " 42%|████▏     | 25/60 [00:22<00:34,  1.03it/s]\u001b[A\n",
            " 43%|████▎     | 26/60 [00:23<00:32,  1.04it/s]\u001b[A\n",
            " 45%|████▌     | 27/60 [00:24<00:31,  1.05it/s]\u001b[A\n",
            " 47%|████▋     | 28/60 [00:25<00:30,  1.06it/s]\u001b[A\n",
            " 48%|████▊     | 29/60 [00:25<00:29,  1.06it/s]\u001b[A\n",
            " 50%|█████     | 30/60 [00:27<00:33,  1.11s/it]\u001b[A\n",
            " 52%|█████▏    | 31/60 [00:28<00:30,  1.07s/it]\u001b[A\n",
            " 53%|█████▎    | 32/60 [00:29<00:28,  1.03s/it]\u001b[A\n",
            " 55%|█████▌    | 33/60 [00:30<00:27,  1.01s/it]\u001b[A\n",
            " 57%|█████▋    | 34/60 [00:31<00:26,  1.00s/it]\u001b[A\n",
            " 58%|█████▊    | 35/60 [00:32<00:24,  1.00it/s]\u001b[A\n",
            " 60%|██████    | 36/60 [00:35<00:41,  1.73s/it]\u001b[A\n",
            " 62%|██████▏   | 37/60 [00:36<00:34,  1.51s/it]\u001b[A\n",
            " 63%|██████▎   | 38/60 [00:37<00:29,  1.36s/it]\u001b[A\n",
            " 65%|██████▌   | 39/60 [00:38<00:26,  1.26s/it]\u001b[A\n",
            " 67%|██████▋   | 40/60 [00:39<00:23,  1.20s/it]\u001b[A\n",
            " 68%|██████▊   | 41/60 [00:40<00:21,  1.15s/it]\u001b[A\n",
            " 70%|███████   | 42/60 [00:42<00:22,  1.24s/it]\u001b[A\n",
            " 72%|███████▏  | 43/60 [00:43<00:20,  1.19s/it]\u001b[A\n",
            " 73%|███████▎  | 44/60 [00:44<00:19,  1.21s/it]\u001b[A\n",
            " 75%|███████▌  | 45/60 [00:45<00:18,  1.24s/it]\u001b[A\n",
            " 77%|███████▋  | 46/60 [00:47<00:17,  1.26s/it]\u001b[A\n",
            " 78%|███████▊  | 47/60 [00:48<00:16,  1.23s/it]\u001b[A\n",
            " 80%|████████  | 48/60 [00:49<00:15,  1.27s/it]\u001b[A\n",
            " 82%|████████▏ | 49/60 [00:50<00:13,  1.24s/it]\u001b[A\n",
            " 83%|████████▎ | 50/60 [00:52<00:12,  1.28s/it]\u001b[A\n",
            " 85%|████████▌ | 51/60 [00:53<00:11,  1.25s/it]\u001b[A\n",
            " 87%|████████▋ | 52/60 [00:54<00:10,  1.26s/it]\u001b[A\n",
            " 88%|████████▊ | 53/60 [00:56<00:08,  1.25s/it]\u001b[A\n",
            " 90%|█████████ | 54/60 [00:58<00:10,  1.72s/it]\u001b[A\n",
            " 92%|█████████▏| 55/60 [01:02<00:11,  2.34s/it]\u001b[A\n",
            " 93%|█████████▎| 56/60 [01:04<00:09,  2.30s/it]\u001b[A\n",
            " 95%|█████████▌| 57/60 [01:06<00:06,  2.13s/it]\u001b[A\n",
            " 97%|█████████▋| 58/60 [01:08<00:03,  1.96s/it]\u001b[A\n",
            " 98%|█████████▊| 59/60 [01:09<00:01,  1.89s/it]\u001b[A\n",
            "100%|██████████| 60/60 [01:11<00:00,  1.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(11489051, 75)\n",
            "['txt_vec10_pca0', 'txt_vec10_pca1', 'txt_vec10_pca2', 'txt_vec10_pca3', 'txt_vec10_pca4', 'txt_vec10_pca5', 'txt_vec10_pca6', 'txt_vec10_pca7', 'txt_vec10_pca8', 'txt_vec10_pca9', 'img_vec10_pca0', 'img_vec10_pca1', 'img_vec10_pca2', 'img_vec10_pca3', 'img_vec10_pca4', 'img_vec10_pca5', 'img_vec10_pca6', 'img_vec10_pca7', 'img_vec10_pca8', 'img_vec10_pca9', 'phase_item_clickd_count', 'phase_item_click_time_diff_mean', 'phase_user_click_count', 'user_id_phase_time_std', 'user_id_phase_time_max_min_diff', 'user_id_phase_query_lastbuy_time_diff', 'user_click_item_if_sim_sum', 'user_click_item_if_sim_max', 'user_last_click_item_if_sim', 'user_click_item_if_sim_rolling2_sum', 'user_click_item_bn_sim_sum', 'user_item_txt_sim', 'user_click_item_txt_sim_sum', 'user_click_item_txt_sim_max', 'user_last_click_item_txt_sim', 'user_click_item_txt_sim_rolling2_sum', 'user_click_item_txt_sim_rolling2_mean', 'user_click_item_txt_sim_rolling3_mean', 'user_item_img_sim', 'user_click_item_tc_sim_sum', 'user_click_item_tc_sim_max', 'user_click_item_tc_sim_rolling2_sum', 'user_last_click_item_w2w_sim', 'user_click_item_w2w_sim_sum_2', 'user_last_click_item_deepwalk_sim', 'user_click_item_deepwalk_sim_sum_2', 'user_last_click_item_n2v_sim', 'user_click_item_n2v_sim_sum_2', 'user_click_item_common_sim_sum', 'user_click_item_common_sim_max', 'user_last_click_common_if_sim', 'user_click_item_common_sim_rolling2_sum', 'item_w2v_0', 'item_w2v_1', 'item_w2v_2', 'item_w2v_3', 'item_w2v_4', 'item_w2v_5', 'item_w2v_6', 'item_w2v_7']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLbqXDnc3CBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feats_cols=['txt_vec10_pca0']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZczspshzrEt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "95e24fa7-1d40-4bf7-eb68-462ca965cb83"
      },
      "source": [
        "train_df = df[~df['label'].isna()].reset_index(drop=True)\n",
        "train_df['label'] = train_df['label'].astype('int8')\n",
        "test_df = df[df['label'].isna()].reset_index(drop=True)\n",
        "\n",
        "\n",
        "train_his = np.array(train_df['history'].values.tolist())\n",
        "train_mask = (train_his == 0).astype('float32')\n",
        "train_target = train_df['item_id'].values\n",
        "train_feats = train_df[feats_cols].values\n",
        "labels = train_df['label'].values\n",
        "\n",
        "test_his = np.array(test_df['history'].values.tolist())\n",
        "test_mask = (test_his == 0).astype('float32')\n",
        "test_target = test_df['item_id'].values\n",
        "test_feats = test_df[feats_cols].values\n",
        "\n",
        "del train_df, test_df, model\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "225"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8WC_Siq4WuB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7cf5dc48-2772-485c-d7a6-cb33317a4d55"
      },
      "source": [
        "oof_df = df[~df['label'].isna()].reset_index(drop=True)[['user_id', 'phase', 'item_id']]\n",
        "test_pred_df = df[df['label'].isna()].reset_index(drop=True)[['user_id', 'phase', 'item_id']]\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=2020)\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=1, verbose=1, mode='min')\n",
        "output_dim = 2\n",
        "oof_df['nn_prob'] = 0\n",
        "test_pred_df['nn_prob'] = 0\n",
        "oof_emb = np.zeros((oof_df.shape[0], emb_size))\n",
        "test_emb = np.zeros((test_pred_df.shape[0], emb_size))\n",
        "for i, (trn_idx, val_idx) in enumerate(skf.split(train_his, labels)):\n",
        "    print('============ {} fold ============'.format(i))\n",
        "    TFBKD.clear_session()\n",
        "    t = time.time()\n",
        "    \n",
        "    trn_his, trn_mask, trn_target = train_his[trn_idx], train_mask[trn_idx], train_target[trn_idx]\n",
        "    trn_feats, trn_y = train_feats[trn_idx], labels[trn_idx]\n",
        "    val_his, val_mask, val_target = train_his[val_idx], train_mask[val_idx], train_target[val_idx]\n",
        "    val_feats, val_y = train_feats[val_idx], labels[val_idx]\n",
        "    \n",
        "    # config = tf.ConfigProto()\n",
        "    # config.gpu_options.allow_growth=True\n",
        "    # sess = tf.Session(config=config)\n",
        "    # TFBKD.set_session(sess)\n",
        "    \n",
        "    clf = TargetAttentionNet(\n",
        "        n_steps=max_len,\n",
        "        vocab_size=56098,\n",
        "        embedding_matrix_init=embedding_matrix,\n",
        "        embedding_size=emb_size,\n",
        "        feats_dim=trn_feats.shape[1],\n",
        "        head_count=8,\n",
        "        QKV_dim=emb_size,\n",
        "        attention_hidden_dim=128,\n",
        "        output_dim=output_dim,\n",
        "        random_state=2020\n",
        "    )\n",
        "    clf.fit(\n",
        "        x=[trn_his, trn_mask, trn_target, trn_feats], y=np.eye(output_dim)[trn_y],\n",
        "        batch_size=1024, epochs=4,\n",
        "        validation_data=([val_his, val_mask, val_target, val_feats], np.eye(output_dim)[val_y]),\n",
        "        verbose=1, callbacks=[early_stopping]\n",
        "    )\n",
        "    oof_df.loc[val_idx, 'nn_prob'] = clf.predict([val_his, val_mask, val_target, val_feats], batch_size=2048)[:, 1]\n",
        "    print('val auc:', roc_auc_score(val_y, oof_df['nn_prob'].values[val_idx]))\n",
        "    test_pred_df['nn_prob'] += clf.predict([test_his, test_mask, test_target, test_feats], batch_size=2048)[:, 1] / skf.n_splits\n",
        "    emb_layer = keras.models.Model(inputs=clf.input, outputs=clf.get_layer(name='emb').output)\n",
        "    oof_emb[val_idx] = emb_layer.predict([val_his, val_mask, val_target, val_feats], batch_size=2048)\n",
        "    test_emb += emb_layer.predict([test_his, test_mask, test_target, test_feats], batch_size=2048) / skf.n_splits\n",
        "    \n",
        "    del emb_layer, clf\n",
        "    # BKD.clear_session()\n",
        "    # tf.reset_default_graph()\n",
        "    gc.collect()\n",
        "    \n",
        "    print('runtime: {}\\n'.format(time.time() - t))\n",
        "\n",
        "\n",
        "for i in tqdm(range(emb_size)):\n",
        "    oof_df['nn_emb_{}'.format(i)] = oof_emb[:, i]\n",
        "    test_pred_df['nn_emb_{}'.format(i)] = test_emb[:, i]\n",
        "oof_df.to_pickle('kdd2020_data/recall/nn_trn.pkl')\n",
        "test_pred_df.to_pickle('kdd2020_data/recall/nn_test.pkl')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "============ 0 fold ============\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 5)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         multiple             112198      input_1[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 5)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "self_attention_layer_1 (SelfAtt (None, 5, 2)         138         embedding_1[0][0]                \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 5, 2)         80          self_attention_layer_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "emb (TargetAttentionLayer)      (None, 2)            1025        bidirectional_1[0][0]            \n",
            "                                                                 embedding_1[1][0]                \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 2)            0           embedding_1[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 5)            0           emb[0][0]                        \n",
            "                                                                 lambda_1[0][0]                   \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 512)          3072        concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 128)          65664       dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            258         dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 182,435\n",
            "Trainable params: 70,237\n",
            "Non-trainable params: 112,198\n",
            "__________________________________________________________________________________________________\n",
            "Train on 6707795 samples, validate on 1676949 samples\n",
            "Epoch 1/4\n",
            "6707795/6707795 [==============================] - 295s 44us/step - loss: 0.0128 - val_loss: 0.0125\n",
            "Epoch 2/4\n",
            "6707795/6707795 [==============================] - 290s 43us/step - loss: 0.0125 - val_loss: 0.0126\n",
            "Epoch 00002: early stopping\n",
            "val auc: 0.5003349895403548\n",
            "runtime: 631.054888010025\n",
            "\n",
            "============ 1 fold ============\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 5)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         multiple             112198      input_1[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 5)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "self_attention_layer_1 (SelfAtt (None, 5, 2)         138         embedding_1[0][0]                \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 5, 2)         80          self_attention_layer_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "emb (TargetAttentionLayer)      (None, 2)            1025        bidirectional_1[0][0]            \n",
            "                                                                 embedding_1[1][0]                \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 2)            0           embedding_1[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 5)            0           emb[0][0]                        \n",
            "                                                                 lambda_1[0][0]                   \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 512)          3072        concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 128)          65664       dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            258         dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 182,435\n",
            "Trainable params: 70,237\n",
            "Non-trainable params: 112,198\n",
            "__________________________________________________________________________________________________\n",
            "Train on 6707795 samples, validate on 1676949 samples\n",
            "Epoch 1/4\n",
            "6707795/6707795 [==============================] - 291s 43us/step - loss: 0.0129 - val_loss: 0.0125\n",
            "Epoch 2/4\n",
            "6707795/6707795 [==============================] - 287s 43us/step - loss: 0.0125 - val_loss: 0.0125\n",
            "Epoch 3/4\n",
            "6707795/6707795 [==============================] - 288s 43us/step - loss: 0.0125 - val_loss: 0.0125\n",
            "Epoch 4/4\n",
            "6707795/6707795 [==============================] - 289s 43us/step - loss: 0.0125 - val_loss: 0.0124\n",
            "val auc: 0.534569940575226\n",
            "runtime: 1200.5075469017029\n",
            "\n",
            "============ 2 fold ============\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 5)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         multiple             112198      input_1[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 5)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "self_attention_layer_1 (SelfAtt (None, 5, 2)         138         embedding_1[0][0]                \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 5, 2)         80          self_attention_layer_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "emb (TargetAttentionLayer)      (None, 2)            1025        bidirectional_1[0][0]            \n",
            "                                                                 embedding_1[1][0]                \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 2)            0           embedding_1[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 5)            0           emb[0][0]                        \n",
            "                                                                 lambda_1[0][0]                   \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 512)          3072        concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 128)          65664       dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            258         dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 182,435\n",
            "Trainable params: 70,237\n",
            "Non-trainable params: 112,198\n",
            "__________________________________________________________________________________________________\n",
            "Train on 6707795 samples, validate on 1676949 samples\n",
            "Epoch 1/4\n",
            "6707795/6707795 [==============================] - 297s 44us/step - loss: 0.0129 - val_loss: 0.0124\n",
            "Epoch 2/4\n",
            "6707795/6707795 [==============================] - 289s 43us/step - loss: 0.0125 - val_loss: 0.0125\n",
            "Epoch 00002: early stopping\n",
            "val auc: 0.5351872836949613\n",
            "runtime: 631.2893419265747\n",
            "\n",
            "============ 3 fold ============\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 5)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         multiple             112198      input_1[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 5)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "self_attention_layer_1 (SelfAtt (None, 5, 2)         138         embedding_1[0][0]                \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 5, 2)         80          self_attention_layer_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "emb (TargetAttentionLayer)      (None, 2)            1025        bidirectional_1[0][0]            \n",
            "                                                                 embedding_1[1][0]                \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 2)            0           embedding_1[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 5)            0           emb[0][0]                        \n",
            "                                                                 lambda_1[0][0]                   \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 512)          3072        concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 128)          65664       dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            258         dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 182,435\n",
            "Trainable params: 70,237\n",
            "Non-trainable params: 112,198\n",
            "__________________________________________________________________________________________________\n",
            "Train on 6707795 samples, validate on 1676949 samples\n",
            "Epoch 1/4\n",
            "5780480/6707795 [========================>.....] - ETA: 38s - loss: 0.0131"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFBXTsW0fPsH",
        "colab_type": "text"
      },
      "source": [
        "# Rank_4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1OvmY5KfVOP",
        "colab_type": "text"
      },
      "source": [
        "**bert**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK9e9tDJ-Lpo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "f36fce72-ff96-4481-b551-59701cfa7018"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/35/1c3f6e62d81f5f0daff1384e6d5e6c5758682a8357ebc765ece2b9def62b/transformers-3.0.0-py3-none-any.whl (754kB)\n",
            "\u001b[K     |████████████████████████████████| 757kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 19.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting tokenizers==0.8.0-rc4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/bd/e5abec46af977c8a1375c1dca7cb1e5b3ec392ef279067af7f6bc50491a0/tokenizers-0.8.0rc4-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 21.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 32.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=35d42177f0578d5f5bf1686a1420c0d68626c6e611442986d496186a89ea9580\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.0rc4 transformers-3.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6ATBlOSf1Mi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "215e82e6-be86-4d65-ae2c-d85ac2cd9332"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.layers import *\n",
        "from keras import backend as BKD\n",
        "import keras.backend.tensorflow_backend as TFBKD\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from gensim.models import Word2Vec\n",
        "import gensim\n",
        "import gc\n",
        "import time\n",
        "pd.set_option('display.max_columns', None)\n",
        "tqdm.pandas(desc='pandas bar')\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(\n",
        "    level=logging.DEBUG,\n",
        "    filename='logging_log.txt',\n",
        "    filemode='w',\n",
        "    format= '%(asctime)s - %(pathname)s[line:%(lineno)d] - %(levelname)s: %(message)s'\n",
        ")\n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import Lambda, concatenate, Activation\n",
        "def build_model(transformer, max_len=512):\n",
        "\n",
        "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "    sequence_output = transformer(input_word_ids)[0]\n",
        "#     cls_token = sequence_output[:, 0, :]\n",
        "    cls_token = sequence_output\n",
        "    \n",
        "    x1 = tf.keras.layers.Conv1D(128, 2,padding='same')(cls_token)\n",
        "    \n",
        "    x1 = tf.keras.layers.Dropout(0.15)(x1)\n",
        "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
        "    x1 = tf.keras.layers.Dropout(0.15)(x1)\n",
        "   \n",
        "    \n",
        "    x1 = tf.keras.layers.Conv1D(64, 2,padding='same')(x1)\n",
        "    x1 = tf.keras.layers.Dropout(0.15)(x1)\n",
        "    x1 = tf.keras.layers.Dense(1)(x1)\n",
        "    x1 = tf.keras.layers.Dropout(0.15)(x1)\n",
        "    x1 = tf.keras.layers.Flatten()(x1)\n",
        "    \n",
        "\n",
        "    out = Dense(2, activation='softmax')(x1)\n",
        "    model = Model(inputs=input_word_ids, outputs=out)     \n",
        "    model.compile(Adam(lr=1e-5), loss='categorical_crossentropy')\n",
        "\n",
        "    return model\n",
        "\n",
        "MAX_LEN=5\n",
        "MODEL = 'bert-base-cased'\n",
        "from transformers import TFAutoModel, AutoTokenizer\n",
        "transformer_layer = TFAutoModel.from_pretrained(MODEL)\n",
        "model = build_model(transformer_layer, max_len=MAX_LEN)\n",
        "\n",
        "\n",
        "df = pd.read_pickle('kdd2020_data/recall/nn_input.pkl')\n",
        "print(df.shape)\n",
        "\n",
        "words = set()\n",
        "for line in tqdm(df['history'].values):\n",
        "    words |= set(line)\n",
        "words = np.sort(list(words))\n",
        "print(words[:10])\n",
        "vocab_size = len(words)\n",
        "words_idx_dict = dict(zip(words, range(vocab_size)))\n",
        "\n",
        "feats_cols = [f for f in df.columns if f not in ['user_id', 'phase', 'query_time', 'item_id', 'label', 'history']]\n",
        "drop_cols = []\n",
        "for f in feats_cols:\n",
        "    if df[f].count() / df[f].shape[0] <= 0.7:\n",
        "        drop_cols.append(f)\n",
        "print(drop_cols)\n",
        "feats_cols = [f for f in feats_cols if f not in drop_cols]\n",
        "for f in tqdm(feats_cols):\n",
        "    df[f] = df[f].astype('float32')\n",
        "    df[f] = df[f].fillna(df[f].mean())\n",
        "    df[f] = StandardScaler().fit_transform(df[[f]].values).squeeze()\n",
        "print(df.shape)\n",
        "\n",
        "\n",
        "df['item_id'] = df['item_id'].map(words_idx_dict)\n",
        "print(df['item_id'].count() / df.shape[0])\n",
        "df['item_id'] = df['item_id'].fillna(vocab_size).astype('int32')\n",
        "df['item_id'] += 1\n",
        "print(df['item_id'].count() / df.shape[0])\n",
        "\n",
        "\n",
        "df['len'] = df['history'].progress_apply(len)\n",
        "print(df['len'].describe())\n",
        "print(df['len'].quantile(0.9))\n",
        "print(df['len'].quantile(0.95))\n",
        "max_len = int(df['len'].quantile(0.95))\n",
        "del df['len']\n",
        "\n",
        "\n",
        "df['history'] = df['history'].progress_apply(lambda seq: [words_idx_dict[int(x)] + 1 for x in seq])\n",
        "df['history'] = df['history'].progress_apply(\n",
        "    lambda seq: seq[-max_len:] if len(seq) >= max_len else seq + ([0] * (max_len - len(seq)))\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "train_df = df[~df['label'].isna()].reset_index(drop=True)\n",
        "train_df['label'] = train_df['label'].astype('int8')\n",
        "test_df = df[df['label'].isna()].reset_index(drop=True)\n",
        "\n",
        "\n",
        "train_his = np.array(train_df['history'].values.tolist())\n",
        "train_mask = (train_his == 0).astype('float32')\n",
        "train_target = train_df['item_id'].values\n",
        "train_feats = train_df[feats_cols].values\n",
        "labels = train_df['label'].values\n",
        "\n",
        "test_his = np.array(test_df['history'].values.tolist())\n",
        "test_mask = (test_his == 0).astype('float32')\n",
        "test_target = test_df['item_id'].values\n",
        "test_feats = test_df[feats_cols].values\n",
        "\n",
        "del train_df, test_df, model\n",
        "gc.collect()\n",
        "\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=2020)\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=1, verbose=1, mode='min')\n",
        "output_dim = 2\n",
        "oof_df['nn_prob'] = 0\n",
        "test_pred_df['nn_prob'] = 0\n",
        "\n",
        "for i, (trn_idx, val_idx) in enumerate(skf.split(train_his, labels)):\n",
        "    print('============ {} fold ============'.format(i))\n",
        "    t = time.time()\n",
        "    \n",
        "    tensorflow.keras.backend.clear_session()\n",
        "    trn_his, trn_mask, trn_target = train_his[trn_idx], train_mask[trn_idx], train_target[trn_idx]\n",
        "    trn_feats, trn_y = train_feats[trn_idx], labels[trn_idx]\n",
        "    val_his, val_mask, val_target = train_his[val_idx], train_mask[val_idx], train_target[val_idx]\n",
        "    val_feats, val_y = train_feats[val_idx], labels[val_idx]\n",
        "    \n",
        "    clf=build_model(transformer_layer, max_len=MAX_LEN)\n",
        "\n",
        "    clf.fit(\n",
        "        x=[trn_his, trn_mask, trn_target, trn_feats], y=np.eye(output_dim)[trn_y],\n",
        "        batch_size=1024, epochs=4,\n",
        "        validation_data=([val_his, val_mask, val_target, val_feats], np.eye(output_dim)[val_y]),\n",
        "        verbose=1, callbacks=[early_stopping]\n",
        "    )\n",
        "    oof_df.loc[val_idx, 'nn_prob'] = clf.predict([val_his, val_mask, val_target, val_feats], batch_size=2048)[:, 1]\n",
        "    print('val auc:', roc_auc_score(val_y, oof_df['nn_prob'].values[val_idx]))\n",
        "    test_pred_df['nn_prob'] += clf.predict([test_his, test_mask, test_target, test_feats], batch_size=2048)[:, 1] / skf.n_splits\n",
        "  \n",
        "    \n",
        "    del clf\n",
        "    gc.collect()\n",
        "    \n",
        "    print('runtime: {}\\n'.format(time.time() - t))\n",
        "\n",
        "\n",
        "oof_df.to_pickle('kdd2020_data/recall/bert_trn.pkl')\n",
        "test_pred_df.to_pickle('kdd2020_data/recall/bert_test.pkl')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 99320/11489051 [00:00<00:11, 993189.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(11489051, 75)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 11489051/11489051 [00:12<00:00, 910130.75it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[ 1  3  9 10 14 18 19 20 21 22]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/60 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['item_id_phase_user_age_level_mean', 'item_id_phase_user_age_level_min', 'item_id_phase_user_age_level_max', 'item_id_phase_user_age_level_std', 'phase_item_click_gender_mean', 'user_age_level', 'user_gender', 'user_city_level', 'phase_user_age_level_click_count']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 60/60 [01:06<00:00,  1.10s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(11489051, 75)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rpandas bar:   0%|          | 0/11489051 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.8137921922358948\n",
            "1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "pandas bar: 100%|██████████| 11489051/11489051 [00:11<00:00, 1035528.24it/s]\n",
            "pandas bar:   0%|          | 0/11489051 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "count    1.148905e+07\n",
            "mean     1.516868e+01\n",
            "std      1.352401e+01\n",
            "min      1.000000e+00\n",
            "25%      6.000000e+00\n",
            "50%      1.100000e+01\n",
            "75%      1.900000e+01\n",
            "max      1.530000e+02\n",
            "Name: len, dtype: float64\n",
            "32.0\n",
            "42.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "pandas bar: 100%|██████████| 11489051/11489051 [01:49<00:00, 104753.14it/s]\n",
            "pandas bar: 100%|██████████| 11489051/11489051 [00:41<00:00, 276912.77it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYfHFxPGj_RM",
        "colab_type": "text"
      },
      "source": [
        "# Stacking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOEOu_rOVt5x",
        "colab_type": "text"
      },
      "source": [
        "**lightgbm & xgboost**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US-fEFiXtsAi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import GroupKFold\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import math\n",
        "\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_NHu-tBnL2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 2020\n",
        "current_phase = 3"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaOgqJLlnPbA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "afe68f91-5469-4bec-8000-e73f42223939"
      },
      "source": [
        "df_feature = pd.read_pickle('kdd2020_data/recall/rank_feature11.pkl')\n",
        "print(df_feature.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11489051, 74)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LyJYzLenXlW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_nn_train = pd.read_pickle('kdd2020_data/recall/nn_trn.pkl')\n",
        "df_nn_test = pd.read_pickle('kdd2020_data/recall/nn_test.pkl')\n",
        "df_nn = df_nn_train.append(df_nn_test)\n",
        "print(df_nn.shape)\n",
        "df_feature = df_feature.merge(df_nn[['user_id', 'phase', 'item_id', 'nn_prob']], how='left')\n",
        "del df_nn\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aAiRWAlnl_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_nn2 = pd.read_pickle('kdd2020_data/recall/nn2.pkl')\n",
        "df_feature = df_feature.merge(\n",
        "    df_nn2[['user_id', 'phase', 'item_id', 'pred']], how='left')\n",
        "del df_nn2\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzEEylzQnv39",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b19321b9-31cc-402d-db27-a7ca2c8f0f88"
      },
      "source": [
        "df_feature['group'] = df_feature['user_id'].astype('str') + '_' + df_feature['phase'].astype('str')\n",
        "\n",
        "df_train = df_feature[df_feature['label'].notnull()]\n",
        "df_test = df_feature[df_feature['label'].isnull()]\n",
        "\n",
        "del df_feature\n",
        "gc.collect()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2555"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mDYnJ9tn0iD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d49c629d-905c-46e0-a4f6-ee8bdc63a629"
      },
      "source": [
        "ycol = 'label'\n",
        "\n",
        "feature_names = list(\n",
        "    filter(lambda x: x not in [ycol, 'group'], df_train.columns))\n",
        "\n",
        "model = lgb.LGBMClassifier(num_leaves=64,\n",
        "                           max_depth=10,\n",
        "                           learning_rate=0.01,\n",
        "                           n_estimators=10000,\n",
        "                           subsample=0.8,\n",
        "                           feature_fraction=0.8,\n",
        "                           reg_alpha=0.5,\n",
        "                           reg_lambda=0.5,\n",
        "                           random_state=seed,\n",
        "                           metric=None)\n",
        "\n",
        "oof = []\n",
        "prediction = df_test[['user_id', 'phase', 'item_id']]\n",
        "prediction['pred'] = 0\n",
        "df_importance_list = []\n",
        "\n",
        "kfold = GroupKFold(n_splits=5)\n",
        "for fold_id, (trn_idx, val_idx) in enumerate(\n",
        "        kfold.split(df_train[feature_names], df_train[ycol],\n",
        "                    df_train['group'])):\n",
        "    X_train = df_train.iloc[trn_idx][feature_names]\n",
        "    Y_train = df_train.iloc[trn_idx][ycol]\n",
        "\n",
        "    X_val = df_train.iloc[val_idx][feature_names]\n",
        "    Y_val = df_train.iloc[val_idx][ycol]\n",
        "\n",
        "    print('\\nFold_{} Training ================================\\n'.format(\n",
        "        fold_id + 1))\n",
        "\n",
        "    lgb_model = model.fit(X_train,\n",
        "                          Y_train,\n",
        "                          eval_names=['train', 'valid'],\n",
        "                          eval_set=[(X_val, Y_val)],\n",
        "                          verbose=500,\n",
        "                          eval_metric='auc',\n",
        "                          early_stopping_rounds=50)\n",
        "\n",
        "    pred_val = lgb_model.predict_proba(X_val, num_iteration=lgb_model.best_iteration_)[:, 1]\n",
        "    df_oof = df_train.iloc[val_idx][['user_id', 'item_id', 'phase',ycol]].copy()\n",
        "    df_oof['pred'] = pred_val\n",
        "    oof.append(df_oof)\n",
        "\n",
        "    pred_test = lgb_model.predict_proba(\n",
        "        df_test[feature_names], num_iteration=lgb_model.best_iteration_)[:, 1]\n",
        "    prediction['pred'] += pred_test / 5\n",
        "\n",
        "    df_importance = pd.DataFrame({\n",
        "        'column': feature_names,\n",
        "        'importance': lgb_model.feature_importances_,\n",
        "    })\n",
        "    df_importance_list.append(df_importance)\n",
        "\n",
        "    del lgb_model, pred_val, pred_test, X_train, Y_train, X_val, Y_val\n",
        "    gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Fold_1 Training ================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noKl0yOfn5sQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_importance = pd.concat(df_importance_list)\n",
        "df_importance = df_importance.groupby(['column'])['importance'].agg('mean').sort_values(ascending=False).reset_index()\n",
        "df_importance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kr7T2jTln_6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_oof = pd.concat(oof)\n",
        "df_oof.sort_values(['user_id', 'phase', 'pred'], inplace=True, ascending=False)\n",
        "df_oof.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDu4YZM7oBJL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_score = np.array([0.0, 0.0, 0.0, 0.0])\n",
        "phases = sorted(list(df_oof['phase'].unique()))\n",
        "\n",
        "for phase in phases:\n",
        "    df_oof_phase = df_oof[df_oof['phase'] == phase]\n",
        "    score = evaluate_scores(df_oof_phase, phase)\n",
        "    val_score += score\n",
        "    print(score)\n",
        "val_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THT9nS3loDpi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_click = pd.read_pickle('kdd2020_data/recall/click.pkl')\n",
        "df_count = df_click.groupby(['item_id', 'phase']).size().reset_index()\n",
        "df_count.rename({0: 'count'}, inplace=True, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KzaXZWPoGlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_score = np.array([0.0, 0.0, 0.0, 0.0])\n",
        "df_oof_b = df_oof.merge(df_count, how='left')\n",
        "df_oof_b['count'] = df_oof_b['count']**0.5\n",
        "df_oof_b['pred'] = df_oof_b['pred'] / df_oof_b['count'] #use mean to improve low-frequency item to appear\n",
        "phases = sorted(list(df_oof_b['phase'].unique()))\n",
        "df_oof_b.sort_values(['user_id', 'phase', 'pred'],\n",
        "                     inplace=True,\n",
        "                     ascending=False)\n",
        "\n",
        "for phase in phases:\n",
        "    df_oof_phase = df_oof_b[df_oof_b['phase'] == phase]\n",
        "    score = evaluate_scores(df_oof_phase, phase)\n",
        "    val_score += score\n",
        "    print(score)\n",
        "print(val_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYq2nJM7oJPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_b = prediction.merge(df_count, how='left')\n",
        "prediction_b['count'] = prediction_b['count']**0.5\n",
        "prediction_b['pred'] = prediction_b['pred'] / prediction_b['count']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daUgLhKQoL-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from random import sample\n",
        "prediction.sort_values(['phase', 'user_id', 'pred'],inplace=True,ascending=False)\n",
        "final_prediction = prediction_b[prediction_b['phase'] > 6]\n",
        "\n",
        "gg = final_prediction.groupby(['user_id', 'phase'])\n",
        "all_items = set(final_prediction['item_id'].values)\n",
        "\n",
        "lines = []\n",
        "\n",
        "for _, g in tqdm(gg):\n",
        "    g = g.head(50)\n",
        "\n",
        "    user_id = g['user_id'].values[0]\n",
        "    items = g['item_id'].values.tolist()\n",
        "\n",
        "    if len(set(items)) < 50:\n",
        "        buchong = all_items - set(items)\n",
        "        buchong = sample(buchong, 50 - len(set(items)))\n",
        "        items += buchong\n",
        "\n",
        "    assert len(set(items)) == 50\n",
        "\n",
        "    lines.append([user_id] + items)\n",
        "\n",
        "df_sub = pd.DataFrame(lines)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAdRDalioPT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_sub.to_csv('../prediction_result/result.csv', index=False, header=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}